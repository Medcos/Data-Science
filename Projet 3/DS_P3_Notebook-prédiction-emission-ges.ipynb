{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203ad14c",
   "metadata": {},
   "source": [
    "# Sommaire :\n",
    " \n",
    " **<a href=\"#C1\">IMPORTATION </a>**\n",
    "  - <a href =\"#C11\"> Importation des libraries</a>\n",
    "  - <a href =\"#C12\"> Chargement des données</a>\n",
    "  \n",
    "**<a href=\"#C2\"> PREPARATION DE DONNEES </a>**\n",
    "  - <a href =\"#C21\"> 2.1)  Division des données en ensembles d'entraînement et de test</a>\n",
    "  -<a href =\"#C22\"> 2.2)  Création du caractère aléatoire et proportionnelle de la division </a>\n",
    "  \n",
    "**<a href=\"#C3\"> MODELISATION </a>**\n",
    "  - <a href =\"#C31\"> 3.1) Regression linéaire </a>\n",
    "  - <a href =\"#C32\"> 3.2) Forêt Aléatoire </a>\n",
    "  - <a href =\"#C33\"> 3.3) Gradient Boosting </a>\n",
    "  - <a href =\"#C34\"> 3.4) MLP </a>\n",
    "  - <a href =\"#C35\"> 3.5) XGBoost </a>\n",
    "\n",
    "**<a href=\"#C4\"> CHOIX DU MODELE </a>**\n",
    "  - <a href=\"#C41\"> 4.1) Tableau récapitulatif des score du modèle </a>\n",
    "  - <a href=\"#C42\"> 4.2) Modèle XGBoost avec la librairie LIME </a>\n",
    "  \n",
    "**<a href=\"#C5\"> MODELISATION SANS \"ENERGYSTARScore</a>**\n",
    "  - <a href =\"#C51\"> 5.1) Regression linéaire </a>\n",
    "  - <a href =\"#C52\"> 5.2) Forêt Aléatoire </a>\n",
    "  - <a href =\"#C53\"> 5.3) Gradient Boosting </a>\n",
    "  - <a href =\"#C54\"> 5.4) MLP </a>\n",
    "  - <a href =\"#C55\"> 5.5) XGBoost </a>\n",
    "  \n",
    "**<a href=\"#C6\"> CONCLUSION</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ef8091",
   "metadata": {},
   "source": [
    "# <a name=\"C1\"> IMPORTATION </a>\n",
    "## <a name=\"C11\"> Importation des libraries</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d055d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builtin\n",
    "import os\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9bf234",
   "metadata": {},
   "source": [
    "## <a name=\"C12\"> Chargement des données</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d572ebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CouncilDistrictCode</th>\n",
       "      <th>AgeBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighborhood_9</th>\n",
       "      <th>Neighborhood_10</th>\n",
       "      <th>Neighborhood_11</th>\n",
       "      <th>Neighborhood_12</th>\n",
       "      <th>Neighborhood_13</th>\n",
       "      <th>Neighborhood_14</th>\n",
       "      <th>Neighborhood_15</th>\n",
       "      <th>Neighborhood_16</th>\n",
       "      <th>Neighborhood_17</th>\n",
       "      <th>Neighborhood_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>11.390012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.390012</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.403054</td>\n",
       "      <td>5.206750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11.547964</td>\n",
       "      <td>9.620063</td>\n",
       "      <td>11.390780</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.551769</td>\n",
       "      <td>5.171052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>13.770628</td>\n",
       "      <td>12.189527</td>\n",
       "      <td>13.540273</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.564348</td>\n",
       "      <td>5.488524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>11.023861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.023861</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.707727</td>\n",
       "      <td>5.376204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>12.075850</td>\n",
       "      <td>11.034890</td>\n",
       "      <td>11.640263</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.743192</td>\n",
       "      <td>5.353752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CouncilDistrictCode  AgeBuilt  NumberofBuildings  NumberofFloors  \\\n",
       "0                    7        89                1.0              12   \n",
       "1                    7        20                1.0              11   \n",
       "2                    7        47                1.0              41   \n",
       "3                    7        90                1.0              10   \n",
       "4                    7        36                1.0              18   \n",
       "\n",
       "   PropertyGFATotal  PropertyGFAParking  PropertyGFABuilding(s)  \\\n",
       "0         11.390012            0.000000               11.390012   \n",
       "1         11.547964            9.620063               11.390780   \n",
       "2         13.770628           12.189527               13.540273   \n",
       "3         11.023861            0.000000               11.023861   \n",
       "4         12.075850           11.034890               11.640263   \n",
       "\n",
       "   ENERGYSTARScore  SiteEUI(kBtu/sf)  SourceEUI(kBtu/sf)  ...  Neighborhood_9  \\\n",
       "0             60.0          4.403054            5.206750  ...             0.0   \n",
       "1             61.0          4.551769            5.171052  ...             0.0   \n",
       "2             43.0          4.564348            5.488524  ...             0.0   \n",
       "3             56.0          4.707727            5.376204  ...             0.0   \n",
       "4             75.0          4.743192            5.353752  ...             0.0   \n",
       "\n",
       "   Neighborhood_10  Neighborhood_11  Neighborhood_12  Neighborhood_13  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   Neighborhood_14  Neighborhood_15  Neighborhood_16  Neighborhood_17  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   Neighborhood_18  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ohe_Data\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff518bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1663, 62)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be025ce6",
   "metadata": {},
   "source": [
    "# <a name=\"C2\"> PREPARATION DE DONNEES </a>\n",
    "## <a name=\"C21\"> 2.1) Division des données en ensembles d'entraînement et de test </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f0bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns= [\"Target_Energies\",\"Target_GES\",\"GHGEmissionsIntensity\"])\n",
    "y = data['Target_GES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3dc1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CouncilDistrictCode</th>\n",
       "      <th>AgeBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighborhood_9</th>\n",
       "      <th>Neighborhood_10</th>\n",
       "      <th>Neighborhood_11</th>\n",
       "      <th>Neighborhood_12</th>\n",
       "      <th>Neighborhood_13</th>\n",
       "      <th>Neighborhood_14</th>\n",
       "      <th>Neighborhood_15</th>\n",
       "      <th>Neighborhood_16</th>\n",
       "      <th>Neighborhood_17</th>\n",
       "      <th>Neighborhood_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>11.390012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.390012</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.403054</td>\n",
       "      <td>5.206750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11.547964</td>\n",
       "      <td>9.620063</td>\n",
       "      <td>11.390780</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.551769</td>\n",
       "      <td>5.171052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>13.770628</td>\n",
       "      <td>12.189527</td>\n",
       "      <td>13.540273</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.564348</td>\n",
       "      <td>5.488524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>11.023861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.023861</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.707727</td>\n",
       "      <td>5.376204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>12.075850</td>\n",
       "      <td>11.034890</td>\n",
       "      <td>11.640263</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.743192</td>\n",
       "      <td>5.353752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CouncilDistrictCode  AgeBuilt  NumberofBuildings  NumberofFloors  \\\n",
       "0                    7        89                1.0              12   \n",
       "1                    7        20                1.0              11   \n",
       "2                    7        47                1.0              41   \n",
       "3                    7        90                1.0              10   \n",
       "4                    7        36                1.0              18   \n",
       "\n",
       "   PropertyGFATotal  PropertyGFAParking  PropertyGFABuilding(s)  \\\n",
       "0         11.390012            0.000000               11.390012   \n",
       "1         11.547964            9.620063               11.390780   \n",
       "2         13.770628           12.189527               13.540273   \n",
       "3         11.023861            0.000000               11.023861   \n",
       "4         12.075850           11.034890               11.640263   \n",
       "\n",
       "   ENERGYSTARScore  SiteEUI(kBtu/sf)  SourceEUI(kBtu/sf)  ...  Neighborhood_9  \\\n",
       "0             60.0          4.403054            5.206750  ...             0.0   \n",
       "1             61.0          4.551769            5.171052  ...             0.0   \n",
       "2             43.0          4.564348            5.488524  ...             0.0   \n",
       "3             56.0          4.707727            5.376204  ...             0.0   \n",
       "4             75.0          4.743192            5.353752  ...             0.0   \n",
       "\n",
       "   Neighborhood_10  Neighborhood_11  Neighborhood_12  Neighborhood_13  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   Neighborhood_14  Neighborhood_15  Neighborhood_16  Neighborhood_17  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   Neighborhood_18  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2a5e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.521381\n",
       "1    5.689886\n",
       "2    7.644575\n",
       "3    5.657494\n",
       "4    6.224578\n",
       "Name: Target_GES, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2f80b",
   "metadata": {},
   "source": [
    "## <a name=\"C22\"> 2.2) Création du caractère aléatoire et proportionnelle de la division </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df25a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc01b645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CouncilDistrictCode</th>\n",
       "      <th>AgeBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighborhood_9</th>\n",
       "      <th>Neighborhood_10</th>\n",
       "      <th>Neighborhood_11</th>\n",
       "      <th>Neighborhood_12</th>\n",
       "      <th>Neighborhood_13</th>\n",
       "      <th>Neighborhood_14</th>\n",
       "      <th>Neighborhood_15</th>\n",
       "      <th>Neighborhood_16</th>\n",
       "      <th>Neighborhood_17</th>\n",
       "      <th>Neighborhood_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.730794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.730794</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.765587</td>\n",
       "      <td>5.775483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.631712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.631712</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.523415</td>\n",
       "      <td>4.231204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11.602282</td>\n",
       "      <td>10.563595</td>\n",
       "      <td>11.165451</td>\n",
       "      <td>47.5</td>\n",
       "      <td>4.756173</td>\n",
       "      <td>5.839478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.098026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.098026</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.186051</td>\n",
       "      <td>3.328627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12.270375</td>\n",
       "      <td>11.654668</td>\n",
       "      <td>11.493284</td>\n",
       "      <td>83.0</td>\n",
       "      <td>3.981549</td>\n",
       "      <td>5.126342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CouncilDistrictCode  AgeBuilt  NumberofBuildings  NumberofFloors  \\\n",
       "1563                    3        20                0.0               3   \n",
       "1155                    2        55                1.0               1   \n",
       "243                     7        36                1.0               4   \n",
       "1223                    4        70                1.0               1   \n",
       "312                     7        20                2.0               5   \n",
       "\n",
       "      PropertyGFATotal  PropertyGFAParking  PropertyGFABuilding(s)  \\\n",
       "1563         10.730794            0.000000               10.730794   \n",
       "1155         10.631712            0.000000               10.631712   \n",
       "243          11.602282           10.563595               11.165451   \n",
       "1223         10.098026            0.000000               10.098026   \n",
       "312          12.270375           11.654668               11.493284   \n",
       "\n",
       "      ENERGYSTARScore  SiteEUI(kBtu/sf)  SourceEUI(kBtu/sf)  ...  \\\n",
       "1563             88.0          4.765587            5.775483  ...   \n",
       "1155             90.0          3.523415            4.231204  ...   \n",
       "243              47.5          4.756173            5.839478  ...   \n",
       "1223             53.0          2.186051            3.328627  ...   \n",
       "312              83.0          3.981549            5.126342  ...   \n",
       "\n",
       "      Neighborhood_9  Neighborhood_10  Neighborhood_11  Neighborhood_12  \\\n",
       "1563             0.0              0.0              0.0              0.0   \n",
       "1155             0.0              0.0              0.0              0.0   \n",
       "243              0.0              0.0              0.0              0.0   \n",
       "1223             0.0              0.0              0.0              0.0   \n",
       "312              0.0              0.0              1.0              0.0   \n",
       "\n",
       "      Neighborhood_13  Neighborhood_14  Neighborhood_15  Neighborhood_16  \\\n",
       "1563              0.0              0.0              0.0              0.0   \n",
       "1155              0.0              0.0              0.0              0.0   \n",
       "243               0.0              0.0              0.0              0.0   \n",
       "1223              1.0              0.0              0.0              0.0   \n",
       "312               0.0              0.0              0.0              0.0   \n",
       "\n",
       "      Neighborhood_17  Neighborhood_18  \n",
       "1563              0.0              0.0  \n",
       "1155              1.0              0.0  \n",
       "243               0.0              0.0  \n",
       "1223              0.0              0.0  \n",
       "312               0.0              0.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42, shuffle=True)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f769f13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448    3.408504\n",
       "168     9.281225\n",
       "220     5.893466\n",
       "1643    4.214347\n",
       "344     6.169339\n",
       "Name: Target_GES, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b41ea",
   "metadata": {},
   "source": [
    "# <a name=\"C3\"> MODELISATION </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d889db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# calculer les scores R² et \n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af7b07",
   "metadata": {},
   "source": [
    "## <a name=\"C31\"> 3.1) Regression linéaire </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094cf4e",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle\n",
    "#### Le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a65584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7f09b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du modèle\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "parameters = {'normalize': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aec7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "lr = GridSearchCV(estimator=model, param_grid=parameters, cv=5, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1120b972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearRegression(),\n",
       "             param_grid={'normalize': [True, False]}, scoring='r2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiser sur le jeu d'entraînement\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad41d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_normalize</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013096</td>\n",
       "      <td>0.018041</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>True</td>\n",
       "      <td>{'normalize': True}</td>\n",
       "      <td>0.908985</td>\n",
       "      <td>-1.226554e+21</td>\n",
       "      <td>-1.870435e+21</td>\n",
       "      <td>-1.467149e+22</td>\n",
       "      <td>0.182631</td>\n",
       "      <td>-3.553696e+21</td>\n",
       "      <td>5.605567e+21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>False</td>\n",
       "      <td>{'normalize': False}</td>\n",
       "      <td>0.908932</td>\n",
       "      <td>8.858361e-01</td>\n",
       "      <td>9.432302e-01</td>\n",
       "      <td>9.173024e-01</td>\n",
       "      <td>0.182651</td>\n",
       "      <td>7.675902e-01</td>\n",
       "      <td>2.930451e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.013096      0.018041         0.003303        0.004689   \n",
       "1       0.000000      0.000000         0.006252        0.007658   \n",
       "\n",
       "  param_normalize                params  split0_test_score  split1_test_score  \\\n",
       "0            True   {'normalize': True}           0.908985      -1.226554e+21   \n",
       "1           False  {'normalize': False}           0.908932       8.858361e-01   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0      -1.870435e+21      -1.467149e+22           0.182631    -3.553696e+21   \n",
       "1       9.432302e-01       9.173024e-01           0.182651     7.675902e-01   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0    5.605567e+21                2  \n",
       "1    2.930451e-01                1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# résultats de la validation croisée\n",
    "res = lr.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a50da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d74e4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.7675902484492775\n"
     ]
    }
   ],
   "source": [
    "lr_r2 = lr.best_score_\n",
    "print(\"Best score: \", lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb19ac",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab5680de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9e58d",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "105d9724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Racine de l'erreur quadratique moyenne :  0.19604465402957524\n",
      "--------------------------------------------------------------------------------\n",
      "Erreur quadratique moyenne :  0.4427693011372573\n",
      "Erreur carré relative :  0.08301362316399041\n",
      "Score R² :  0.9169863768360096\n"
     ]
    }
   ],
   "source": [
    "# la racine de l'erreur quadratique moyenne\n",
    "rmse = mean_squared_error(y_test, y_test_pred)\n",
    "# l'erreur quadratique moyenne\n",
    "mse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "# Le score R²\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "# l'erreur carré relative\n",
    "rse = 1-r2\n",
    "\n",
    "print(\"Racine de l'erreur quadratique moyenne : \", rmse)\n",
    "\n",
    "print('----'*20)\n",
    "print(\"Erreur quadratique moyenne : \", mse)\n",
    "print(\"Erreur carré relative : \", rse)\n",
    "print('Score R² : ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49eb54b",
   "metadata": {},
   "source": [
    "#### Les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7ea9172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Régression Linéaire</th>\n",
       "      <td>0.442769</td>\n",
       "      <td>0.083014</td>\n",
       "      <td>0.916986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mse       rse        R²\n",
       "Régression Linéaire  0.442769  0.083014  0.916986"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'mse':mse,\n",
    "    'rse' :rse,\n",
    "    'R²' : r2\n",
    "}\n",
    "df_lr  = pd.DataFrame(scores, index = ['Régression Linéaire'])\n",
    "df_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b45271",
   "metadata": {},
   "source": [
    "### c.) Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bf8264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les importances de caractéristiques\n",
    "feat_imp = lr.best_estimator_.coef_\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance':feat_imp\n",
    "})\n",
    "# Trier la dataframe obtenué\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "864abddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SiteEUI(kBtu/sf)</td>\n",
       "      <td>1.343022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PrimaryPropertyType_1</td>\n",
       "      <td>0.540107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PropertyGFABuilding(s)</td>\n",
       "      <td>0.452275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Attribute  Importance\n",
       "8         SiteEUI(kBtu/sf)    1.343022\n",
       "19   PrimaryPropertyType_1    0.540107\n",
       "6   PropertyGFABuilding(s)    0.452275"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = importances.iloc[:3]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dd67730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# le graphique à barres à partir de coefficients : \n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color= 'red')\n",
    "plt.title('Feature importances ', size=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad9687",
   "metadata": {},
   "source": [
    "## <a name=\"C32\"> 3.2) Forêt Aléatoire </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231bd129",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle\n",
    "#### modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ace3122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as model_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8010ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du modèle\n",
    "rf = model_class(random_state=42)\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'max_depth': [1,2,3,4,5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb0b35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "rfr = GridSearchCV(estimator=rf, param_grid = param_grid, cv=5, scoring = ['r2', 'neg_mean_squared_error'],refit='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e2d19b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [100, 150, 200, 250, 300]},\n",
       "             refit='r2', scoring=['r2', 'neg_mean_squared_error'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiser sur le jeu d'entraînement\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d06dd219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_test_neg_mean_squared_error</th>\n",
       "      <th>split1_test_neg_mean_squared_error</th>\n",
       "      <th>split2_test_neg_mean_squared_error</th>\n",
       "      <th>split3_test_neg_mean_squared_error</th>\n",
       "      <th>split4_test_neg_mean_squared_error</th>\n",
       "      <th>mean_test_neg_mean_squared_error</th>\n",
       "      <th>std_test_neg_mean_squared_error</th>\n",
       "      <th>rank_test_neg_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.311814</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.020462</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 100}</td>\n",
       "      <td>0.445467</td>\n",
       "      <td>0.512755</td>\n",
       "      <td>0.463094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040774</td>\n",
       "      <td>25</td>\n",
       "      <td>-1.296555</td>\n",
       "      <td>-1.209441</td>\n",
       "      <td>-1.226392</td>\n",
       "      <td>-1.457073</td>\n",
       "      <td>-1.140395</td>\n",
       "      <td>-1.265971</td>\n",
       "      <td>0.107691</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.460330</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>0.028118</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 150}</td>\n",
       "      <td>0.440254</td>\n",
       "      <td>0.509504</td>\n",
       "      <td>0.469789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038630</td>\n",
       "      <td>22</td>\n",
       "      <td>-1.308744</td>\n",
       "      <td>-1.217511</td>\n",
       "      <td>-1.211100</td>\n",
       "      <td>-1.456007</td>\n",
       "      <td>-1.120925</td>\n",
       "      <td>-1.262857</td>\n",
       "      <td>0.113395</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.596241</td>\n",
       "      <td>0.080326</td>\n",
       "      <td>0.025021</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 200}</td>\n",
       "      <td>0.439015</td>\n",
       "      <td>0.508825</td>\n",
       "      <td>0.468327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>24</td>\n",
       "      <td>-1.311640</td>\n",
       "      <td>-1.219195</td>\n",
       "      <td>-1.214439</td>\n",
       "      <td>-1.461075</td>\n",
       "      <td>-1.122667</td>\n",
       "      <td>-1.265803</td>\n",
       "      <td>0.114482</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.653608</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>0.039768</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 250}</td>\n",
       "      <td>0.439668</td>\n",
       "      <td>0.510757</td>\n",
       "      <td>0.470315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.310114</td>\n",
       "      <td>-1.214401</td>\n",
       "      <td>-1.209899</td>\n",
       "      <td>-1.462535</td>\n",
       "      <td>-1.117107</td>\n",
       "      <td>-1.262811</td>\n",
       "      <td>0.117047</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.914911</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 300}</td>\n",
       "      <td>0.436573</td>\n",
       "      <td>0.513594</td>\n",
       "      <td>0.470467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040750</td>\n",
       "      <td>23</td>\n",
       "      <td>-1.317349</td>\n",
       "      <td>-1.207359</td>\n",
       "      <td>-1.209550</td>\n",
       "      <td>-1.461946</td>\n",
       "      <td>-1.120504</td>\n",
       "      <td>-1.263341</td>\n",
       "      <td>0.117295</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.412836</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.018746</td>\n",
       "      <td>0.006245</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 100}</td>\n",
       "      <td>0.726869</td>\n",
       "      <td>0.731441</td>\n",
       "      <td>0.694033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020326</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.638609</td>\n",
       "      <td>-0.666617</td>\n",
       "      <td>-0.698886</td>\n",
       "      <td>-0.739103</td>\n",
       "      <td>-0.617963</td>\n",
       "      <td>-0.672236</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.616185</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.022233</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 150}</td>\n",
       "      <td>0.721212</td>\n",
       "      <td>0.730266</td>\n",
       "      <td>0.699849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016580</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.651834</td>\n",
       "      <td>-0.669534</td>\n",
       "      <td>-0.685601</td>\n",
       "      <td>-0.739964</td>\n",
       "      <td>-0.604548</td>\n",
       "      <td>-0.670296</td>\n",
       "      <td>0.044163</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.696366</td>\n",
       "      <td>0.118845</td>\n",
       "      <td>0.025884</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 200}</td>\n",
       "      <td>0.717987</td>\n",
       "      <td>0.729635</td>\n",
       "      <td>0.699365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015670</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.659376</td>\n",
       "      <td>-0.671100</td>\n",
       "      <td>-0.686705</td>\n",
       "      <td>-0.742879</td>\n",
       "      <td>-0.601455</td>\n",
       "      <td>-0.672303</td>\n",
       "      <td>0.045555</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.988926</td>\n",
       "      <td>0.071412</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 250}</td>\n",
       "      <td>0.718379</td>\n",
       "      <td>0.730802</td>\n",
       "      <td>0.701797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014817</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.658458</td>\n",
       "      <td>-0.668204</td>\n",
       "      <td>-0.681150</td>\n",
       "      <td>-0.740049</td>\n",
       "      <td>-0.593829</td>\n",
       "      <td>-0.668338</td>\n",
       "      <td>0.046810</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.244489</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.046570</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 300}</td>\n",
       "      <td>0.716709</td>\n",
       "      <td>0.732906</td>\n",
       "      <td>0.701672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015768</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.662362</td>\n",
       "      <td>-0.662981</td>\n",
       "      <td>-0.681437</td>\n",
       "      <td>-0.742147</td>\n",
       "      <td>-0.596909</td>\n",
       "      <td>-0.669167</td>\n",
       "      <td>0.046438</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.029214</td>\n",
       "      <td>0.018304</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.842418</td>\n",
       "      <td>0.824388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.348364</td>\n",
       "      <td>-0.391150</td>\n",
       "      <td>-0.401131</td>\n",
       "      <td>-0.449021</td>\n",
       "      <td>-0.331560</td>\n",
       "      <td>-0.384245</td>\n",
       "      <td>0.041453</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.735826</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.029331</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 150}</td>\n",
       "      <td>0.849452</td>\n",
       "      <td>0.842335</td>\n",
       "      <td>0.826154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.351997</td>\n",
       "      <td>-0.391357</td>\n",
       "      <td>-0.397095</td>\n",
       "      <td>-0.447285</td>\n",
       "      <td>-0.323372</td>\n",
       "      <td>-0.382221</td>\n",
       "      <td>0.042225</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.038616</td>\n",
       "      <td>0.017549</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 200}</td>\n",
       "      <td>0.846656</td>\n",
       "      <td>0.840782</td>\n",
       "      <td>0.825903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.358533</td>\n",
       "      <td>-0.395213</td>\n",
       "      <td>-0.397669</td>\n",
       "      <td>-0.449910</td>\n",
       "      <td>-0.321772</td>\n",
       "      <td>-0.384619</td>\n",
       "      <td>0.042839</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.294247</td>\n",
       "      <td>0.018160</td>\n",
       "      <td>0.036135</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 250}</td>\n",
       "      <td>0.847924</td>\n",
       "      <td>0.841542</td>\n",
       "      <td>0.826253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.355570</td>\n",
       "      <td>-0.393326</td>\n",
       "      <td>-0.396871</td>\n",
       "      <td>-0.447993</td>\n",
       "      <td>-0.318502</td>\n",
       "      <td>-0.382452</td>\n",
       "      <td>0.043437</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.354062</td>\n",
       "      <td>0.213364</td>\n",
       "      <td>0.047349</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 300}</td>\n",
       "      <td>0.846740</td>\n",
       "      <td>0.843797</td>\n",
       "      <td>0.826637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.358337</td>\n",
       "      <td>-0.387727</td>\n",
       "      <td>-0.395992</td>\n",
       "      <td>-0.446669</td>\n",
       "      <td>-0.318349</td>\n",
       "      <td>-0.381415</td>\n",
       "      <td>0.042474</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.622964</td>\n",
       "      <td>0.036117</td>\n",
       "      <td>0.025007</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 100}</td>\n",
       "      <td>0.917371</td>\n",
       "      <td>0.917993</td>\n",
       "      <td>0.901166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.193195</td>\n",
       "      <td>-0.203557</td>\n",
       "      <td>-0.225755</td>\n",
       "      <td>-0.253211</td>\n",
       "      <td>-0.198630</td>\n",
       "      <td>-0.214870</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.038404</td>\n",
       "      <td>0.187315</td>\n",
       "      <td>0.029424</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 150}</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.916877</td>\n",
       "      <td>0.900154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.196481</td>\n",
       "      <td>-0.206328</td>\n",
       "      <td>-0.228067</td>\n",
       "      <td>-0.256650</td>\n",
       "      <td>-0.194892</td>\n",
       "      <td>-0.216484</td>\n",
       "      <td>0.023311</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.185408</td>\n",
       "      <td>0.083788</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 200}</td>\n",
       "      <td>0.914025</td>\n",
       "      <td>0.915222</td>\n",
       "      <td>0.898450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.201019</td>\n",
       "      <td>-0.210436</td>\n",
       "      <td>-0.231958</td>\n",
       "      <td>-0.254007</td>\n",
       "      <td>-0.194566</td>\n",
       "      <td>-0.218397</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.536507</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.043575</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 250}</td>\n",
       "      <td>0.914960</td>\n",
       "      <td>0.915449</td>\n",
       "      <td>0.898288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.198833</td>\n",
       "      <td>-0.209873</td>\n",
       "      <td>-0.232329</td>\n",
       "      <td>-0.250730</td>\n",
       "      <td>-0.191975</td>\n",
       "      <td>-0.216748</td>\n",
       "      <td>0.021815</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.716027</td>\n",
       "      <td>0.194076</td>\n",
       "      <td>0.049644</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 300}</td>\n",
       "      <td>0.914240</td>\n",
       "      <td>0.917147</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.200516</td>\n",
       "      <td>-0.205658</td>\n",
       "      <td>-0.232226</td>\n",
       "      <td>-0.250526</td>\n",
       "      <td>-0.193073</td>\n",
       "      <td>-0.216400</td>\n",
       "      <td>0.021573</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.699901</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>0.027555</td>\n",
       "      <td>0.006067</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.951561</td>\n",
       "      <td>0.961231</td>\n",
       "      <td>0.958528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.113255</td>\n",
       "      <td>-0.096232</td>\n",
       "      <td>-0.094730</td>\n",
       "      <td>-0.115211</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>-0.107502</td>\n",
       "      <td>0.009946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.068378</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.032652</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 150}</td>\n",
       "      <td>0.951853</td>\n",
       "      <td>0.960484</td>\n",
       "      <td>0.957710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.112572</td>\n",
       "      <td>-0.098086</td>\n",
       "      <td>-0.096599</td>\n",
       "      <td>-0.116336</td>\n",
       "      <td>-0.118197</td>\n",
       "      <td>-0.108358</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.315579</td>\n",
       "      <td>0.105090</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>0.008709</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.950960</td>\n",
       "      <td>0.960334</td>\n",
       "      <td>0.957317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.114661</td>\n",
       "      <td>-0.098459</td>\n",
       "      <td>-0.097495</td>\n",
       "      <td>-0.117347</td>\n",
       "      <td>-0.119399</td>\n",
       "      <td>-0.109472</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.811060</td>\n",
       "      <td>0.033118</td>\n",
       "      <td>0.048391</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 250}</td>\n",
       "      <td>0.951134</td>\n",
       "      <td>0.960525</td>\n",
       "      <td>0.956703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.114254</td>\n",
       "      <td>-0.097985</td>\n",
       "      <td>-0.098897</td>\n",
       "      <td>-0.117888</td>\n",
       "      <td>-0.118930</td>\n",
       "      <td>-0.109591</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.998371</td>\n",
       "      <td>0.146827</td>\n",
       "      <td>0.048192</td>\n",
       "      <td>0.007010</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 300}</td>\n",
       "      <td>0.950433</td>\n",
       "      <td>0.960800</td>\n",
       "      <td>0.956555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007623</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.115892</td>\n",
       "      <td>-0.097301</td>\n",
       "      <td>-0.099237</td>\n",
       "      <td>-0.119003</td>\n",
       "      <td>-0.118916</td>\n",
       "      <td>-0.110070</td>\n",
       "      <td>0.009719</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.311814      0.009681         0.020462        0.006333   \n",
       "1        0.460330      0.016154         0.028118        0.006247   \n",
       "2        0.596241      0.080326         0.025021        0.005871   \n",
       "3        0.653608      0.097168         0.039768        0.008900   \n",
       "4        0.914911      0.006076         0.050003        0.006241   \n",
       "5        0.412836      0.018684         0.018746        0.006245   \n",
       "6        0.616185      0.012634         0.022233        0.007387   \n",
       "7        0.696366      0.118845         0.025884        0.011179   \n",
       "8        0.988926      0.071412         0.050457        0.007277   \n",
       "9        1.244489      0.026500         0.046570        0.008144   \n",
       "10       0.521368      0.029214         0.018304        0.003502   \n",
       "11       0.735826      0.042945         0.029331        0.002096   \n",
       "12       1.038616      0.017549         0.032308        0.011131   \n",
       "13       1.294247      0.018160         0.036135        0.006660   \n",
       "14       1.354062      0.213364         0.047349        0.008570   \n",
       "15       0.622964      0.036117         0.025007        0.007664   \n",
       "16       1.038404      0.187315         0.029424        0.002731   \n",
       "17       1.185408      0.083788         0.032854        0.003480   \n",
       "18       1.536507      0.013100         0.043575        0.003410   \n",
       "19       1.716027      0.194076         0.049644        0.010726   \n",
       "20       0.699901      0.011845         0.027555        0.006067   \n",
       "21       1.068378      0.013470         0.032652        0.003809   \n",
       "22       1.315579      0.105090         0.035792        0.008709   \n",
       "23       1.811060      0.033118         0.048391        0.002795   \n",
       "24       1.998371      0.146827         0.048192        0.007010   \n",
       "\n",
       "   param_max_depth param_n_estimators                                 params  \\\n",
       "0                1                100  {'max_depth': 1, 'n_estimators': 100}   \n",
       "1                1                150  {'max_depth': 1, 'n_estimators': 150}   \n",
       "2                1                200  {'max_depth': 1, 'n_estimators': 200}   \n",
       "3                1                250  {'max_depth': 1, 'n_estimators': 250}   \n",
       "4                1                300  {'max_depth': 1, 'n_estimators': 300}   \n",
       "5                2                100  {'max_depth': 2, 'n_estimators': 100}   \n",
       "6                2                150  {'max_depth': 2, 'n_estimators': 150}   \n",
       "7                2                200  {'max_depth': 2, 'n_estimators': 200}   \n",
       "8                2                250  {'max_depth': 2, 'n_estimators': 250}   \n",
       "9                2                300  {'max_depth': 2, 'n_estimators': 300}   \n",
       "10               3                100  {'max_depth': 3, 'n_estimators': 100}   \n",
       "11               3                150  {'max_depth': 3, 'n_estimators': 150}   \n",
       "12               3                200  {'max_depth': 3, 'n_estimators': 200}   \n",
       "13               3                250  {'max_depth': 3, 'n_estimators': 250}   \n",
       "14               3                300  {'max_depth': 3, 'n_estimators': 300}   \n",
       "15               4                100  {'max_depth': 4, 'n_estimators': 100}   \n",
       "16               4                150  {'max_depth': 4, 'n_estimators': 150}   \n",
       "17               4                200  {'max_depth': 4, 'n_estimators': 200}   \n",
       "18               4                250  {'max_depth': 4, 'n_estimators': 250}   \n",
       "19               4                300  {'max_depth': 4, 'n_estimators': 300}   \n",
       "20               5                100  {'max_depth': 5, 'n_estimators': 100}   \n",
       "21               5                150  {'max_depth': 5, 'n_estimators': 150}   \n",
       "22               5                200  {'max_depth': 5, 'n_estimators': 200}   \n",
       "23               5                250  {'max_depth': 5, 'n_estimators': 250}   \n",
       "24               5                300  {'max_depth': 5, 'n_estimators': 300}   \n",
       "\n",
       "    split0_test_r2  split1_test_r2  split2_test_r2  ...  std_test_r2  \\\n",
       "0         0.445467        0.512755        0.463094  ...     0.040774   \n",
       "1         0.440254        0.509504        0.469789  ...     0.038630   \n",
       "2         0.439015        0.508825        0.468327  ...     0.038938   \n",
       "3         0.439668        0.510757        0.470315  ...     0.039476   \n",
       "4         0.436573        0.513594        0.470467  ...     0.040750   \n",
       "5         0.726869        0.731441        0.694033  ...     0.020326   \n",
       "6         0.721212        0.730266        0.699849  ...     0.016580   \n",
       "7         0.717987        0.729635        0.699365  ...     0.015670   \n",
       "8         0.718379        0.730802        0.701797  ...     0.014817   \n",
       "9         0.716709        0.732906        0.701672  ...     0.015768   \n",
       "10        0.851006        0.842418        0.824388  ...     0.012852   \n",
       "11        0.849452        0.842335        0.826154  ...     0.011788   \n",
       "12        0.846656        0.840782        0.825903  ...     0.011147   \n",
       "13        0.847924        0.841542        0.826253  ...     0.011333   \n",
       "14        0.846740        0.843797        0.826637  ...     0.011198   \n",
       "15        0.917371        0.917993        0.901166  ...     0.009850   \n",
       "16        0.915966        0.916877        0.900154  ...     0.009340   \n",
       "17        0.914025        0.915222        0.898450  ...     0.008424   \n",
       "18        0.914960        0.915449        0.898288  ...     0.008277   \n",
       "19        0.914240        0.917147        0.898333  ...     0.008610   \n",
       "20        0.951561        0.961231        0.958528  ...     0.007823   \n",
       "21        0.951853        0.960484        0.957710  ...     0.007551   \n",
       "22        0.950960        0.960334        0.957317  ...     0.007695   \n",
       "23        0.951134        0.960525        0.956703  ...     0.007563   \n",
       "24        0.950433        0.960800        0.956555  ...     0.007623   \n",
       "\n",
       "    rank_test_r2  split0_test_neg_mean_squared_error  \\\n",
       "0             25                           -1.296555   \n",
       "1             22                           -1.308744   \n",
       "2             24                           -1.311640   \n",
       "3             21                           -1.310114   \n",
       "4             23                           -1.317349   \n",
       "5             20                           -0.638609   \n",
       "6             18                           -0.651834   \n",
       "7             19                           -0.659376   \n",
       "8             16                           -0.658458   \n",
       "9             17                           -0.662362   \n",
       "10            15                           -0.348364   \n",
       "11            13                           -0.351997   \n",
       "12            14                           -0.358533   \n",
       "13            12                           -0.355570   \n",
       "14            11                           -0.358337   \n",
       "15             6                           -0.193195   \n",
       "16             8                           -0.196481   \n",
       "17            10                           -0.201019   \n",
       "18             9                           -0.198833   \n",
       "19             7                           -0.200516   \n",
       "20             1                           -0.113255   \n",
       "21             2                           -0.112572   \n",
       "22             3                           -0.114661   \n",
       "23             4                           -0.114254   \n",
       "24             5                           -0.115892   \n",
       "\n",
       "    split1_test_neg_mean_squared_error  split2_test_neg_mean_squared_error  \\\n",
       "0                            -1.209441                           -1.226392   \n",
       "1                            -1.217511                           -1.211100   \n",
       "2                            -1.219195                           -1.214439   \n",
       "3                            -1.214401                           -1.209899   \n",
       "4                            -1.207359                           -1.209550   \n",
       "5                            -0.666617                           -0.698886   \n",
       "6                            -0.669534                           -0.685601   \n",
       "7                            -0.671100                           -0.686705   \n",
       "8                            -0.668204                           -0.681150   \n",
       "9                            -0.662981                           -0.681437   \n",
       "10                           -0.391150                           -0.401131   \n",
       "11                           -0.391357                           -0.397095   \n",
       "12                           -0.395213                           -0.397669   \n",
       "13                           -0.393326                           -0.396871   \n",
       "14                           -0.387727                           -0.395992   \n",
       "15                           -0.203557                           -0.225755   \n",
       "16                           -0.206328                           -0.228067   \n",
       "17                           -0.210436                           -0.231958   \n",
       "18                           -0.209873                           -0.232329   \n",
       "19                           -0.205658                           -0.232226   \n",
       "20                           -0.096232                           -0.094730   \n",
       "21                           -0.098086                           -0.096599   \n",
       "22                           -0.098459                           -0.097495   \n",
       "23                           -0.097985                           -0.098897   \n",
       "24                           -0.097301                           -0.099237   \n",
       "\n",
       "    split3_test_neg_mean_squared_error  split4_test_neg_mean_squared_error  \\\n",
       "0                            -1.457073                           -1.140395   \n",
       "1                            -1.456007                           -1.120925   \n",
       "2                            -1.461075                           -1.122667   \n",
       "3                            -1.462535                           -1.117107   \n",
       "4                            -1.461946                           -1.120504   \n",
       "5                            -0.739103                           -0.617963   \n",
       "6                            -0.739964                           -0.604548   \n",
       "7                            -0.742879                           -0.601455   \n",
       "8                            -0.740049                           -0.593829   \n",
       "9                            -0.742147                           -0.596909   \n",
       "10                           -0.449021                           -0.331560   \n",
       "11                           -0.447285                           -0.323372   \n",
       "12                           -0.449910                           -0.321772   \n",
       "13                           -0.447993                           -0.318502   \n",
       "14                           -0.446669                           -0.318349   \n",
       "15                           -0.253211                           -0.198630   \n",
       "16                           -0.256650                           -0.194892   \n",
       "17                           -0.254007                           -0.194566   \n",
       "18                           -0.250730                           -0.191975   \n",
       "19                           -0.250526                           -0.193073   \n",
       "20                           -0.115211                           -0.118080   \n",
       "21                           -0.116336                           -0.118197   \n",
       "22                           -0.117347                           -0.119399   \n",
       "23                           -0.117888                           -0.118930   \n",
       "24                           -0.119003                           -0.118916   \n",
       "\n",
       "    mean_test_neg_mean_squared_error  std_test_neg_mean_squared_error  \\\n",
       "0                          -1.265971                         0.107691   \n",
       "1                          -1.262857                         0.113395   \n",
       "2                          -1.265803                         0.114482   \n",
       "3                          -1.262811                         0.117047   \n",
       "4                          -1.263341                         0.117295   \n",
       "5                          -0.672236                         0.043103   \n",
       "6                          -0.670296                         0.044163   \n",
       "7                          -0.672303                         0.045555   \n",
       "8                          -0.668338                         0.046810   \n",
       "9                          -0.669167                         0.046438   \n",
       "10                         -0.384245                         0.041453   \n",
       "11                         -0.382221                         0.042225   \n",
       "12                         -0.384619                         0.042839   \n",
       "13                         -0.382452                         0.043437   \n",
       "14                         -0.381415                         0.042474   \n",
       "15                         -0.214870                         0.022136   \n",
       "16                         -0.216484                         0.023311   \n",
       "17                         -0.218397                         0.021842   \n",
       "18                         -0.216748                         0.021815   \n",
       "19                         -0.216400                         0.021573   \n",
       "20                         -0.107502                         0.009946   \n",
       "21                         -0.108358                         0.009187   \n",
       "22                         -0.109472                         0.009510   \n",
       "23                         -0.109591                         0.009240   \n",
       "24                         -0.110070                         0.009719   \n",
       "\n",
       "    rank_test_neg_mean_squared_error  \n",
       "0                                 25  \n",
       "1                                 22  \n",
       "2                                 24  \n",
       "3                                 21  \n",
       "4                                 23  \n",
       "5                                 19  \n",
       "6                                 18  \n",
       "7                                 20  \n",
       "8                                 16  \n",
       "9                                 17  \n",
       "10                                14  \n",
       "11                                12  \n",
       "12                                15  \n",
       "13                                13  \n",
       "14                                11  \n",
       "15                                 6  \n",
       "16                                 8  \n",
       "17                                10  \n",
       "18                                 9  \n",
       "19                                 7  \n",
       "20                                 1  \n",
       "21                                 2  \n",
       "22                                 3  \n",
       "23                                 4  \n",
       "24                                 5  \n",
       "\n",
       "[25 rows x 23 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# résultats de la validation croisée\n",
    "res = rfr.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "968ec685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(rfr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f279a733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.952509750597993\n"
     ]
    }
   ],
   "source": [
    "rfr_r2 = rfr.best_score_\n",
    "print(\"Best score: \", rfr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "984b8a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score du training set :  0.9685326572827466\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = rfr.predict(X_train)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "print(\"Score du training set : \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34dac16",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30905bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a128add",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdd3d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6656f93",
   "metadata": {},
   "source": [
    "#### Les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e87f4e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Forêt Aléatoire</th>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.038181</td>\n",
       "      <td>0.961819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mse       rse        R²\n",
       "Forêt Aléatoire  0.090167  0.038181  0.961819"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'mse':mse,\n",
    "    'rse' :rse,\n",
    "    'R²' : r2\n",
    "}\n",
    "df_rfr  = pd.DataFrame(scores, index = ['Forêt Aléatoire'])\n",
    "df_rfr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa3771",
   "metadata": {},
   "source": [
    "### c.) Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17528870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les importances de caractéristiques\n",
    "feat_imp = rfr.best_estimator_.feature_importances_\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance':feat_imp\n",
    "})\n",
    "# Trier la dataframe obtenué\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3041337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaturalGas(kBtu)</td>\n",
       "      <td>0.633677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Electricity(kBtu)</td>\n",
       "      <td>0.214215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SiteEUI(kBtu/sf)</td>\n",
       "      <td>0.082741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Attribute  Importance\n",
       "12   NaturalGas(kBtu)    0.633677\n",
       "11  Electricity(kBtu)    0.214215\n",
       "8    SiteEUI(kBtu/sf)    0.082741"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = importances.iloc[:3]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a311debd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# le graphique à barres à partir de coefficients : \n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color= 'red')\n",
    "plt.title('Feature importances ', size=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0006f4",
   "metadata": {},
   "source": [
    "## <a name=\"C33\"> 3.3) Gradient Boosting </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe855f6d",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle\n",
    "#### modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de4fff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04a44107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du modèle\n",
    "gb =  GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [1,2,3,4,5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de4f436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "gbr = GridSearchCV(estimator=gb, param_grid = param_grid, cv=5, n_jobs=-1, verbose=1, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a979adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.2],\n",
       "                         'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [100, 150, 200, 250, 300]},\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiser sur le jeu d'entraînement\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ceaee09e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.322346</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.004922</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.845442</td>\n",
       "      <td>0.855108</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>0.832797</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.840085</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.491369</td>\n",
       "      <td>0.033054</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.891851</td>\n",
       "      <td>0.899075</td>\n",
       "      <td>0.899538</td>\n",
       "      <td>0.882566</td>\n",
       "      <td>0.860869</td>\n",
       "      <td>0.886780</td>\n",
       "      <td>0.014344</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666842</td>\n",
       "      <td>0.032254</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.915684</td>\n",
       "      <td>0.919777</td>\n",
       "      <td>0.902938</td>\n",
       "      <td>0.879597</td>\n",
       "      <td>0.904650</td>\n",
       "      <td>0.014011</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.780252</td>\n",
       "      <td>0.036166</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.909696</td>\n",
       "      <td>0.922016</td>\n",
       "      <td>0.929879</td>\n",
       "      <td>0.911350</td>\n",
       "      <td>0.888296</td>\n",
       "      <td>0.912247</td>\n",
       "      <td>0.014052</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.993785</td>\n",
       "      <td>0.038221</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.911821</td>\n",
       "      <td>0.925152</td>\n",
       "      <td>0.934419</td>\n",
       "      <td>0.914059</td>\n",
       "      <td>0.890811</td>\n",
       "      <td>0.915252</td>\n",
       "      <td>0.014669</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.380100</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.984648</td>\n",
       "      <td>0.992724</td>\n",
       "      <td>0.995524</td>\n",
       "      <td>0.991737</td>\n",
       "      <td>0.988901</td>\n",
       "      <td>0.990707</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2.110755</td>\n",
       "      <td>0.065290</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.984706</td>\n",
       "      <td>0.992753</td>\n",
       "      <td>0.995534</td>\n",
       "      <td>0.991737</td>\n",
       "      <td>0.988989</td>\n",
       "      <td>0.990744</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2.766919</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.984709</td>\n",
       "      <td>0.992753</td>\n",
       "      <td>0.995545</td>\n",
       "      <td>0.991763</td>\n",
       "      <td>0.988994</td>\n",
       "      <td>0.990753</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3.350845</td>\n",
       "      <td>0.093680</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.984703</td>\n",
       "      <td>0.992748</td>\n",
       "      <td>0.995545</td>\n",
       "      <td>0.991786</td>\n",
       "      <td>0.988986</td>\n",
       "      <td>0.990753</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3.361567</td>\n",
       "      <td>0.247332</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.984699</td>\n",
       "      <td>0.992744</td>\n",
       "      <td>0.995549</td>\n",
       "      <td>0.991788</td>\n",
       "      <td>0.988985</td>\n",
       "      <td>0.990753</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.322346      0.017115         0.003809        0.004922   \n",
       "1        0.491369      0.033054         0.003198        0.003917   \n",
       "2        0.666842      0.032254         0.007060        0.004607   \n",
       "3        0.780252      0.036166         0.006373        0.006635   \n",
       "4        0.993785      0.038221         0.007846        0.006986   \n",
       "..            ...           ...              ...             ...   \n",
       "70       1.380100      0.041095         0.004167        0.006075   \n",
       "71       2.110755      0.065290         0.009373        0.007653   \n",
       "72       2.766919      0.031460         0.007851        0.006988   \n",
       "73       3.350845      0.093680         0.009373        0.007653   \n",
       "74       3.361567      0.247332         0.007152        0.006387   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                 0.05               1                100   \n",
       "1                 0.05               1                150   \n",
       "2                 0.05               1                200   \n",
       "3                 0.05               1                250   \n",
       "4                 0.05               1                300   \n",
       "..                 ...             ...                ...   \n",
       "70                 0.2               5                100   \n",
       "71                 0.2               5                150   \n",
       "72                 0.2               5                200   \n",
       "73                 0.2               5                250   \n",
       "74                 0.2               5                300   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.845442   \n",
       "1   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.891851   \n",
       "2   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.905255   \n",
       "3   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.909696   \n",
       "4   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.911821   \n",
       "..                                                ...                ...   \n",
       "70  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.984648   \n",
       "71  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.984706   \n",
       "72  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.984709   \n",
       "73  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.984703   \n",
       "74  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.984699   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.855108           0.851667           0.832797   \n",
       "1            0.899075           0.899538           0.882566   \n",
       "2            0.915684           0.919777           0.902938   \n",
       "3            0.922016           0.929879           0.911350   \n",
       "4            0.925152           0.934419           0.914059   \n",
       "..                ...                ...                ...   \n",
       "70           0.992724           0.995524           0.991737   \n",
       "71           0.992753           0.995534           0.991737   \n",
       "72           0.992753           0.995545           0.991763   \n",
       "73           0.992748           0.995545           0.991786   \n",
       "74           0.992744           0.995549           0.991788   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.815410         0.840085        0.014495               75  \n",
       "1            0.860869         0.886780        0.014344               74  \n",
       "2            0.879597         0.904650        0.014011               73  \n",
       "3            0.888296         0.912247        0.014052               71  \n",
       "4            0.890811         0.915252        0.014669               69  \n",
       "..                ...              ...             ...              ...  \n",
       "70           0.988901         0.990707        0.003696                8  \n",
       "71           0.988989         0.990744        0.003674                6  \n",
       "72           0.988994         0.990753        0.003677                5  \n",
       "73           0.988986         0.990753        0.003681                3  \n",
       "74           0.988985         0.990753        0.003683                4  \n",
       "\n",
       "[75 rows x 16 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# résultats de la validation croisée\n",
    "res = gbr.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "764b6ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(gbr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4be3f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.9908838865952918\n"
     ]
    }
   ],
   "source": [
    "gbr_r2 = gbr.best_score_\n",
    "print(\"Best score: \", gbr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8daae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score du training set :  0.9995508625237779\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = gbr.predict(X_train)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "print(\"Score du training set : \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69114c",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "458aba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f68c6",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "743b1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a031add",
   "metadata": {},
   "source": [
    "#### Les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30d75e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.011942</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.994943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mse       rse        R²\n",
       "Gradient Boosting  0.011942  0.005057  0.994943"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'mse':mse,\n",
    "    'rse' :rse,\n",
    "    'R²' : r2\n",
    "}\n",
    "df_gr  = pd.DataFrame(scores, index = ['Gradient Boosting'])\n",
    "df_gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97633ac4",
   "metadata": {},
   "source": [
    "### c.) Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a0b3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les importances de caractéristiques\n",
    "feat_imp = gbr.best_estimator_.feature_importances_\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance':feat_imp\n",
    "})\n",
    "# Trier la dataframe obtenué\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "689191ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaturalGas(kBtu)</td>\n",
       "      <td>0.615047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Electricity(kBtu)</td>\n",
       "      <td>0.245497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SteamUse(kBtu)</td>\n",
       "      <td>0.085497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Attribute  Importance\n",
       "12   NaturalGas(kBtu)    0.615047\n",
       "11  Electricity(kBtu)    0.245497\n",
       "10     SteamUse(kBtu)    0.085497"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = importances.iloc[:3]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd2cec9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFiCAYAAADm7CPVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAonElEQVR4nO3de7wcZX3H8c+XhHAPIAkFE0IQowIKFA4RRDGKVMBLwBsgYKPYiBULWgXUFvHSWqWCilQaKRerlqIiRgyXigZbFU2CEQkSGzBACJaACEm4hIRf/3jmcCabnd05J7uZPXO+79drX2cuz8z+zs7sb595ZuYZRQRmZjb8bVZ1AGZm1hlO6GZmNeGEbmZWE07oZmY14YRuZlYTTuhmZjXhhG49TVJkr7lVx2LW60ZXHcBQSBrsxfNfjIgzuhFLJ0iaAUwGiIhzq4zFRg5J+wPHZKPXRMTCyoKxjhiWCb2GZgCvzIbPrS4MG2H2Bz6eDS8FFlYViHVGHRL6sSXK3NX1KKwrIkJVx2A2XAz7hB4R11Qdg5lZL/BJUTOzuoiIYfcCov+1kevZBzif1Hb4R+Ap4H5gNnAisFmb5bciNflcBPwCeBh4GngUWAR8BdivxfJz8/9Li9e5uWWmNZtesP62ZXPz52bjOwIfAeYBD2XzLm+y3BjglOyzug94EvgTcBvweWByh7f13IL5l+fKTM6mvRm4DlgOPAHcCZwHjG9Ydnvgw8AC4BFgVfZ/n9pq25POefS/54xs2qHAN0lt0U8CfwC+Bxw1iP91L+CLwO3ZPvQEcA9wFXBsieWXZjEtzca3BP4G+B/g/4Bnsn0uH3+r19Im7/Gi7DObDdwNPE763jwAXA/8NbDlYPdLYFK239wJrM72pZ9l6xtd8vPbOit/bbZPPpG97gauBmYCY9us4xDS9/aOLIYngXuB/wReVyKGUcDJwPcZ+F48kQ3fCswC3gRs3Ynvxwbv342VdvuV3+mGuPzo7Iuzrs0O/Qtglxbr+X3JL8Y/Fiw/t+Ty57b6Mgzmi9Pis5wLHJDtvI3vf3nDMn3Zl6RVzE8B7+ngtp5bMP/yXJk9ga+3iGkpsHu23AuBJS3KXgWo4D1n5MrNAM5usy/Non3l4BPA2jaf6VxgpxbrWJr7P/cg/TA0W8eMNu/TNKED7yi53BJgr7L7JXAk6Qe1aH03Alu0+fyOJP2ItovtsoLltwH+o8Ty1wLbFaxjHPDLkp/RMZ3Kh/nXsG9DHyxJIqvxZJNWkDbkr0g1g92B40hJaypwk6SDIuLxJqvbilSz/69s+ftJNfQJpOT4NmBz4COSHoyILzQs/3ekneDTpKMFaH6S985B/6ODtxOpRjkRmAP8gFRDn0DaAQGQdAjwQ1JtCOAmUm34PlKN8BDSF39r4GJJT0XE5ZsgfoB/At5COkr4Oql2uwvwV8CLSdv2a5Kmk7bZBFLN64fAStI2ex/py/1WUiK5pM17HgNMJ+07/0aq4Y8CDiN9DqOz938M+FCzFUj6DOlHAdIPw5XAj0g1u5cA7wL+jHQl1I8kHRwRT7SIaQtSjXQfUu38O6SjlfHZen5E2s9eDbw/W+bCbHpe4z6/NWlfWAD8BFhMSsRjGfjevID0w3qdpP0j4k8t4oR0pc2HAQH/CvycVBnoIx0pbQMcAXwMOKfZCiS9jXR0NCqbdFv2P99FOirZDXgZ8NrsfRqX34K0DxycTbqXlBMWZbE8n7QtXwi8DrhG0hER8UzDqr4KHJQNL8nW8TvSdhybLX8Y8NI2n8nQdeNXotsvcr90Q1j29Nzy36XgEAz4h1y5f2pRKyg8HCTt5L/N1vEYxb/sc8v+P3Svhh6kGuJbW6xvOwZq8KsoaE4gfQHuyZUb14FtPbdg/uUN/8PFNNSGST+8v86VmU9KVq9usr7DSEkggDsK3nNGw3veD0xpUu7gbLsHKVEf1KTMIbn3WwUc1qTMc0g/FP3vd15BXEsb4vpAm882/3/MKLEt9gH2aDF/M9KPVv86P15iv4xsX2n2+U0lVZCCVHHaoJZOOhJZlfuMT6f4yGpHYFqT6RfkYvkKMKZJmc2BK3LlTm2YvzMDR2nzgG1afE67kx0pdvrV8RVuilfDztDudXluuS1JbYlBSrQbbLiG9/lJVvZR2rQLtljHq3KxnFRQZm5/mRLry38Zzt3Ysg2f1flt1vfBXNmT25R9da7sRzuwrecWzL88V+Y3FPzAAic0/K9ntnjPG3Pldmsyf0bDul7bYl2n5sr9R5P5V+fmv7fFenYnHQX0J/4dmpRZmlvX1SU+2/z/MWOo26jJem/O1rmkxH4ZwCtarOvrrcqRmrP65zdt2mwT666kWngAP2xTdnNSrT+A3zXMOzgXR8sf0m6+RtpVLq8l/ZICfCki1rQp//Xs71gGDscG62e54e4danXGhW3mn5z9fQD4RquCEfEj0mE+wF9sZFxl/WtErC2Y99Pc8DrS4X2R/8kN793mPRdFxA0t5l9KapYAeKOk/maB/kP9o7PRh0lNNk1FxD2kQ3hIzRDtPtN227Kb+vf5PSWNa1P2VxHx3y3m55uB1tsW2Wd5XDa6EvjMoKJM3kY6wQ/ppGyhiHia1EQHMEXS5NzsfPPUPlSkDm3o7W4sujc3/Irc8LaSjmmz7ITc8F6kmvR6JO1Mal/7C9IOtyMD7cuNJrZ5vyrdHxG/L5opaXtg32z0AVJyarfOVdnfvTY+vFJ+0WLe/+WGF0fEoyXL7tjmPW9qNTMi1kj6KfB60n6xN+lIAmA/Uns3pCOQdhWMG0lXFkGqHFxVUG4dqS26KyS9Bjie1F48idQUN6qg+ATSuZgit7R5u/tzw43bYl9SZQvgxxGxss26msnnhJ1L5IR8DHuRjoogtbcvB54LnJKdq/sq8MvYsK29a4Z9Qo/B3Vg0OTf8uUG+1QZfbEnHkWp625dcx9j2RSpzf5v5uzFw38IBpPMPZbVLip3ycNGMiHgq9wNUWC7zVG54yzZll5SIK1/muQwk9F1z039XYj35MrsWloKHI+LJEusblOxH/SoGd8TVbp9vleyh9bbIV5B+Wzqi9U3ODV8+yGWf3a8jYp2k95BOxo4hnch+F/AnST8nHfXdEBELhhhnKcM+oQ9S2cTbzJj8iKTDSGfW+5PcraQz5XeR2tzzO2J/8iuqxfSCVldNwMZ9dptvxLKDUbYm1MkaU7Ornxqtzg1vmxverqBMkVW54e0KS7XflkP1beA12fBK0rXWC0lHbI8z8Lkez0BTSLt9fmO2Rf7HYlVhqdY6lhMi4lpJU0mXYr6OtN/vAByVvf5B0u3AhyPi+o1430IjLaHnN/rkrF1yqM5lIJnPjIivNiskaZuNeI+N1clzJPnP7vKIeGcH1z2cFTWv5eX3gfznuLKgTJH8j8FQmheGLKvA9CfzXwNHRMSKgrKHbqKwHssNb1tYqrX+7bEW2KrFOZhSIuLXwLGStiPdbPYy0pVTLyMl+BcDcySdHBEtz0MNxUg7KZpvVhjyiQtJYxhoe5tflMwzuw/1fQrka/5jCksl7U5IDUZHPrsaev4gyyzPDT+QG55SYj35MssLS3XHa3LDHytK5plO7/NFluWGh3qepn+/Hk26hr4jImJlRFwfEedExDRSE9kF2WwB5+dPkHfKSEvoN+eGy/TSWGQnBo5u2vXk+NoS63v2sFPtzzT+KTf83DZlO3ZVTUQ8RLodGuBASbt1at3D3OGtZmY//v011tUMfIaQarr9P9DTJLVrmsq3Xf9yMEEWyDd3tNvv/iw3XLjPZ//vtI2IaTBuY6CW/qqsVjxYncoJLUXEwxHxQdI9EJCutivzIz4oIy2hz2HgJMw7JA21pplvN92zqFC2g32gxPryh+HtDr2XAP1XQ0wr+gGQtAPp6ptOuiL7uxlDu0SsjvaRdESL+TMYOHk2OyLW9c+IiKdId+RCOpqaUbSS7Af0hGx0NemKl401mP2u1D4PvJd0R2rXZZ9l/6Wc25H6IBqsKxn4Pn1A0i6diK2Fpbnhjjd5j6iEHhGrSX1mQGqumCOpr9Uykg6StN4VMdklb/+bjfZJ2uCXXdK2wLdIV4e0k79c8IBWBbNrYfuvzd0dOK3Je/f3S9HJJhdInZD1n3c4UdIFWY2sKUljJf1NdplbnV0qaYMkl50gOy8bfYaBQ+688xioKX++WfuzpB1JJyT7k+5Xov0t9WWU3u9Idz/2Oye7hn49kt5A6n5hU/osAz9MZ0k6vVUlR9Ir89Mi4j4GrtnfCbhBUmEzmpLDJX2sYfprs/cuPMmarbf/x38VXXhOw0g7KUpEfFnSQaTa6yTgl5KuJ11PvIx06DmO1IfG4aTayF3AmQ2ruhD4Ujb8bUnfIF2atJJ04mMGqUnka7SvKd9E6hUP4N8kXUBKnP21uSURkb/07Z9J3Q4AfFHSwcANpJrGPtl7TyTVPo5v896lRcTq7Drdm0lXGJwBvE3SVQwc/m5Huh17Kuku2S0YuCGpjq4h9eeyUFKzvlz6m1EuiIh5jQtHxC2SPkuqXW4H3CzpPxjoy+XFwLsZaPK4jYI+TYbgN8CDpMP/kyStIF0X3n+VzBMR0d8k8V1Se/ME0ra9I/t/7yZdyXE08AZSTf5qUo+CXRcRv5d0CqkCsxnwBeBdkr7NQOdrE0hdLBxFqmTd3LCaj5D6lDmcdG37HZK+R7pT/A+kbfhnpPsGjiB9r28idQ/Sb9fsvT8n6cekeyL6e6McR7pm/20M/Ch/IVr3xzM0Vd2iujEvcrcND3F5kTrGejK/rhavuQXraNWzX5C+7Fu1Wk+2rlHAf7dYz7lNlvlEi/LPkK7CmdZqHQ2fZdPYCpZ5IekyzTKf3ZPAkR3Y1kWf3eW5MpM3Zl25cjNyZWe0mw+cReveFi+hfW+Ln6SDvS0O4vOd2eL9ljaUPZjUp0pR+UdIif3c3LRpTd6z7X452LKkG7dWlNgfLy1YfgypktZuG/S/rmhYvmxPlM+QEn/L/WGorxHV5NIvkk+TapLnkH6x/0Cq4T5Jqqn/EPgUcEiks9TN1nES8Hbgx6STlWuyZa8FjouIY6LEr3CktsAjSD3u/Zz0xVjXZpmPk064Xkvakfvf+z9JHTyd2+59hyoiFgMHknoZvIJ0w8tjWcx/Ip3s+xop2e0aXbrmtldExGdJNfIrSXcmryFtk2uBoyPi3dHmbsGIOIdUO7yQdOJ0JemE6TLSzSpvjohpEdHupqjBxj6LdLR3TfZeT7Uoewuplvpl0lHrGtI9F7eTmj72i4g5nYyvrIi4Fngeqb+hm0h3+z5NOtq4i9Rk9U4GepdsXH5NRLyf1N/7P5Fq2CtICf5xUvPUHOCjwL4R8ZcNq/h30mfzQVKvpUtI5zrWkT6jhaTP7cCIOKPd/jBUyn5dzKwkSTOAy7LRd8am6x7YrKURWUM3M6sjJ3Qzs5pwQjczqwkndDOzmnBCNzOricquchk3blxMnjy5kvc2MxuuFixY8FBENO1eobI7RSdPnsz8+fPbFzQzs2dJKuz2200uZmY14YRuZlYTTuhmZjXhhG5mVhNO6GZmNeGEbmZWE07oZmY14YRuZlYTw/MRdM0fGWid4P7xzYYt19DNzGqiVEKXdKSkxZKWSDq7oMw0SQslLZLU+BBWMzPrsrZNLpJGAReRnnm5DJgnaXZE3JErswPwL6SHAd8raecuxWtmZgXK1NCnAksi4u6IWEN6EO70hjJvB66OiHsBIuLBzoZpZmbtlEnoE4D7cuPLsml5LwB2lDRX0gJJ72i2IkkzJc2XNH/FihVDi9jMzJoqk9CbXVLSeCnEaOBA4HXAa4G/l/SCDRaKmBURfRHRN3580+58zcxsiMpctrgM2C03PhFY3qTMQxGxGlgt6SfAfsDvOhKlmZm1VaaGPg+YImkPSWOA44HZDWW+B7xC0mhJWwMvBX7b2VDNzKyVtjX0iFgr6TTgBmAUcGlELJJ0ajb/4oj4raTrgduAZ4BLIuL2bgZuZmbrq+yZon19fTHkR9D5TtHu8Z2iZj1N0oKI6Gs2z3eKmpnVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTZRK6JKOlLRY0hJJZzeZP03So5IWZq9zOh+qmZm1MrpdAUmjgIuAI4BlwDxJsyPijoai/x0Rr+9CjGZmVkKZGvpUYElE3B0Ra4ArgendDcvMzAarTEKfANyXG1+WTWt0iKRfS7pO0j4dic7MzEpr2+QCqMm0aBi/Fdg9IlZJOhq4BpiywYqkmcBMgEmTJg0uUjMza6lMDX0ZsFtufCKwPF8gIh6LiFXZ8Bxgc0njGlcUEbMioi8i+saPH78RYZuZWaMyCX0eMEXSHpLGAMcDs/MFJO0iSdnw1Gy9D3c6WDMzK9a2ySUi1ko6DbgBGAVcGhGLJJ2azb8YeAvwXklrgSeA4yOisVnGzMy6SFXl3b6+vpg/f/7QFlazZn3rCP8Om/U0SQsioq/ZPN8pamZWE07oZmY14YRuZlYTTuhmZjXhhG5mVhNO6GZmNeGEbmZWE07oZmY14YRuZlYTTuhmZjXhhG5mVhNO6GZmNeGEbmZWE07oZmY14YRuZlYTTuhmZjXhhG5mVhNO6GZmNeGEbmZWE07oZmY14YRuZlYTTuhmZjXhhG5mVhNO6GZmNeGEbmZWE6USuqQjJS2WtETS2S3KHSRpnaS3dC5EMzMro21ClzQKuAg4CtgbOEHS3gXlPgvc0OkgzcysvTI19KnAkoi4OyLWAFcC05uUez/wHeDBDsZnZmYllUnoE4D7cuPLsmnPkjQBOBa4uNWKJM2UNF/S/BUrVgw2VjMza6FMQleTadEw/gXgrIhY12pFETErIvoiom/8+PElQzQzszJGlyizDNgtNz4RWN5Qpg+4UhLAOOBoSWsj4ppOBGlmZu2VSejzgCmS9gDuB44H3p4vEBF79A9Luhy41snczGzTapvQI2KtpNNIV6+MAi6NiEWSTs3mt2w3NzOzTaNMDZ2ImAPMaZjWNJFHxIyND8vMzAbLd4qamdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdVEqYQu6UhJiyUtkXR2k/nTJd0maaGk+ZJe3vlQzcysldHtCkgaBVwEHAEsA+ZJmh0Rd+SK3QTMjoiQtC9wFfCibgRsZmbNlamhTwWWRMTdEbEGuBKYni8QEasiIrLRbYDAzMw2qTIJfQJwX258WTZtPZKOlXQn8APgXc1WJGlm1iQzf8WKFUOJ18zMCpRJ6GoybYMaeER8NyJeBBwDfKrZiiJiVkT0RUTf+PHjBxWomZm1ViahLwN2y41PBJYXFY6InwB7Shq3kbGZmdkglEno84ApkvaQNAY4HpidLyDp+ZKUDR8AjAEe7nSwZmZWrO1VLhGxVtJpwA3AKODSiFgk6dRs/sXAm4F3SHoaeAI4LneS1MzMNgFVlXf7+vpi/vz5Q1tYzZr1rSP8O2zW0yQtiIi+ZvN8p6iZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdVE294WzTrCHap1jztUs4xr6GZmNeGEbmZWE07oZmY14YRuZlYTTuhmZjXhhG5mVhNO6GZmNeGEbmZWE07oZmY14YRuZlYTTuhmZjVRKqFLOlLSYklLJJ3dZP6Jkm7LXj+TtF/nQzUzs1baJnRJo4CLgKOAvYETJO3dUOz3wCsjYl/gU8CsTgdqZmatlamhTwWWRMTdEbEGuBKYni8QET+LiEey0VuAiZ0N08zM2imT0CcA9+XGl2XTipwCXLcxQZmZ2eCV6Q+9WUfWTTtglvQqUkJ/ecH8mcBMgEmTJpUM0czMyihTQ18G7JYbnwgsbywkaV/gEmB6RDzcbEURMSsi+iKib/z48UOJ18zMCpRJ6POAKZL2kDQGOB6YnS8gaRJwNXByRPyu82GamVk7bZtcImKtpNOAG4BRwKURsUjSqdn8i4FzgJ2Af1F61NjaiOjrXthmZtZIUdHzCPv6+mL+/PlDW9jPp+yebu0P3mbd42eKjiiSFhRVmH2nqJlZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTTihm5nVhBO6mVlNOKGbmdWEE7qZWU04oZuZ1YQTuplZTZRK6JKOlLRY0hJJZzeZ/yJJP5f0lKQPdT5MMzNrZ3S7ApJGARcBRwDLgHmSZkfEHblifwT+BjimG0GamVl7ZWroU4ElEXF3RKwBrgSm5wtExIMRMQ94ugsxmplZCWUS+gTgvtz4smzaoEmaKWm+pPkrVqwYyirMzKxAmYSuJtNiKG8WEbMioi8i+saPHz+UVZiZWYEyCX0ZsFtufCKwvDvhmJnZUJVJ6POAKZL2kDQGOB6Y3d2wzMxssNpe5RIRayWdBtwAjAIujYhFkk7N5l8saRdgPjAWeEbSGcDeEfFY90I3M7O8tgkdICLmAHMapl2cG/4DqSnGzOpCzU6fWUfEkE5DtuU7Rc3MasIJ3cysJpzQzcxqwgndzKwmnNDNzGrCCd3MrCac0M3MasIJ3cysJpzQzcxqwgndzKwmnNDNzGrCCd3MrCac0M3MasIJ3cysJpzQzcxqwgndzKwmnNDNzGrCCd3MrCac0M3MasIJ3cysJpzQzcxqwgndzKwmnNDNzGrCCd3MrCac0M3MaqJUQpd0pKTFkpZIOrvJfEn6Ujb/NkkHdD5UMzNrpW1ClzQKuAg4CtgbOEHS3g3FjgKmZK+ZwFc6HKeZmbVRpoY+FVgSEXdHxBrgSmB6Q5npwNciuQXYQdKuHY7VzMxaGF2izATgvtz4MuClJcpMAB7IF5I0k1SDB1glafGgoh2+xgEPVR1EKVLVEfQKb7PhZfhsL9jYbbZ70YwyCb3ZO8cQyhARs4BZJd6zViTNj4i+quOw8rzNhhdvr6RMk8syYLfc+ERg+RDKmJlZF5VJ6POAKZL2kDQGOB6Y3VBmNvCO7GqXg4FHI+KBxhWZmVn3tG1yiYi1kk4DbgBGAZdGxCJJp2bzLwbmAEcDS4DHgXd2L+RhacQ1M9WAt9nw4u0FKGKDpm4zMxuGfKeomVlNOKGbmdWEE7qZWU04oZuZ1USZG4tskCQdApwEvALYFXgCuB34AfD1iHi0wvCsgKQ+0jZ7LgPb7IcR8cdKA7OmvL025Bp6h0m6Dng36TLPI0kJfW/g74Atge9JemN1EVojSTMk3Qp8BNgKWAw8CLwc+C9JV0iaVGWMNsDbq5hr6J13ckQ09imxCrg1e31e0rhNH5a1sA1waEQ80WympP1JPYneuymDskLeXgV8HbqZWU24ht4lklYy0EHZGGBzYHVEjK0uKmtF0mU071TuXRWEY214e23ICb1LImK7/LikY0h9y1vvujY3vCVwLO5krpd5ezVwk8smJOmWiDi46jisHEmbka6aeHXVsVh73l6uoXeNpDflRjcD+mhyeGg9bQowIq+WGKZG/PZyQu+eN+SG1wJL2fDRfdZDGs57APwBOKuicKwNb68NucmlSyQdGhE/bTfNzKxTfGNR91xYcpr1CEk3lZlmvcHba0Nucumw7Lb/lwHjJX0wN2ss6QEh1mMkbQlsDYyTtCMDz8gdS7qt3HqIt1cxJ/TOGwNsS/ps85cuPga8pZKIrJ33AGeQksECBhLEY8BFFcVkxby9CrgNvUsk7R4R91Qdh5Un6f0R4WaxYcLba0NO6B2W9dPyPuAR4FLgPFKPcHcBfxsRSyoMzwpI2p10J+9D2YPOXw4siYhrqo3MmvH2as4JvcMk3QjMJzW3HA5cBnyflNRPjIhp1UVnzUg6B/hL0iVwVwKvAeYCLwV+HRFnVBacbcDbq5gTeodJ+nVE7CdJwD0RMSk3b2FE7F9ddNaMpDuA/Ukn2u4FdomIxyWNBhZGxIurjM/W5+1VzCdFO28dQESEpMZudJ+pIB5r78mIWAOskXRXRDwOEBFrJa2pODbbkLdXASf0znuepNmkM+/9w2Tje1QXlrWwQ9ZVg4CxuW4bBGxfXVhWwNurgJtcOkzSK1vNj4ibN1UsVk7WDWuhiHjnporF2vP2KuaE3iWSDoyIBQ3T3hAR368qJmtN0hYR8VTDtOeM5GdU9jJvrw351v/u+aqkl/SPSDqB9FxR611XZyfWAJC0C/BfFcZjrXl7NXBC7563AFdI2kvSXwF/DfxFxTFZa9cA35Y0StJk4EbSg4itN12Dt9d63OTSRZJeQNrp7gOOKXqorfUOSe8DjgQmA++JiJ9VG5G14u21Pif0DpP0G9bvo3ln4FHgKYCI2LeKuKxYQydqAk4GfgP8CiAizq8iLmvO26uYL1vsvNdXHYAN2nYN498tmG69wdurgGvoHSZp24hYtbFlzMwGyydFO+97kj4v6TBJ2/RPlPQ8SadIuoHU5mc9QtIsSU1vF5e0jaR3STpxU8dlzXl7FXMNvQskHQ2cCBwK7Eh6puhi4AfAv0XEHyoMzxpI2h/4KPAS4HZgBbAl6aHDY0m9Zl7ceM2zVcPbq5gTullG0rZAH7Ar8ATw24hYXG1UVsTba0NO6F0i6VBSz2+rJZ0EHAB80Q+96F2SXg/MiQh3ojZMSNoKmDTSE3k/t6F3z1eAxyXtB5wJ3AN8rdqQrI3jgf+V9DlJe1UdjLUm6Y3AQuD6bHz/XGd4I5ITevesjXT4M51UM/8ivqyqp0XEScCfk54udZmkn0uaKcnbrTd9HJgK/AkgIhaSbjAasZzQu2elpI8AJwE/kDQK2LzimKyNiHgM+A7pSTi7AscCt0p6f6WBWTNrI+LRqoPoJU7o3XMc6e7QU7KrWiaQni9qPUrSGyV9F/gR6cd3akQcBewHfKjS4KyZ2yW9HRglaYqkCwHf+m9mIOlrwCUR8ZMm8w6PiJsqCMsKSNoa+Bip0zsBNwCfiognKw2sQk7oXZI9ifxCYC9gDDAKWBURI/qJKr1M0mcj4qx206z3ZE2a22RNZiOWm1y658vACcD/AlsB7wYuqjQia+eIJtOO2uRRWCmSvilpbHZH9iJgsaQPVx1XlZzQuygilgCjImJdRFwGTKs4JGtC0nuzXjJfJOm23Ov3wG1Vx2eF9s5q5McAc4BJpJ4XRyz3ttg9j0saAyyU9DngAWCbNstYNb4JXAd8Bjg7N33lSH6c2TCwuaTNSQn9yxHxtKQR3YbsGnr3nEz6fE8DVgO7AW+uNCIrEhGxFHgfsDL3QtJzKozLWvtXYCmpovQTSbsDI7oN3SdFbcSTdG1EvD5rYgnSFRP9IiKeV1FoNgiSRGriXFt1LFVxQu8wSdOBiRFxUTb+C2B8NvvMiPh2ZcGZ1UDDE4sg/Qg/BPxPRPy+gpB6hptcOu9MIN+fxBbAQaQTou+tIiArR9KxkrbPje8g6ZgKQ7Lmtmt4jSX1unidpOOrDKxqrqF3mKR5EXFQbvzLEXFaNnxLRBxcXXTWiqSFEbF/w7RfRcSfVxSSDUJ2vuOHEXFA1bFUxTX0ztsxP9KfzDPjsV7W7PvgK8GGieyKJLUtWGNO6J33C0l/1ThR0nuAX1YQj5U3X9L5kvbMHhl4AbCg6qCsHEmvBh6pOo4qucmlwyTtDFxD6pjr1mzygaS29GMi4v8qCs3ayO44/HvgNaSa3o3ApyNidaWB2Xqym8AaE9dzgOXAX0bEbzd9VL3BCb1LstrCPtnoooj4UZXxmNVFdr15XgAP+4fXCb3j2t2I4jsPe4+kL0TEGZK+z4Y1PyLijRWEZSVI2pF0096z5zoi4tbiJerNJ3w6bwEDN6f0J4f+EzUB+CaV3vPv2d9/rjQKGxRJnwJmkJ4w1f9dC+DVVcVUNdfQzXi2+9UrssfQ2TAgaTHwkohYU3UsvcI19C7KDgenAFv2T2v28ASrXkSskzRe0hgniGHjdmAH4MGK4+gZTuhdIundwOnARNKTyQ8Gfs4IPhwcBpYCP82eHP/sCbaIOL+yiKyVzwC/knQ76aoyYGSf83BC757TSbf83xIRr5L0IuATFcdkrS3PXpuRbimHJidJrWdcAXwW+A3wTMWx9AQn9O55MiKelISkLSLiTkkvrDooa+mOiPhWfoKkt1YVjLX1UER8qeogeolPinZJ9vT4dwJnkJpZHgE2j4ijq4zLikm6tbEfkGbTrDdIOp/U1DKb9ZtcRuxli07om4CkVwLbA9f7hFvvkXQUcDTwNuA/c7PGkh5zNrWSwKwlST9uMjkiYsSep3JC7wJJmwG3RcSLq47F2pO0H7A/8EngnNyslcCPI2JE9w9iw4cTepdI+gbwkYi4t+pYrBxJY4HVEbEuGx8FbBERj1cbmRWR9DpSFxv5S4M/WV1E1fJJ0e7ZFVgk6ZesfwnciL2kahi4kdQx16psfKts2ssqi8gKSboY2Bp4FXAJ8BZGeI+mTujd40sUh58tI6I/mRMRqyRtXWVA1tLLImJfSbdFxCckfR64uuqgquSE3iURcXPVMdigrZZ0QP9VEpIOBJ6oOCYr1r9tHpf0XOBhYI8K46mcE3qXSFrJwE0pY4DNSe2zY6uLyto4A/iWpOXZ+K7AcdWFY21cK2kH4DzSsweC1PQyYvmk6CaSPWx4akR8tOpYrJikzYEXknrIvDMinq44JCtB0hakJrNHq46lSn4E3SYSEdfgflx6WtZefhZwekT8Bpgs6fUVh2UFJG0t6e8lfTUingJ2Hunby00uXSLpTbnRzYA+3C9Ir7uM1J/9Idn4MuBbwLWVRWSteHs1cELvnjfkhteSevKbXk0oVtKeEXGcpBMAIuIJSSP6KfI9zturgRN691wSET/NT5B0KO67uZetkbQV2ZGUpD3J9RFiPcfbq4Hb0LvnwpLTrHd8HLge2C270/cm4MxqQ7IWzmXD7XVWpRFVzFe5dJikQ0h3Fp4BXJCbNRY4NiL2qyIuK0fSTqSHkYjUl/1DFYdkLXh7rc9NLp03BtiW9Nlul5v+GOnWZOsxkhq7x30g+ztJ0qSR3B1rL5N0U0QcDvygybQRyTX0LpG0e0TcU3Uc1l5BN6z9RnR3rL1I0pakPlx+DEwj1c4hHQVfFxF7VRRa5VxD757HJZ3Hhj3BOTn0mIh4VdUx2KC8h9Sk+VzSZYv9VgIXVRFQr/BJ0e75BnAnqW+JT5AuW5xXZUDWnKQzc8NvbZj3j5s+ImvjZ6TzVB+KiOeRvl+3AzcD36wysKq5yaVLJC2IiAOznuD2zabdHBGvrDo2W1/+MXONj5zzI+h6j6RbgddExB8lHQZcCbyf9JCSvSJixJ6rcpNL9/T3AfJA1gn/cmBihfFYMRUMNxu36o2KiD9mw8cBsyLiO8B3JC2sLqzqOaF3z6clbQ/8Len687HAB6oNyQpEwXCzcaveKEmjI2ItcDgwMzdvROc0N7nYiCdpHempUiI9paj/kXMi9eC3eVWx2YYkfYz0UO+HgEnAARERkp4PXBERh1YaYIWc0DtM0jktZkdEfGqTBWNWU5IOJvVXf2NErM6mvQDYdiTfN+CE3mGS/rbJ5G2AU4CdImLbTRySmY0QTuhdJGk74HRSMr8K+HxEuHMuM+uKEX0CoVskPQf4IHAicAWpje+RaqMys7pzQu+w7O7QNwGzgJfknyJvZtZNbnLpMEnPkPpkXsv6l7yJdFLUD4k2s65wQjczqwn35WJmVhNO6GZmNeGEbmZWE07oZmY14YRuZlYT/w/E51qoAxi2rQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='red')\n",
    "plt.title('Feature importances', size=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8307dca",
   "metadata": {},
   "source": [
    "## <a name=\"C34\"> 3.4) MLP </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9d5e48",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle\n",
    "#### modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8851838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1380827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = MLPRegressor()\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,), (20,), (30,), (50,), (100,)],\n",
    "    'activation': ['relu', 'logistic', 'tanh'],\n",
    "    'solver': ['lbfgs', 'adam', 'sgd']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14f87774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "mlp = GridSearchCV(estimator=rp, param_grid = param_grid, cv=5, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138a0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimiser sur le jeu d'entraînement\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# résultats de la validation croisée\n",
    "res = mlp.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2297c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(mlp.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf597809",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_r2 = mlp.best_score_\n",
    "print(\"Best score: \", mlp.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6de7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = mlp.predict(X_train)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "print(\"Score du training set : \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e2f45",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee33ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5952a",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c42aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4e598",
   "metadata": {},
   "source": [
    "#### Les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaeb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    'mse':mse,\n",
    "    'rse' :rse,\n",
    "    'R²' : r2\n",
    "}\n",
    "df_mlp  = pd.DataFrame(scores, index = ['MLP'])\n",
    "df_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6899ded",
   "metadata": {},
   "source": [
    "### c.) Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f540eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire le meilleur estimator de GridSearchCV object\n",
    "best_mlp = mlp.best_estimator_\n",
    "\n",
    "# Calculate feature importances\n",
    "coefs = np.abs(best_mlp.coefs_[0])\n",
    "feature_importances = np.sum(coefs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les importances de caractéristiques\n",
    "feat_imp = feature_importances\n",
    "\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance':feat_imp\n",
    "})\n",
    "# Trier la dataframe obtenué\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b40951",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = importances.iloc[:3]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ec825",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='red')\n",
    "plt.title('Feature importances ', size=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83401c3",
   "metadata": {},
   "source": [
    "## <a name=\"C35\"> 3.5) XGBoost </a>\n",
    "#### Installation de XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ebe65",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle\n",
    "#### modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du modèle\n",
    "rp = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [1,2,3,4,5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3fbddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "gb = GridSearchCV(estimator=rp, param_grid = param_grid, cv=5, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a862d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimiser sur le jeu d'entraînement\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a5667f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# résultats de la validation croisée\n",
    "res = gb.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(gb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_r2 = gb.best_score_\n",
    "print(\"Best score: \", gb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e130ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gb.predict(X_train)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "print(\"Score du training set : \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fa1fc",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c89243",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b099f93",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9959c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9db85c",
   "metadata": {},
   "source": [
    "### Les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f858b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    'mse':mse,\n",
    "    'rse' :rse,\n",
    "    'R²' : r2\n",
    "}\n",
    "df_gb  = pd.DataFrame(scores, index = ['XGBoost'])\n",
    "df_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ed7d3",
   "metadata": {},
   "source": [
    "### c.) Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9de4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les importances de caractéristiques\n",
    "feat_imp = gb.best_estimator_.feature_importances_\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance':feat_imp\n",
    "})\n",
    "# Trier la dataframe obtenué\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = importances.iloc[:3]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7030cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='red')\n",
    "plt.title('Feature importances ', size=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea273f0",
   "metadata": {},
   "source": [
    "# <a name=\"C4\"> CHOIX DU MODELE </a>\n",
    "## <a name=\"C41\"> 4.1) Tableau récapitulatif des scores du modèle </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebeb23a",
   "metadata": {},
   "source": [
    "#### best scores issus du GridSearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40834af",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    'linear reg':lr_r2,\n",
    "    'RandomForest':rfr_r2,\n",
    "    'grd boosting' : gbr_r2,\n",
    "    'mlp' : mlp_r2,\n",
    "    'XGB' :gb_r2\n",
    "}\n",
    "R2  = pd.DataFrame(scores, index = ['R²'])\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b23ea8",
   "metadata": {},
   "source": [
    "Comme, nous pouvons le constater dans le tableau le modèle présentant le meilleur score est celui de : **Gradiant Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe4187",
   "metadata": {},
   "source": [
    "#### Tableau compilatif des scores du testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8fc51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF1 = pd.concat([df_lr,df_gr,df_rfr,df_mlp,df_gb])\n",
    "DF1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e993c221",
   "metadata": {},
   "source": [
    "## <a name=\"C42\"> 4.2) Modèle Gradiant Boosting avec la librairie LIME </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1675c25",
   "metadata": {},
   "source": [
    "#### Installation de la librairie LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d5dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install lime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877b689",
   "metadata": {},
   "source": [
    "#### Feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c844f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff38c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Création d'un explainer LIME\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X.columns.values, discretize_continuous=True, mode='regression')\n",
    "\n",
    "# Calcul de l'importance des fonctionnalités pour les instances de test\n",
    "for i in range(5):\n",
    "    exp = explainer.explain_instance(X_test.values[i], gbr.predict, num_features=5)\n",
    "    print('Instance {}:'.format(i))\n",
    "    print('True value: {}'.format(y_test.values[i]))\n",
    "    print('Predicted value: {}'.format(gbr.predict(X_test.values[i].reshape(1, -1))[0]))\n",
    "    print('Explanation: \\n{}'.format(exp.as_list()))\n",
    "# Visualisation de l'importance des fonctionnalités\n",
    "    fig = exp.as_pyplot_figure()\n",
    "    fig.suptitle('Feature importance {}'.format(i))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0c3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e21775dd",
   "metadata": {},
   "source": [
    "# <a name=\"C5\"> MODELISATION SANS \"ENERGYSTARScore\"</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e13bd0",
   "metadata": {},
   "source": [
    "#### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed926c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns= [\"Target_Energies\",\"Target_GES\",\"ENERGYSTARScore\",\"GHGEmissionsIntensity\"])\n",
    "y = data['Target_GES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781bc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=5, shuffle=True)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45218388",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac2c2d",
   "metadata": {},
   "source": [
    "## <a name=\"C51\"> 5.1) Regression linéaire </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb14cef",
   "metadata": {},
   "source": [
    "\n",
    "###  a.) Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2026b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'normalize': False}\n",
    "# initialisation du modèle\n",
    "lr = LinearRegression()\n",
    "# Adapter les données (entraînement du modèle)\n",
    "lr.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9189e",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b62ec90",
   "metadata": {},
   "source": [
    "####  Evaluation du training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc579db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse = mean_squared_error(y_train, y_train_pred)\n",
    "mse = (np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_lr_train  = pd.DataFrame(scores, index = ['Training set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990129d",
   "metadata": {},
   "source": [
    "####  Evaluation du testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'erreur quadratique moyenne\n",
    "mse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "# Le score R²\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "# l'erreur carré relative\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_lr  = pd.DataFrame(scores, index = ['Régression Linéaire'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dab2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_lr_train,df_lr])\n",
    "print(\"REGRESSION LINEAIRE :\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72691ad8",
   "metadata": {},
   "source": [
    "## <a name=\"C52\"> 5.2) Forêt Aléatoire </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6491fd1",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef5703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du modèle\n",
    "rfr = model_class(random_state=42, max_depth= 5, n_estimators= 100)\n",
    "# Adapter les données (entraînement du modèle)\n",
    "rfr.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "y_train_pred = rfr.predict(X_train)\n",
    "y_test_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95212c14",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle\n",
    "####  Evaluation du training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train,y_train_pred )\n",
    "mse = mean_squared_error(y_train, y_train_pred )\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_rfr_train  = pd.DataFrame(scores, index = ['Training set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535a1f1",
   "metadata": {},
   "source": [
    "####  Evaluation du testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2230085",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_rfr = pd.DataFrame(scores, index = ['Forêt Aléatoire'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83711ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_rfr_train,df_rfr])\n",
    "print(\"FORÊT ALEATOIRE :\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11676a6f",
   "metadata": {},
   "source": [
    "## <a name=\"C53\"> 5.3) Gradient Boosting  </a>\n",
    "###  a.) Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ea656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Hyperparameters for GradientBoostingRegressor\n",
    "gbr_params = {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 300}\n",
    "\n",
    "gbr = GradientBoostingRegressor(**gbr_params,random_state=0)\n",
    "gbr.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "y_train_pred = gbr.predict(X_train)\n",
    "y_test_pred = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ee1ec",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle\n",
    "####  Evaluation du training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train,y_train_pred )\n",
    "mse = mean_squared_error(y_train, y_train_pred )\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_grb_train  = pd.DataFrame(scores, index = ['Training set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c50b9e",
   "metadata": {},
   "source": [
    "####  Evaluation du testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_grb = pd.DataFrame(scores, index = ['Gradient Boosting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_grb_train,df_grb])\n",
    "print(\"GRADIENT BOOSTING  :\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae287ee",
   "metadata": {},
   "source": [
    "## <a name=\"C54\"> 5.4) MLP </a>\n",
    "###  a.) Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(activation = 'relu', hidden_layer_sizes= (30,), solver ='lbfgs')\n",
    "mlp.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "y_test_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd14632",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle\n",
    "####  Evaluation du training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train,y_train_pred )\n",
    "mse = mean_squared_error(y_train, y_train_pred )\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_mlp_train  = pd.DataFrame(scores, index = ['Training set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f3c38",
   "metadata": {},
   "source": [
    "####  Evaluation du testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98619c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_mlp = pd.DataFrame(scores, index = ['MLP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8721d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_mlp_train, df_mlp])\n",
    "print(\"MLP :\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1994d",
   "metadata": {},
   "source": [
    "## <a name=\"C55\"> 5.5) XGBoost </a>\n",
    "###  a.) Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = xgb.XGBRegressor(learning_rate= 0.2, max_depth=3, n_estimators= 300) \n",
    "gb.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "y_train_pred = gb.predict(X_train)\n",
    "y_test_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff1d7c",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle\n",
    "####  Evaluation du training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train,y_train_pred )\n",
    "mse = mean_squared_error(y_train, y_train_pred )\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_gb_train  = pd.DataFrame(scores, index = ['Training set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb42b1af",
   "metadata": {},
   "source": [
    "####  Evaluation du testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_gb = pd.DataFrame(scores, index = ['XGBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ec350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_gb_train, df_gb])\n",
    "print(\"XGBOOST :\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69112246",
   "metadata": {},
   "source": [
    "## Tableau récapitulatif des scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e752d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2 = pd.concat([df_lr,df_grb,df_rfr,df_mlp,df_gb])\n",
    "DF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703640ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2 = DF2.drop(columns=[\"mse\",\"rse\"])\n",
    "DF2 = DF2.transpose()\n",
    "\n",
    "DF1 = DF1.drop(columns=[\"mse\",\"rse\"])\n",
    "DF1 = DF1.transpose()\n",
    "\n",
    "DF = pd.concat([DF1,DF2])\n",
    "DF.index = [\"R²(avec ENERGYSTARScore)\",\"R²(Sans ENERGYSTARScore)\"]\n",
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c59342",
   "metadata": {},
   "source": [
    "Nous ne constatons pas de changement notable du R²."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f5497",
   "metadata": {},
   "source": [
    "# <a name=\"C6\"> CONCLUSION </a>\n",
    "\n",
    "Le meilleur modèle pour la prédiction de la consommation de l'énergie est l'algorithme Gradiant Boosting.\n",
    "\n",
    "La suppression de la variable \"ENERGYSTARScore\" n'a pas d'impact majeur sur notre modèle.\n",
    "\n",
    "Les variables ayant le plus d'importance dans la prédiction de lénergie sont : \n",
    "\n",
    "   - **SiteEUI(kBtu/sf) (54%)**\n",
    " \n",
    "   - **Electricity(kBtu) (36%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26d102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
