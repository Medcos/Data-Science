{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203ad14c",
   "metadata": {},
   "source": [
    "# Sommaire :\n",
    " \n",
    " **<a href=\"#C1\">IMPORTATION </a>**\n",
    "  - <a href =\"#C11\"> Importation des libraries</a>\n",
    "  - <a href =\"#C12\"> Chargement des données</a>\n",
    "  \n",
    "**<a href=\"#C2\"> PREPARATION DE DONNEES </a>**\n",
    "  - <a href =\"#C21\"> 2.1)  Division des données en ensembles d'entraînement et de test</a>\n",
    "  -<a href =\"#C22\"> 2.2)  Création du caractère aléatoire et proportionnelle de la division </a>\n",
    "  \n",
    "**<a href=\"#C3\"> MODELISATION </a>**\n",
    "  - <a href =\"#C31\"> 3.1) Regression linéaire </a>\n",
    "  - <a href =\"#C32\"> 3.2) Forêt Aléatoire </a>\n",
    "  - <a href =\"#C33\"> 3.3) Gradient Boosting </a>\n",
    "  - <a href =\"#C34\"> 3.4) MLP </a>\n",
    "  - <a href =\"#C35\"> 3.5) XGBoost </a>\n",
    "\n",
    "**<a href=\"#C4\"> CHOIX DU MODELE </a>**\n",
    "  - <a href=\"#C41\"> 4.1) Tableau récapitulatif des score du modèle </a>\n",
    "  - <a href=\"#C42\"> 4.2) Modèle XGBoost avec la librairie LIME </a>\n",
    "  \n",
    "**<a href=\"#C5\"> MODELISATION SANS \"ENERGYSTARScore</a>**\n",
    "  - <a href =\"#C51\"> 5.1) Regression linéaire </a>\n",
    "  - <a href =\"#C52\"> 5.2) Forêt Aléatoire </a>\n",
    "  - <a href =\"#C53\"> 5.3) Gradient Boosting </a>\n",
    "  - <a href =\"#C54\"> 5.4) MLP </a>\n",
    "  - <a href =\"#C55\"> 5.5) XGBoost </a>\n",
    "  \n",
    "**<a href=\"#C6\"> CONCLUSION</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ef8091",
   "metadata": {},
   "source": [
    "# <a name=\"C1\"> IMPORTATION </a>\n",
    "## <a name=\"C11\"> Importation des libraries</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d055d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builtin\n",
    "import os\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9bf234",
   "metadata": {},
   "source": [
    "## <a name=\"C12\"> Chargement des données</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d572ebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CouncilDistrictCode</th>\n",
       "      <th>AgeBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighborhood_9</th>\n",
       "      <th>Neighborhood_10</th>\n",
       "      <th>Neighborhood_11</th>\n",
       "      <th>Neighborhood_12</th>\n",
       "      <th>Neighborhood_13</th>\n",
       "      <th>Neighborhood_14</th>\n",
       "      <th>Neighborhood_15</th>\n",
       "      <th>Neighborhood_16</th>\n",
       "      <th>Neighborhood_17</th>\n",
       "      <th>Neighborhood_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>11.390012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.390012</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.403054</td>\n",
       "      <td>5.206750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11.547964</td>\n",
       "      <td>9.620063</td>\n",
       "      <td>11.390780</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.551769</td>\n",
       "      <td>5.171052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>13.770628</td>\n",
       "      <td>12.189527</td>\n",
       "      <td>13.540273</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.564348</td>\n",
       "      <td>5.488524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>11.023861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.023861</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.707727</td>\n",
       "      <td>5.376204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>12.075850</td>\n",
       "      <td>11.034890</td>\n",
       "      <td>11.640263</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.743192</td>\n",
       "      <td>5.353752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CouncilDistrictCode  AgeBuilt  NumberofBuildings  NumberofFloors  \\\n",
       "0                    7        89                1.0              12   \n",
       "1                    7        20                1.0              11   \n",
       "2                    7        47                1.0              41   \n",
       "3                    7        90                1.0              10   \n",
       "4                    7        36                1.0              18   \n",
       "\n",
       "   PropertyGFATotal  PropertyGFAParking  PropertyGFABuilding(s)  \\\n",
       "0         11.390012            0.000000               11.390012   \n",
       "1         11.547964            9.620063               11.390780   \n",
       "2         13.770628           12.189527               13.540273   \n",
       "3         11.023861            0.000000               11.023861   \n",
       "4         12.075850           11.034890               11.640263   \n",
       "\n",
       "   ENERGYSTARScore  SiteEUI(kBtu/sf)  SourceEUI(kBtu/sf)  ...  Neighborhood_9  \\\n",
       "0             60.0          4.403054            5.206750  ...             0.0   \n",
       "1             61.0          4.551769            5.171052  ...             0.0   \n",
       "2             43.0          4.564348            5.488524  ...             0.0   \n",
       "3             56.0          4.707727            5.376204  ...             0.0   \n",
       "4             75.0          4.743192            5.353752  ...             0.0   \n",
       "\n",
       "   Neighborhood_10  Neighborhood_11  Neighborhood_12  Neighborhood_13  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   Neighborhood_14  Neighborhood_15  Neighborhood_16  Neighborhood_17  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   Neighborhood_18  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ohe_Data\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff518bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1663, 62)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be025ce6",
   "metadata": {},
   "source": [
    "# <a name=\"C2\"> PREPARATION DE DONNEES </a>\n",
    "## <a name=\"C21\"> 2.1) Division des données en ensembles d'entraînement et de test </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f0bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns= [\"Target_Energies\",\"Target_GES\",\"GHGEmissionsIntensity\"])\n",
    "y = data['Target_Energies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3dc1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CouncilDistrictCode</th>\n",
       "      <th>AgeBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighborhood_9</th>\n",
       "      <th>Neighborhood_10</th>\n",
       "      <th>Neighborhood_11</th>\n",
       "      <th>Neighborhood_12</th>\n",
       "      <th>Neighborhood_13</th>\n",
       "      <th>Neighborhood_14</th>\n",
       "      <th>Neighborhood_15</th>\n",
       "      <th>Neighborhood_16</th>\n",
       "      <th>Neighborhood_17</th>\n",
       "      <th>Neighborhood_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>11.390012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.390012</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.403054</td>\n",
       "      <td>5.206750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11.547964</td>\n",
       "      <td>9.620063</td>\n",
       "      <td>11.390780</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.551769</td>\n",
       "      <td>5.171052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>13.770628</td>\n",
       "      <td>12.189527</td>\n",
       "      <td>13.540273</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.564348</td>\n",
       "      <td>5.488524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>11.023861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.023861</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.707727</td>\n",
       "      <td>5.376204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>12.075850</td>\n",
       "      <td>11.034890</td>\n",
       "      <td>11.640263</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.743192</td>\n",
       "      <td>5.353752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CouncilDistrictCode  AgeBuilt  NumberofBuildings  NumberofFloors  \\\n",
       "0                    7        89                1.0              12   \n",
       "1                    7        20                1.0              11   \n",
       "2                    7        47                1.0              41   \n",
       "3                    7        90                1.0              10   \n",
       "4                    7        36                1.0              18   \n",
       "\n",
       "   PropertyGFATotal  PropertyGFAParking  PropertyGFABuilding(s)  \\\n",
       "0         11.390012            0.000000               11.390012   \n",
       "1         11.547964            9.620063               11.390780   \n",
       "2         13.770628           12.189527               13.540273   \n",
       "3         11.023861            0.000000               11.023861   \n",
       "4         12.075850           11.034890               11.640263   \n",
       "\n",
       "   ENERGYSTARScore  SiteEUI(kBtu/sf)  SourceEUI(kBtu/sf)  ...  Neighborhood_9  \\\n",
       "0             60.0          4.403054            5.206750  ...             0.0   \n",
       "1             61.0          4.551769            5.171052  ...             0.0   \n",
       "2             43.0          4.564348            5.488524  ...             0.0   \n",
       "3             56.0          4.707727            5.376204  ...             0.0   \n",
       "4             75.0          4.743192            5.353752  ...             0.0   \n",
       "\n",
       "   Neighborhood_10  Neighborhood_11  Neighborhood_12  Neighborhood_13  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   Neighborhood_14  Neighborhood_15  Neighborhood_16  Neighborhood_17  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   Neighborhood_18  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2a5e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15.793246\n",
       "1    15.942305\n",
       "2    18.100297\n",
       "3    15.731636\n",
       "4    16.466822\n",
       "Name: Target_Energies, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2f80b",
   "metadata": {},
   "source": [
    "## <a name=\"C22\"> 2.2) Création du caractère aléatoire et proportionnelle de la division </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df25a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc01b645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CouncilDistrictCode</th>\n",
       "      <th>AgeBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighborhood_9</th>\n",
       "      <th>Neighborhood_10</th>\n",
       "      <th>Neighborhood_11</th>\n",
       "      <th>Neighborhood_12</th>\n",
       "      <th>Neighborhood_13</th>\n",
       "      <th>Neighborhood_14</th>\n",
       "      <th>Neighborhood_15</th>\n",
       "      <th>Neighborhood_16</th>\n",
       "      <th>Neighborhood_17</th>\n",
       "      <th>Neighborhood_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.730794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.730794</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.765587</td>\n",
       "      <td>5.775483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.631712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.631712</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.523415</td>\n",
       "      <td>4.231204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11.602282</td>\n",
       "      <td>10.563595</td>\n",
       "      <td>11.165451</td>\n",
       "      <td>47.5</td>\n",
       "      <td>4.756173</td>\n",
       "      <td>5.839478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.098026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.098026</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.186051</td>\n",
       "      <td>3.328627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12.270375</td>\n",
       "      <td>11.654668</td>\n",
       "      <td>11.493284</td>\n",
       "      <td>83.0</td>\n",
       "      <td>3.981549</td>\n",
       "      <td>5.126342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CouncilDistrictCode  AgeBuilt  NumberofBuildings  NumberofFloors  \\\n",
       "1563                    3        20                0.0               3   \n",
       "1155                    2        55                1.0               1   \n",
       "243                     7        36                1.0               4   \n",
       "1223                    4        70                1.0               1   \n",
       "312                     7        20                2.0               5   \n",
       "\n",
       "      PropertyGFATotal  PropertyGFAParking  PropertyGFABuilding(s)  \\\n",
       "1563         10.730794            0.000000               10.730794   \n",
       "1155         10.631712            0.000000               10.631712   \n",
       "243          11.602282           10.563595               11.165451   \n",
       "1223         10.098026            0.000000               10.098026   \n",
       "312          12.270375           11.654668               11.493284   \n",
       "\n",
       "      ENERGYSTARScore  SiteEUI(kBtu/sf)  SourceEUI(kBtu/sf)  ...  \\\n",
       "1563             88.0          4.765587            5.775483  ...   \n",
       "1155             90.0          3.523415            4.231204  ...   \n",
       "243              47.5          4.756173            5.839478  ...   \n",
       "1223             53.0          2.186051            3.328627  ...   \n",
       "312              83.0          3.981549            5.126342  ...   \n",
       "\n",
       "      Neighborhood_9  Neighborhood_10  Neighborhood_11  Neighborhood_12  \\\n",
       "1563             0.0              0.0              0.0              0.0   \n",
       "1155             0.0              0.0              0.0              0.0   \n",
       "243              0.0              0.0              0.0              0.0   \n",
       "1223             0.0              0.0              0.0              0.0   \n",
       "312              0.0              0.0              1.0              0.0   \n",
       "\n",
       "      Neighborhood_13  Neighborhood_14  Neighborhood_15  Neighborhood_16  \\\n",
       "1563              0.0              0.0              0.0              0.0   \n",
       "1155              0.0              0.0              0.0              0.0   \n",
       "243               0.0              0.0              0.0              0.0   \n",
       "1223              1.0              0.0              0.0              0.0   \n",
       "312               0.0              0.0              0.0              0.0   \n",
       "\n",
       "      Neighborhood_17  Neighborhood_18  \n",
       "1563              0.0              0.0  \n",
       "1155              1.0              0.0  \n",
       "243               0.0              0.0  \n",
       "1223              0.0              0.0  \n",
       "312               0.0              0.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42, shuffle=True)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f769f13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448    14.154191\n",
       "168     19.495993\n",
       "220     17.538779\n",
       "1643    14.889072\n",
       "344     16.768602\n",
       "Name: Target_Energies, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b41ea",
   "metadata": {},
   "source": [
    "# <a name=\"C3\"> MODELISATION </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d889db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# calculer les scores R² et \n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af7b07",
   "metadata": {},
   "source": [
    "## <a name=\"C31\"> 3.1) Regression linéaire </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094cf4e",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle\n",
    "#### Le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a65584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7f09b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du modèle\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "parameters = {'normalize': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aec7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "lr = GridSearchCV(estimator=model, param_grid=parameters, cv=5, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1120b972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearRegression(),\n",
       "             param_grid={'normalize': [True, False]}, scoring='r2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiser sur le jeu d'entraînement\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad41d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_normalize</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010739</td>\n",
       "      <td>0.014944</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>True</td>\n",
       "      <td>{'normalize': True}</td>\n",
       "      <td>0.783062</td>\n",
       "      <td>-3.398844e+22</td>\n",
       "      <td>-1.153372e+23</td>\n",
       "      <td>-4.981058e+22</td>\n",
       "      <td>0.141806</td>\n",
       "      <td>-3.982723e+22</td>\n",
       "      <td>4.244508e+22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>False</td>\n",
       "      <td>{'normalize': False}</td>\n",
       "      <td>0.783201</td>\n",
       "      <td>7.265246e-01</td>\n",
       "      <td>7.699241e-01</td>\n",
       "      <td>8.529433e-01</td>\n",
       "      <td>0.141366</td>\n",
       "      <td>6.547918e-01</td>\n",
       "      <td>2.599078e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.010739      0.014944         0.009377        0.007833   \n",
       "1       0.004550      0.006187         0.004898        0.006367   \n",
       "\n",
       "  param_normalize                params  split0_test_score  split1_test_score  \\\n",
       "0            True   {'normalize': True}           0.783062      -3.398844e+22   \n",
       "1           False  {'normalize': False}           0.783201       7.265246e-01   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0      -1.153372e+23      -4.981058e+22           0.141806    -3.982723e+22   \n",
       "1       7.699241e-01       8.529433e-01           0.141366     6.547918e-01   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0    4.244508e+22                2  \n",
       "1    2.599078e-01                1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# résultats de la validation croisée\n",
    "res = lr.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a50da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d74e4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.6547917914008282\n"
     ]
    }
   ],
   "source": [
    "lr_r2 = lr.best_score_\n",
    "print(\"Best score: \", lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb19ac",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab5680de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9e58d",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "105d9724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Racine de l'erreur quadratique moyenne :  0.674338962194682\n",
      "--------------------------------------------------------------------------------\n",
      "Erreur quadratique moyenne :  0.821181442919092\n",
      "Erreur carré relative :  0.17840305334663542\n",
      "Score R² :  0.8215969466533646\n"
     ]
    }
   ],
   "source": [
    "# la racine de l'erreur quadratique moyenne\n",
    "rmse = mean_squared_error(y_test, y_test_pred)\n",
    "# l'erreur quadratique moyenne\n",
    "mse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "# Le score R²\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "# l'erreur carré relative\n",
    "rse = 1-r2\n",
    "\n",
    "print(\"Racine de l'erreur quadratique moyenne : \", rmse)\n",
    "\n",
    "print('----'*20)\n",
    "print(\"Erreur quadratique moyenne : \", mse)\n",
    "print(\"Erreur carré relative : \", rse)\n",
    "print('Score R² : ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49eb54b",
   "metadata": {},
   "source": [
    "#### Les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7ea9172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Régression Linéaire</th>\n",
       "      <td>0.821181</td>\n",
       "      <td>0.178403</td>\n",
       "      <td>0.821597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mse       rse        R²\n",
       "Régression Linéaire  0.821181  0.178403  0.821597"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'mse':mse,\n",
    "    'rse' :rse,\n",
    "    'R²' : r2\n",
    "}\n",
    "df_lr  = pd.DataFrame(scores, index = ['Régression Linéaire'])\n",
    "df_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b45271",
   "metadata": {},
   "source": [
    "### c.) Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bf8264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les importances de caractéristiques\n",
    "feat_imp = lr.best_estimator_.coef_\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance':feat_imp\n",
    "})\n",
    "# Trier la dataframe obtenué\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "864abddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SiteEUI(kBtu/sf)</td>\n",
       "      <td>0.960515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PrimaryPropertyType_15</td>\n",
       "      <td>0.763473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PrimaryPropertyType_6</td>\n",
       "      <td>0.753359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Attribute  Importance\n",
       "8         SiteEUI(kBtu/sf)    0.960515\n",
       "33  PrimaryPropertyType_15    0.763473\n",
       "24   PrimaryPropertyType_6    0.753359"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = importances.iloc[:3]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dd67730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# le graphique à barres à partir de coefficients : \n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color= 'red')\n",
    "plt.title('Feature importances ', size=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad9687",
   "metadata": {},
   "source": [
    "## <a name=\"C32\"> 3.2) Forêt Aléatoire </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231bd129",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle\n",
    "#### modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ace3122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as model_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8010ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du modèle\n",
    "rf = model_class(random_state=42)\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'max_depth': [1,2,3,4,5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb0b35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "rfr = GridSearchCV(estimator=rf, param_grid = param_grid, cv=5, scoring = ['r2', 'neg_mean_squared_error'],refit='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e2d19b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [100, 150, 200, 250, 300]},\n",
       "             refit='r2', scoring=['r2', 'neg_mean_squared_error'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiser sur le jeu d'entraînement\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d06dd219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_test_neg_mean_squared_error</th>\n",
       "      <th>split1_test_neg_mean_squared_error</th>\n",
       "      <th>split2_test_neg_mean_squared_error</th>\n",
       "      <th>split3_test_neg_mean_squared_error</th>\n",
       "      <th>split4_test_neg_mean_squared_error</th>\n",
       "      <th>mean_test_neg_mean_squared_error</th>\n",
       "      <th>std_test_neg_mean_squared_error</th>\n",
       "      <th>rank_test_neg_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.312274</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.019275</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 100}</td>\n",
       "      <td>0.531376</td>\n",
       "      <td>0.695649</td>\n",
       "      <td>0.434755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157118</td>\n",
       "      <td>22</td>\n",
       "      <td>-1.799607</td>\n",
       "      <td>-2.040852</td>\n",
       "      <td>-1.418875</td>\n",
       "      <td>-1.756659</td>\n",
       "      <td>-1.887471</td>\n",
       "      <td>-1.780693</td>\n",
       "      <td>0.205393</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.450739</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.028237</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 150}</td>\n",
       "      <td>0.537469</td>\n",
       "      <td>0.696716</td>\n",
       "      <td>0.437400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146403</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.776210</td>\n",
       "      <td>-2.033700</td>\n",
       "      <td>-1.412236</td>\n",
       "      <td>-1.746062</td>\n",
       "      <td>-1.793950</td>\n",
       "      <td>-1.752432</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.552735</td>\n",
       "      <td>0.065665</td>\n",
       "      <td>0.026307</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 200}</td>\n",
       "      <td>0.530822</td>\n",
       "      <td>0.695930</td>\n",
       "      <td>0.432446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161332</td>\n",
       "      <td>23</td>\n",
       "      <td>-1.801737</td>\n",
       "      <td>-2.038966</td>\n",
       "      <td>-1.424672</td>\n",
       "      <td>-1.758060</td>\n",
       "      <td>-1.920290</td>\n",
       "      <td>-1.788745</td>\n",
       "      <td>0.206676</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.641279</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.038063</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 250}</td>\n",
       "      <td>0.533135</td>\n",
       "      <td>0.693468</td>\n",
       "      <td>0.426540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168516</td>\n",
       "      <td>24</td>\n",
       "      <td>-1.792854</td>\n",
       "      <td>-2.055478</td>\n",
       "      <td>-1.439497</td>\n",
       "      <td>-1.773312</td>\n",
       "      <td>-1.976810</td>\n",
       "      <td>-1.807590</td>\n",
       "      <td>0.213058</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.915420</td>\n",
       "      <td>0.021553</td>\n",
       "      <td>0.044120</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 300}</td>\n",
       "      <td>0.532418</td>\n",
       "      <td>0.692639</td>\n",
       "      <td>0.425164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170436</td>\n",
       "      <td>25</td>\n",
       "      <td>-1.795607</td>\n",
       "      <td>-2.061039</td>\n",
       "      <td>-1.442950</td>\n",
       "      <td>-1.770936</td>\n",
       "      <td>-1.994401</td>\n",
       "      <td>-1.812987</td>\n",
       "      <td>0.216073</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.477848</td>\n",
       "      <td>0.087692</td>\n",
       "      <td>0.018826</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 100}</td>\n",
       "      <td>0.761753</td>\n",
       "      <td>0.917258</td>\n",
       "      <td>0.764751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143510</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.914914</td>\n",
       "      <td>-0.554836</td>\n",
       "      <td>-0.590521</td>\n",
       "      <td>-0.655412</td>\n",
       "      <td>-1.266361</td>\n",
       "      <td>-0.796409</td>\n",
       "      <td>0.266655</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.631735</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 150}</td>\n",
       "      <td>0.759405</td>\n",
       "      <td>0.917840</td>\n",
       "      <td>0.767232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147956</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.923931</td>\n",
       "      <td>-0.550931</td>\n",
       "      <td>-0.584294</td>\n",
       "      <td>-0.649701</td>\n",
       "      <td>-1.293975</td>\n",
       "      <td>-0.800566</td>\n",
       "      <td>0.279472</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.642240</td>\n",
       "      <td>0.101253</td>\n",
       "      <td>0.024017</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 200}</td>\n",
       "      <td>0.757236</td>\n",
       "      <td>0.917498</td>\n",
       "      <td>0.765511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160270</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.932261</td>\n",
       "      <td>-0.553223</td>\n",
       "      <td>-0.588613</td>\n",
       "      <td>-0.655079</td>\n",
       "      <td>-1.376719</td>\n",
       "      <td>-0.821179</td>\n",
       "      <td>0.308039</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.021791</td>\n",
       "      <td>0.016301</td>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 250}</td>\n",
       "      <td>0.754950</td>\n",
       "      <td>0.917029</td>\n",
       "      <td>0.765024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163137</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.941040</td>\n",
       "      <td>-0.556370</td>\n",
       "      <td>-0.589837</td>\n",
       "      <td>-0.658259</td>\n",
       "      <td>-1.397148</td>\n",
       "      <td>-0.828531</td>\n",
       "      <td>0.314968</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.216304</td>\n",
       "      <td>0.012721</td>\n",
       "      <td>0.051256</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 300}</td>\n",
       "      <td>0.755018</td>\n",
       "      <td>0.916988</td>\n",
       "      <td>0.764751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164921</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.940781</td>\n",
       "      <td>-0.556643</td>\n",
       "      <td>-0.590520</td>\n",
       "      <td>-0.659381</td>\n",
       "      <td>-1.408997</td>\n",
       "      <td>-0.831264</td>\n",
       "      <td>0.318963</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.041380</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.849997</td>\n",
       "      <td>0.963378</td>\n",
       "      <td>0.899586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130444</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.576040</td>\n",
       "      <td>-0.245572</td>\n",
       "      <td>-0.252059</td>\n",
       "      <td>-0.276420</td>\n",
       "      <td>-0.989960</td>\n",
       "      <td>-0.468010</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.609929</td>\n",
       "      <td>0.093033</td>\n",
       "      <td>0.018768</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 150}</td>\n",
       "      <td>0.847816</td>\n",
       "      <td>0.963615</td>\n",
       "      <td>0.901581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135843</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.584416</td>\n",
       "      <td>-0.243981</td>\n",
       "      <td>-0.247050</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-1.021772</td>\n",
       "      <td>-0.473877</td>\n",
       "      <td>0.302456</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.009609</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.034095</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 200}</td>\n",
       "      <td>0.846438</td>\n",
       "      <td>0.963573</td>\n",
       "      <td>0.899748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147783</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.589709</td>\n",
       "      <td>-0.244263</td>\n",
       "      <td>-0.251652</td>\n",
       "      <td>-0.272043</td>\n",
       "      <td>-1.097774</td>\n",
       "      <td>-0.491088</td>\n",
       "      <td>0.329857</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.260598</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>0.043788</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 250}</td>\n",
       "      <td>0.844700</td>\n",
       "      <td>0.963603</td>\n",
       "      <td>0.900358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150398</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.596383</td>\n",
       "      <td>-0.244061</td>\n",
       "      <td>-0.250122</td>\n",
       "      <td>-0.273754</td>\n",
       "      <td>-1.114304</td>\n",
       "      <td>-0.495725</td>\n",
       "      <td>0.336363</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.338661</td>\n",
       "      <td>0.171496</td>\n",
       "      <td>0.040286</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 300}</td>\n",
       "      <td>0.844861</td>\n",
       "      <td>0.963653</td>\n",
       "      <td>0.901072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152129</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.595763</td>\n",
       "      <td>-0.243726</td>\n",
       "      <td>-0.248329</td>\n",
       "      <td>-0.274176</td>\n",
       "      <td>-1.124712</td>\n",
       "      <td>-0.497341</td>\n",
       "      <td>0.340415</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.607333</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 100}</td>\n",
       "      <td>0.884829</td>\n",
       "      <td>0.981447</td>\n",
       "      <td>0.957169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127112</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.442281</td>\n",
       "      <td>-0.124408</td>\n",
       "      <td>-0.107514</td>\n",
       "      <td>-0.140379</td>\n",
       "      <td>-0.880226</td>\n",
       "      <td>-0.338962</td>\n",
       "      <td>0.297549</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.923709</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 150}</td>\n",
       "      <td>0.883083</td>\n",
       "      <td>0.981724</td>\n",
       "      <td>0.958064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132744</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.448986</td>\n",
       "      <td>-0.122549</td>\n",
       "      <td>-0.105267</td>\n",
       "      <td>-0.138297</td>\n",
       "      <td>-0.914037</td>\n",
       "      <td>-0.345827</td>\n",
       "      <td>0.311222</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.033031</td>\n",
       "      <td>0.158718</td>\n",
       "      <td>0.023818</td>\n",
       "      <td>0.007014</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 200}</td>\n",
       "      <td>0.882338</td>\n",
       "      <td>0.981760</td>\n",
       "      <td>0.956879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144098</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.451846</td>\n",
       "      <td>-0.122311</td>\n",
       "      <td>-0.108242</td>\n",
       "      <td>-0.140172</td>\n",
       "      <td>-0.986061</td>\n",
       "      <td>-0.361726</td>\n",
       "      <td>0.337217</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.512130</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.041037</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 250}</td>\n",
       "      <td>0.880426</td>\n",
       "      <td>0.981626</td>\n",
       "      <td>0.957159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146713</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.459189</td>\n",
       "      <td>-0.123212</td>\n",
       "      <td>-0.107539</td>\n",
       "      <td>-0.140724</td>\n",
       "      <td>-1.002520</td>\n",
       "      <td>-0.366637</td>\n",
       "      <td>0.343609</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.659332</td>\n",
       "      <td>0.222273</td>\n",
       "      <td>0.044055</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 300}</td>\n",
       "      <td>0.880935</td>\n",
       "      <td>0.981561</td>\n",
       "      <td>0.957530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148291</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.457232</td>\n",
       "      <td>-0.123644</td>\n",
       "      <td>-0.106608</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-1.012045</td>\n",
       "      <td>-0.368031</td>\n",
       "      <td>0.347128</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.695266</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.025190</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.895601</td>\n",
       "      <td>0.989819</td>\n",
       "      <td>0.975852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125479</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.400913</td>\n",
       "      <td>-0.068271</td>\n",
       "      <td>-0.060617</td>\n",
       "      <td>-0.069936</td>\n",
       "      <td>-0.830365</td>\n",
       "      <td>-0.286020</td>\n",
       "      <td>0.301472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.053969</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.030350</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 150}</td>\n",
       "      <td>0.893860</td>\n",
       "      <td>0.989915</td>\n",
       "      <td>0.976585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131573</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.407599</td>\n",
       "      <td>-0.067626</td>\n",
       "      <td>-0.058777</td>\n",
       "      <td>-0.069696</td>\n",
       "      <td>-0.867801</td>\n",
       "      <td>-0.294300</td>\n",
       "      <td>0.315924</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.224395</td>\n",
       "      <td>0.156534</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>0.013268</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.892887</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.976054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142531</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.411335</td>\n",
       "      <td>-0.067392</td>\n",
       "      <td>-0.060109</td>\n",
       "      <td>-0.070035</td>\n",
       "      <td>-0.936723</td>\n",
       "      <td>-0.309119</td>\n",
       "      <td>0.341155</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.843155</td>\n",
       "      <td>0.148282</td>\n",
       "      <td>0.044333</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 250}</td>\n",
       "      <td>0.891511</td>\n",
       "      <td>0.989831</td>\n",
       "      <td>0.976088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145055</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.416619</td>\n",
       "      <td>-0.068187</td>\n",
       "      <td>-0.060023</td>\n",
       "      <td>-0.069167</td>\n",
       "      <td>-0.952342</td>\n",
       "      <td>-0.313268</td>\n",
       "      <td>0.347241</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.925164</td>\n",
       "      <td>0.247941</td>\n",
       "      <td>0.047198</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 300}</td>\n",
       "      <td>0.891964</td>\n",
       "      <td>0.989780</td>\n",
       "      <td>0.976409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146437</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.414878</td>\n",
       "      <td>-0.068532</td>\n",
       "      <td>-0.059219</td>\n",
       "      <td>-0.069501</td>\n",
       "      <td>-0.960826</td>\n",
       "      <td>-0.314591</td>\n",
       "      <td>0.350288</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.312274      0.011698         0.019275        0.006298   \n",
       "1        0.450739      0.013813         0.028237        0.006303   \n",
       "2        0.552735      0.065665         0.026307        0.006405   \n",
       "3        0.641279      0.097178         0.038063        0.007438   \n",
       "4        0.915420      0.021553         0.044120        0.006335   \n",
       "5        0.477848      0.087692         0.018826        0.006215   \n",
       "6        0.631735      0.047950         0.025428        0.007164   \n",
       "7        0.642240      0.101253         0.024017        0.006973   \n",
       "8        1.021791      0.016301         0.040093        0.006794   \n",
       "9        1.216304      0.012721         0.051256        0.006399   \n",
       "10       0.489898      0.041380         0.018862        0.006446   \n",
       "11       0.609929      0.093033         0.018768        0.006271   \n",
       "12       1.009609      0.007109         0.034095        0.006755   \n",
       "13       1.260598      0.012919         0.043788        0.006273   \n",
       "14       1.338661      0.171496         0.040286        0.008730   \n",
       "15       0.607333      0.011994         0.021472        0.008231   \n",
       "16       0.923709      0.011842         0.021997        0.007603   \n",
       "17       1.033031      0.158718         0.023818        0.007014   \n",
       "18       1.512130      0.012084         0.041037        0.007561   \n",
       "19       1.659332      0.222273         0.044055        0.011741   \n",
       "20       0.695266      0.006303         0.025190        0.006488   \n",
       "21       1.053969      0.009978         0.030350        0.002805   \n",
       "22       1.224395      0.156534         0.039983        0.013268   \n",
       "23       1.843155      0.148282         0.044333        0.006540   \n",
       "24       1.925164      0.247941         0.047198        0.010011   \n",
       "\n",
       "   param_max_depth param_n_estimators                                 params  \\\n",
       "0                1                100  {'max_depth': 1, 'n_estimators': 100}   \n",
       "1                1                150  {'max_depth': 1, 'n_estimators': 150}   \n",
       "2                1                200  {'max_depth': 1, 'n_estimators': 200}   \n",
       "3                1                250  {'max_depth': 1, 'n_estimators': 250}   \n",
       "4                1                300  {'max_depth': 1, 'n_estimators': 300}   \n",
       "5                2                100  {'max_depth': 2, 'n_estimators': 100}   \n",
       "6                2                150  {'max_depth': 2, 'n_estimators': 150}   \n",
       "7                2                200  {'max_depth': 2, 'n_estimators': 200}   \n",
       "8                2                250  {'max_depth': 2, 'n_estimators': 250}   \n",
       "9                2                300  {'max_depth': 2, 'n_estimators': 300}   \n",
       "10               3                100  {'max_depth': 3, 'n_estimators': 100}   \n",
       "11               3                150  {'max_depth': 3, 'n_estimators': 150}   \n",
       "12               3                200  {'max_depth': 3, 'n_estimators': 200}   \n",
       "13               3                250  {'max_depth': 3, 'n_estimators': 250}   \n",
       "14               3                300  {'max_depth': 3, 'n_estimators': 300}   \n",
       "15               4                100  {'max_depth': 4, 'n_estimators': 100}   \n",
       "16               4                150  {'max_depth': 4, 'n_estimators': 150}   \n",
       "17               4                200  {'max_depth': 4, 'n_estimators': 200}   \n",
       "18               4                250  {'max_depth': 4, 'n_estimators': 250}   \n",
       "19               4                300  {'max_depth': 4, 'n_estimators': 300}   \n",
       "20               5                100  {'max_depth': 5, 'n_estimators': 100}   \n",
       "21               5                150  {'max_depth': 5, 'n_estimators': 150}   \n",
       "22               5                200  {'max_depth': 5, 'n_estimators': 200}   \n",
       "23               5                250  {'max_depth': 5, 'n_estimators': 250}   \n",
       "24               5                300  {'max_depth': 5, 'n_estimators': 300}   \n",
       "\n",
       "    split0_test_r2  split1_test_r2  split2_test_r2  ...  std_test_r2  \\\n",
       "0         0.531376        0.695649        0.434755  ...     0.157118   \n",
       "1         0.537469        0.696716        0.437400  ...     0.146403   \n",
       "2         0.530822        0.695930        0.432446  ...     0.161332   \n",
       "3         0.533135        0.693468        0.426540  ...     0.168516   \n",
       "4         0.532418        0.692639        0.425164  ...     0.170436   \n",
       "5         0.761753        0.917258        0.764751  ...     0.143510   \n",
       "6         0.759405        0.917840        0.767232  ...     0.147956   \n",
       "7         0.757236        0.917498        0.765511  ...     0.160270   \n",
       "8         0.754950        0.917029        0.765024  ...     0.163137   \n",
       "9         0.755018        0.916988        0.764751  ...     0.164921   \n",
       "10        0.849997        0.963378        0.899586  ...     0.130444   \n",
       "11        0.847816        0.963615        0.901581  ...     0.135843   \n",
       "12        0.846438        0.963573        0.899748  ...     0.147783   \n",
       "13        0.844700        0.963603        0.900358  ...     0.150398   \n",
       "14        0.844861        0.963653        0.901072  ...     0.152129   \n",
       "15        0.884829        0.981447        0.957169  ...     0.127112   \n",
       "16        0.883083        0.981724        0.958064  ...     0.132744   \n",
       "17        0.882338        0.981760        0.956879  ...     0.144098   \n",
       "18        0.880426        0.981626        0.957159  ...     0.146713   \n",
       "19        0.880935        0.981561        0.957530  ...     0.148291   \n",
       "20        0.895601        0.989819        0.975852  ...     0.125479   \n",
       "21        0.893860        0.989915        0.976585  ...     0.131573   \n",
       "22        0.892887        0.989950        0.976054  ...     0.142531   \n",
       "23        0.891511        0.989831        0.976088  ...     0.145055   \n",
       "24        0.891964        0.989780        0.976409  ...     0.146437   \n",
       "\n",
       "    rank_test_r2  split0_test_neg_mean_squared_error  \\\n",
       "0             22                           -1.799607   \n",
       "1             21                           -1.776210   \n",
       "2             23                           -1.801737   \n",
       "3             24                           -1.792854   \n",
       "4             25                           -1.795607   \n",
       "5             16                           -0.914914   \n",
       "6             17                           -0.923931   \n",
       "7             18                           -0.932261   \n",
       "8             19                           -0.941040   \n",
       "9             20                           -0.940781   \n",
       "10            11                           -0.576040   \n",
       "11            12                           -0.584416   \n",
       "12            13                           -0.589709   \n",
       "13            14                           -0.596383   \n",
       "14            15                           -0.595763   \n",
       "15             6                           -0.442281   \n",
       "16             7                           -0.448986   \n",
       "17             8                           -0.451846   \n",
       "18             9                           -0.459189   \n",
       "19            10                           -0.457232   \n",
       "20             1                           -0.400913   \n",
       "21             2                           -0.407599   \n",
       "22             3                           -0.411335   \n",
       "23             4                           -0.416619   \n",
       "24             5                           -0.414878   \n",
       "\n",
       "    split1_test_neg_mean_squared_error  split2_test_neg_mean_squared_error  \\\n",
       "0                            -2.040852                           -1.418875   \n",
       "1                            -2.033700                           -1.412236   \n",
       "2                            -2.038966                           -1.424672   \n",
       "3                            -2.055478                           -1.439497   \n",
       "4                            -2.061039                           -1.442950   \n",
       "5                            -0.554836                           -0.590521   \n",
       "6                            -0.550931                           -0.584294   \n",
       "7                            -0.553223                           -0.588613   \n",
       "8                            -0.556370                           -0.589837   \n",
       "9                            -0.556643                           -0.590520   \n",
       "10                           -0.245572                           -0.252059   \n",
       "11                           -0.243981                           -0.247050   \n",
       "12                           -0.244263                           -0.251652   \n",
       "13                           -0.244061                           -0.250122   \n",
       "14                           -0.243726                           -0.248329   \n",
       "15                           -0.124408                           -0.107514   \n",
       "16                           -0.122549                           -0.105267   \n",
       "17                           -0.122311                           -0.108242   \n",
       "18                           -0.123212                           -0.107539   \n",
       "19                           -0.123644                           -0.106608   \n",
       "20                           -0.068271                           -0.060617   \n",
       "21                           -0.067626                           -0.058777   \n",
       "22                           -0.067392                           -0.060109   \n",
       "23                           -0.068187                           -0.060023   \n",
       "24                           -0.068532                           -0.059219   \n",
       "\n",
       "    split3_test_neg_mean_squared_error  split4_test_neg_mean_squared_error  \\\n",
       "0                            -1.756659                           -1.887471   \n",
       "1                            -1.746062                           -1.793950   \n",
       "2                            -1.758060                           -1.920290   \n",
       "3                            -1.773312                           -1.976810   \n",
       "4                            -1.770936                           -1.994401   \n",
       "5                            -0.655412                           -1.266361   \n",
       "6                            -0.649701                           -1.293975   \n",
       "7                            -0.655079                           -1.376719   \n",
       "8                            -0.658259                           -1.397148   \n",
       "9                            -0.659381                           -1.408997   \n",
       "10                           -0.276420                           -0.989960   \n",
       "11                           -0.272166                           -1.021772   \n",
       "12                           -0.272043                           -1.097774   \n",
       "13                           -0.273754                           -1.114304   \n",
       "14                           -0.274176                           -1.124712   \n",
       "15                           -0.140379                           -0.880226   \n",
       "16                           -0.138297                           -0.914037   \n",
       "17                           -0.140172                           -0.986061   \n",
       "18                           -0.140724                           -1.002520   \n",
       "19                           -0.140625                           -1.012045   \n",
       "20                           -0.069936                           -0.830365   \n",
       "21                           -0.069696                           -0.867801   \n",
       "22                           -0.070035                           -0.936723   \n",
       "23                           -0.069167                           -0.952342   \n",
       "24                           -0.069501                           -0.960826   \n",
       "\n",
       "    mean_test_neg_mean_squared_error  std_test_neg_mean_squared_error  \\\n",
       "0                          -1.780693                         0.205393   \n",
       "1                          -1.752432                         0.198582   \n",
       "2                          -1.788745                         0.206676   \n",
       "3                          -1.807590                         0.213058   \n",
       "4                          -1.812987                         0.216073   \n",
       "5                          -0.796409                         0.266655   \n",
       "6                          -0.800566                         0.279472   \n",
       "7                          -0.821179                         0.308039   \n",
       "8                          -0.828531                         0.314968   \n",
       "9                          -0.831264                         0.318963   \n",
       "10                         -0.468010                         0.288764   \n",
       "11                         -0.473877                         0.302456   \n",
       "12                         -0.491088                         0.329857   \n",
       "13                         -0.495725                         0.336363   \n",
       "14                         -0.497341                         0.340415   \n",
       "15                         -0.338962                         0.297549   \n",
       "16                         -0.345827                         0.311222   \n",
       "17                         -0.361726                         0.337217   \n",
       "18                         -0.366637                         0.343609   \n",
       "19                         -0.368031                         0.347128   \n",
       "20                         -0.286020                         0.301472   \n",
       "21                         -0.294300                         0.315924   \n",
       "22                         -0.309119                         0.341155   \n",
       "23                         -0.313268                         0.347241   \n",
       "24                         -0.314591                         0.350288   \n",
       "\n",
       "    rank_test_neg_mean_squared_error  \n",
       "0                                 22  \n",
       "1                                 21  \n",
       "2                                 23  \n",
       "3                                 24  \n",
       "4                                 25  \n",
       "5                                 16  \n",
       "6                                 17  \n",
       "7                                 18  \n",
       "8                                 19  \n",
       "9                                 20  \n",
       "10                                11  \n",
       "11                                12  \n",
       "12                                13  \n",
       "13                                14  \n",
       "14                                15  \n",
       "15                                 6  \n",
       "16                                 7  \n",
       "17                                 8  \n",
       "18                                 9  \n",
       "19                                10  \n",
       "20                                 1  \n",
       "21                                 2  \n",
       "22                                 3  \n",
       "23                                 4  \n",
       "24                                 5  \n",
       "\n",
       "[25 rows x 23 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# résultats de la validation croisée\n",
    "res = rfr.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "968ec685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(rfr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f279a733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8987708766963216\n"
     ]
    }
   ],
   "source": [
    "rfr_r2 = rfr.best_score_\n",
    "print(\"Best score: \", rfr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "984b8a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score du training set :  0.9713497275838447\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = rfr.predict(X_train)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "print(\"Score du training set : \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34dac16",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30905bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a128add",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdd3d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6656f93",
   "metadata": {},
   "source": [
    "#### Les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e87f4e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Forêt Aléatoire</th>\n",
       "      <td>0.171782</td>\n",
       "      <td>0.045447</td>\n",
       "      <td>0.954553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mse       rse        R²\n",
       "Forêt Aléatoire  0.171782  0.045447  0.954553"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'mse':mse,\n",
    "    'rse' :rse,\n",
    "    'R²' : r2\n",
    "}\n",
    "df_rfr  = pd.DataFrame(scores, index = ['Forêt Aléatoire'])\n",
    "df_rfr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa3771",
   "metadata": {},
   "source": [
    "### c.) Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17528870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les importances de caractéristiques\n",
    "feat_imp = rfr.best_estimator_.feature_importances_\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance':feat_imp\n",
    "})\n",
    "# Trier la dataframe obtenué\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3041337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Electricity(kBtu)</td>\n",
       "      <td>0.403683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SiteEUI(kBtu/sf)</td>\n",
       "      <td>0.369183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SourceEUI(kBtu/sf)</td>\n",
       "      <td>0.189757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Attribute  Importance\n",
       "11   Electricity(kBtu)    0.403683\n",
       "8     SiteEUI(kBtu/sf)    0.369183\n",
       "9   SourceEUI(kBtu/sf)    0.189757"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = importances.iloc[:3]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a311debd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# le graphique à barres à partir de coefficients : \n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color= 'red')\n",
    "plt.title('Feature importances ', size=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0006f4",
   "metadata": {},
   "source": [
    "## <a name=\"C33\"> 3.3) Gradient Boosting </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe855f6d",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle\n",
    "#### modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de4fff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04a44107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du modèle\n",
    "gb =  GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [1,2,3,4,5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de4f436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "gbr = GridSearchCV(estimator=gb, param_grid = param_grid, cv=5, n_jobs=-1, verbose=1, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a979adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.2],\n",
       "                         'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [100, 150, 200, 250, 300]},\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiser sur le jeu d'entraînement\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ceaee09e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.306824</td>\n",
       "      <td>0.025765</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.856888</td>\n",
       "      <td>0.917156</td>\n",
       "      <td>0.913416</td>\n",
       "      <td>0.900562</td>\n",
       "      <td>0.652520</td>\n",
       "      <td>0.848108</td>\n",
       "      <td>0.100116</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.429114</td>\n",
       "      <td>0.012082</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.868201</td>\n",
       "      <td>0.953493</td>\n",
       "      <td>0.950860</td>\n",
       "      <td>0.944876</td>\n",
       "      <td>0.651654</td>\n",
       "      <td>0.873817</td>\n",
       "      <td>0.115517</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.536401</td>\n",
       "      <td>0.011774</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.868480</td>\n",
       "      <td>0.968694</td>\n",
       "      <td>0.964632</td>\n",
       "      <td>0.962459</td>\n",
       "      <td>0.643202</td>\n",
       "      <td>0.881493</td>\n",
       "      <td>0.124919</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680757</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.866075</td>\n",
       "      <td>0.975121</td>\n",
       "      <td>0.970569</td>\n",
       "      <td>0.967421</td>\n",
       "      <td>0.636987</td>\n",
       "      <td>0.883235</td>\n",
       "      <td>0.129684</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.929690</td>\n",
       "      <td>0.088425</td>\n",
       "      <td>0.009054</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.863423</td>\n",
       "      <td>0.979105</td>\n",
       "      <td>0.973695</td>\n",
       "      <td>0.971123</td>\n",
       "      <td>0.631228</td>\n",
       "      <td>0.883715</td>\n",
       "      <td>0.133415</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.396734</td>\n",
       "      <td>0.034039</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.911161</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.995150</td>\n",
       "      <td>0.994325</td>\n",
       "      <td>0.637483</td>\n",
       "      <td>0.905911</td>\n",
       "      <td>0.137969</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2.079148</td>\n",
       "      <td>0.042082</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.911236</td>\n",
       "      <td>0.991486</td>\n",
       "      <td>0.995207</td>\n",
       "      <td>0.994342</td>\n",
       "      <td>0.637211</td>\n",
       "      <td>0.905896</td>\n",
       "      <td>0.138091</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2.847909</td>\n",
       "      <td>0.129181</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.911322</td>\n",
       "      <td>0.991486</td>\n",
       "      <td>0.995203</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.637249</td>\n",
       "      <td>0.905923</td>\n",
       "      <td>0.138077</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3.475101</td>\n",
       "      <td>0.068625</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.911348</td>\n",
       "      <td>0.991485</td>\n",
       "      <td>0.995216</td>\n",
       "      <td>0.994365</td>\n",
       "      <td>0.637330</td>\n",
       "      <td>0.905949</td>\n",
       "      <td>0.138049</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3.781870</td>\n",
       "      <td>0.194216</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.911326</td>\n",
       "      <td>0.991489</td>\n",
       "      <td>0.995217</td>\n",
       "      <td>0.994367</td>\n",
       "      <td>0.637281</td>\n",
       "      <td>0.905936</td>\n",
       "      <td>0.138069</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.306824      0.025765         0.006230        0.006567   \n",
       "1        0.429114      0.012082         0.000902        0.001804   \n",
       "2        0.536401      0.011774         0.009373        0.007653   \n",
       "3        0.680757      0.007721         0.006350        0.007779   \n",
       "4        0.929690      0.088425         0.009054        0.007416   \n",
       "..            ...           ...              ...             ...   \n",
       "70       1.396734      0.034039         0.012498        0.006249   \n",
       "71       2.079148      0.042082         0.012578        0.007449   \n",
       "72       2.847909      0.129181         0.002403        0.004806   \n",
       "73       3.475101      0.068625         0.006128        0.007508   \n",
       "74       3.781870      0.194216         0.006752        0.007304   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                 0.05               1                100   \n",
       "1                 0.05               1                150   \n",
       "2                 0.05               1                200   \n",
       "3                 0.05               1                250   \n",
       "4                 0.05               1                300   \n",
       "..                 ...             ...                ...   \n",
       "70                 0.2               5                100   \n",
       "71                 0.2               5                150   \n",
       "72                 0.2               5                200   \n",
       "73                 0.2               5                250   \n",
       "74                 0.2               5                300   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.856888   \n",
       "1   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.868201   \n",
       "2   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.868480   \n",
       "3   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.866075   \n",
       "4   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.863423   \n",
       "..                                                ...                ...   \n",
       "70  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.911161   \n",
       "71  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.911236   \n",
       "72  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.911322   \n",
       "73  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.911348   \n",
       "74  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.911326   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.917156           0.913416           0.900562   \n",
       "1            0.953493           0.950860           0.944876   \n",
       "2            0.968694           0.964632           0.962459   \n",
       "3            0.975121           0.970569           0.967421   \n",
       "4            0.979105           0.973695           0.971123   \n",
       "..                ...                ...                ...   \n",
       "70           0.991439           0.995150           0.994325   \n",
       "71           0.991486           0.995207           0.994342   \n",
       "72           0.991486           0.995203           0.994355   \n",
       "73           0.991485           0.995216           0.994365   \n",
       "74           0.991489           0.995217           0.994367   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.652520         0.848108        0.100116               75  \n",
       "1            0.651654         0.873817        0.115517               74  \n",
       "2            0.643202         0.881493        0.124919               72  \n",
       "3            0.636987         0.883235        0.129684               70  \n",
       "4            0.631228         0.883715        0.133415               68  \n",
       "..                ...              ...             ...              ...  \n",
       "70           0.637483         0.905911        0.137969               59  \n",
       "71           0.637211         0.905896        0.138091               60  \n",
       "72           0.637249         0.905923        0.138077               58  \n",
       "73           0.637330         0.905949        0.138049               56  \n",
       "74           0.637281         0.905936        0.138069               57  \n",
       "\n",
       "[75 rows x 16 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# résultats de la validation croisée\n",
    "res = gbr.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "764b6ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(gbr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4be3f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.9418800482477586\n"
     ]
    }
   ],
   "source": [
    "gbr_r2 = gbr.best_score_\n",
    "print(\"Best score: \", gbr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8daae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score du training set :  0.9990737214643192\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = gbr.predict(X_train)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "print(\"Score du training set : \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69114c",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "458aba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f68c6",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "743b1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a031add",
   "metadata": {},
   "source": [
    "#### Les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30d75e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.07786</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.979401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mse       rse        R²\n",
       "Gradient Boosting  0.07786  0.020599  0.979401"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'mse':mse,\n",
    "    'rse' :rse,\n",
    "    'R²' : r2\n",
    "}\n",
    "df_gr  = pd.DataFrame(scores, index = ['Gradient Boosting'])\n",
    "df_gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97633ac4",
   "metadata": {},
   "source": [
    "### c.) Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a0b3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les importances de caractéristiques\n",
    "feat_imp = gbr.best_estimator_.feature_importances_\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance':feat_imp\n",
    "})\n",
    "# Trier la dataframe obtenué\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "689191ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SiteEUI(kBtu/sf)</td>\n",
       "      <td>0.542601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Electricity(kBtu)</td>\n",
       "      <td>0.359406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaturalGas(kBtu)</td>\n",
       "      <td>0.040455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Attribute  Importance\n",
       "8    SiteEUI(kBtu/sf)    0.542601\n",
       "11  Electricity(kBtu)    0.359406\n",
       "12   NaturalGas(kBtu)    0.040455"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = importances.iloc[:3]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd2cec9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='red')\n",
    "plt.title('Feature importances', size=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8307dca",
   "metadata": {},
   "source": [
    "## <a name=\"C34\"> 3.4) MLP </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9d5e48",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle\n",
    "#### modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8851838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1380827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = MLPRegressor()\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,), (20,), (30,), (50,), (100,)],\n",
    "    'activation': ['relu', 'logistic', 'tanh'],\n",
    "    'solver': ['lbfgs', 'adam', 'sgd']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14f87774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "mlp = GridSearchCV(estimator=rp, param_grid = param_grid, cv=5, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0138a0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPRegressor(),\n",
       "             param_grid={'activation': ['relu', 'logistic', 'tanh'],\n",
       "                         'hidden_layer_sizes': [(10,), (20,), (30,), (50,),\n",
       "                                                (100,)],\n",
       "                         'solver': ['lbfgs', 'adam', 'sgd']},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiser sur le jeu d'entraînement\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6da4a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.325738</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>relu</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.786233</td>\n",
       "      <td>0.722939</td>\n",
       "      <td>0.778956</td>\n",
       "      <td>0.848990</td>\n",
       "      <td>7.145431e-01</td>\n",
       "      <td>0.770332</td>\n",
       "      <td>0.048729</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960306</td>\n",
       "      <td>0.047907</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>relu</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.719203</td>\n",
       "      <td>0.683744</td>\n",
       "      <td>0.742275</td>\n",
       "      <td>0.756102</td>\n",
       "      <td>5.690507e-01</td>\n",
       "      <td>0.694075</td>\n",
       "      <td>0.067141</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.527482</td>\n",
       "      <td>0.045188</td>\n",
       "      <td>0.003729</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>relu</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>-0.000751</td>\n",
       "      <td>-0.005921</td>\n",
       "      <td>-0.002025</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>-1.937841e-05</td>\n",
       "      <td>-0.008106</td>\n",
       "      <td>0.012028</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.417315</td>\n",
       "      <td>0.057224</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>relu</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.851892</td>\n",
       "      <td>0.737156</td>\n",
       "      <td>0.765081</td>\n",
       "      <td>0.766760</td>\n",
       "      <td>6.361040e-01</td>\n",
       "      <td>0.751398</td>\n",
       "      <td>0.069308</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.058794</td>\n",
       "      <td>0.077090</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>relu</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.565666</td>\n",
       "      <td>0.658956</td>\n",
       "      <td>0.734243</td>\n",
       "      <td>0.794446</td>\n",
       "      <td>6.614271e-01</td>\n",
       "      <td>0.682948</td>\n",
       "      <td>0.077275</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.589339</td>\n",
       "      <td>0.096416</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>relu</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>-0.006062</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>0.731900</td>\n",
       "      <td>-7.924098e-07</td>\n",
       "      <td>0.144624</td>\n",
       "      <td>0.293645</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.621597</td>\n",
       "      <td>0.024535</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>relu</td>\n",
       "      <td>(30,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.789059</td>\n",
       "      <td>0.746986</td>\n",
       "      <td>0.797666</td>\n",
       "      <td>0.843849</td>\n",
       "      <td>6.065841e-01</td>\n",
       "      <td>0.756829</td>\n",
       "      <td>0.081178</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.171057</td>\n",
       "      <td>0.158624</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>relu</td>\n",
       "      <td>(30,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.802977</td>\n",
       "      <td>0.837741</td>\n",
       "      <td>0.727192</td>\n",
       "      <td>0.695855</td>\n",
       "      <td>6.825114e-01</td>\n",
       "      <td>0.749255</td>\n",
       "      <td>0.060842</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.580582</td>\n",
       "      <td>0.038565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>(30,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.005617</td>\n",
       "      <td>-0.001392</td>\n",
       "      <td>-0.035879</td>\n",
       "      <td>-7.414334e-06</td>\n",
       "      <td>-0.008729</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.799867</td>\n",
       "      <td>0.100239</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.008123</td>\n",
       "      <td>relu</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.789201</td>\n",
       "      <td>0.809267</td>\n",
       "      <td>0.764364</td>\n",
       "      <td>0.808892</td>\n",
       "      <td>7.414004e-01</td>\n",
       "      <td>0.782625</td>\n",
       "      <td>0.026366</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.373146</td>\n",
       "      <td>0.139187</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>relu</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.857722</td>\n",
       "      <td>0.731883</td>\n",
       "      <td>0.743221</td>\n",
       "      <td>0.796063</td>\n",
       "      <td>6.405538e-01</td>\n",
       "      <td>0.753888</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.718881</td>\n",
       "      <td>0.288386</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.006083</td>\n",
       "      <td>relu</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>0.176726</td>\n",
       "      <td>0.464039</td>\n",
       "      <td>-0.034535</td>\n",
       "      <td>-1.245547e-05</td>\n",
       "      <td>0.121087</td>\n",
       "      <td>0.186787</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.506210</td>\n",
       "      <td>0.054632</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>relu</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.788628</td>\n",
       "      <td>0.821272</td>\n",
       "      <td>0.742396</td>\n",
       "      <td>0.799465</td>\n",
       "      <td>6.372844e-01</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.065538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.957781</td>\n",
       "      <td>0.076002</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>relu</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.870120</td>\n",
       "      <td>0.792679</td>\n",
       "      <td>0.922259</td>\n",
       "      <td>0.835851</td>\n",
       "      <td>7.907002e-01</td>\n",
       "      <td>0.842322</td>\n",
       "      <td>0.049666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.886619</td>\n",
       "      <td>0.230618</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>relu</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>-0.006017</td>\n",
       "      <td>-0.001908</td>\n",
       "      <td>0.358894</td>\n",
       "      <td>5.077138e-05</td>\n",
       "      <td>0.070066</td>\n",
       "      <td>0.144429</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.289139</td>\n",
       "      <td>0.138763</td>\n",
       "      <td>0.009376</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.396646</td>\n",
       "      <td>0.701952</td>\n",
       "      <td>0.602547</td>\n",
       "      <td>-0.028222</td>\n",
       "      <td>1.270293e-01</td>\n",
       "      <td>0.359990</td>\n",
       "      <td>0.276440</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.975422</td>\n",
       "      <td>0.073470</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>-9.198538</td>\n",
       "      <td>-7.434539</td>\n",
       "      <td>-13.361405</td>\n",
       "      <td>-42.428043</td>\n",
       "      <td>-2.635523e+01</td>\n",
       "      <td>-19.755552</td>\n",
       "      <td>13.128143</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.564288</td>\n",
       "      <td>0.338190</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.307528</td>\n",
       "      <td>0.317856</td>\n",
       "      <td>0.322802</td>\n",
       "      <td>-3.694988e-04</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.155084</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.493371</td>\n",
       "      <td>0.077664</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>0.487338</td>\n",
       "      <td>0.562070</td>\n",
       "      <td>0.598304</td>\n",
       "      <td>6.574054e-01</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.224834</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.119308</td>\n",
       "      <td>0.109350</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>-1.898307</td>\n",
       "      <td>-1.779114</td>\n",
       "      <td>-6.564944</td>\n",
       "      <td>-1.472527</td>\n",
       "      <td>-2.592225e+00</td>\n",
       "      <td>-2.861423</td>\n",
       "      <td>1.887673</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.532117</td>\n",
       "      <td>0.414853</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>0.194639</td>\n",
       "      <td>0.378155</td>\n",
       "      <td>-0.029036</td>\n",
       "      <td>-6.606572e-04</td>\n",
       "      <td>0.108588</td>\n",
       "      <td>0.156699</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.647192</td>\n",
       "      <td>0.114749</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(30,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.750879</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.524466</td>\n",
       "      <td>0.734274</td>\n",
       "      <td>6.633056e-01</td>\n",
       "      <td>0.684080</td>\n",
       "      <td>0.085917</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.160041</td>\n",
       "      <td>0.024592</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(30,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>-0.088577</td>\n",
       "      <td>-0.056146</td>\n",
       "      <td>-0.025725</td>\n",
       "      <td>-0.187055</td>\n",
       "      <td>-5.617319e-01</td>\n",
       "      <td>-0.183847</td>\n",
       "      <td>0.196567</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.094301</td>\n",
       "      <td>0.073625</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(30,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.394927</td>\n",
       "      <td>0.197467</td>\n",
       "      <td>0.372426</td>\n",
       "      <td>0.435342</td>\n",
       "      <td>4.375413e-01</td>\n",
       "      <td>0.367541</td>\n",
       "      <td>0.088539</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.948787</td>\n",
       "      <td>0.054547</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.007648</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.743898</td>\n",
       "      <td>0.692108</td>\n",
       "      <td>0.721862</td>\n",
       "      <td>6.870200e-01</td>\n",
       "      <td>0.715138</td>\n",
       "      <td>0.022085</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.443547</td>\n",
       "      <td>0.118655</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.296560</td>\n",
       "      <td>0.350907</td>\n",
       "      <td>0.317310</td>\n",
       "      <td>2.810783e-01</td>\n",
       "      <td>0.249013</td>\n",
       "      <td>0.127074</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.408564</td>\n",
       "      <td>0.111364</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.441157</td>\n",
       "      <td>0.285477</td>\n",
       "      <td>0.448750</td>\n",
       "      <td>0.296605</td>\n",
       "      <td>3.910616e-01</td>\n",
       "      <td>0.372610</td>\n",
       "      <td>0.069578</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.418664</td>\n",
       "      <td>0.062044</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.704556</td>\n",
       "      <td>0.846216</td>\n",
       "      <td>0.512350</td>\n",
       "      <td>0.643021</td>\n",
       "      <td>4.705706e-01</td>\n",
       "      <td>0.635343</td>\n",
       "      <td>0.135347</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.060161</td>\n",
       "      <td>0.116246</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.006067</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.540784</td>\n",
       "      <td>0.338361</td>\n",
       "      <td>0.504672</td>\n",
       "      <td>0.490029</td>\n",
       "      <td>4.997339e-01</td>\n",
       "      <td>0.474716</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.781039</td>\n",
       "      <td>0.142020</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.498697</td>\n",
       "      <td>0.398959</td>\n",
       "      <td>0.482212</td>\n",
       "      <td>0.598950</td>\n",
       "      <td>5.560815e-01</td>\n",
       "      <td>0.506980</td>\n",
       "      <td>0.068147</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.290740</td>\n",
       "      <td>0.146961</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.612643</td>\n",
       "      <td>0.559711</td>\n",
       "      <td>0.591731</td>\n",
       "      <td>0.717279</td>\n",
       "      <td>-1.739638e-04</td>\n",
       "      <td>0.496238</td>\n",
       "      <td>0.253764</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.111930</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>-2.453220</td>\n",
       "      <td>-1.147129</td>\n",
       "      <td>-4.607638</td>\n",
       "      <td>-5.959582</td>\n",
       "      <td>-7.613615e+00</td>\n",
       "      <td>-4.356237</td>\n",
       "      <td>2.330849</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.180619</td>\n",
       "      <td>0.038680</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.006458</td>\n",
       "      <td>-0.003496</td>\n",
       "      <td>-0.026421</td>\n",
       "      <td>-2.665425e-04</td>\n",
       "      <td>-0.007352</td>\n",
       "      <td>0.009817</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.316261</td>\n",
       "      <td>0.219681</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>0.734346</td>\n",
       "      <td>0.461947</td>\n",
       "      <td>-0.052885</td>\n",
       "      <td>3.876769e-01</td>\n",
       "      <td>0.306154</td>\n",
       "      <td>0.295668</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.210004</td>\n",
       "      <td>0.080554</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.149762</td>\n",
       "      <td>0.117792</td>\n",
       "      <td>0.030243</td>\n",
       "      <td>0.057638</td>\n",
       "      <td>3.796972e-02</td>\n",
       "      <td>0.078681</td>\n",
       "      <td>0.046965</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.398264</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>-0.005422</td>\n",
       "      <td>0.281795</td>\n",
       "      <td>-0.032626</td>\n",
       "      <td>-1.070821e-03</td>\n",
       "      <td>0.048499</td>\n",
       "      <td>0.117254</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.546046</td>\n",
       "      <td>0.265944</td>\n",
       "      <td>0.010078</td>\n",
       "      <td>0.006885</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(30,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.337320</td>\n",
       "      <td>0.809361</td>\n",
       "      <td>0.556568</td>\n",
       "      <td>-0.035723</td>\n",
       "      <td>1.939488e-01</td>\n",
       "      <td>0.372295</td>\n",
       "      <td>0.291373</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.321742</td>\n",
       "      <td>0.163197</td>\n",
       "      <td>0.007749</td>\n",
       "      <td>0.006987</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(30,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.380642</td>\n",
       "      <td>0.221126</td>\n",
       "      <td>0.340893</td>\n",
       "      <td>0.279918</td>\n",
       "      <td>4.522351e-01</td>\n",
       "      <td>0.334963</td>\n",
       "      <td>0.079829</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.613795</td>\n",
       "      <td>0.323635</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(30,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.111568</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>-0.051903</td>\n",
       "      <td>1.820914e-01</td>\n",
       "      <td>0.048209</td>\n",
       "      <td>0.085649</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.044049</td>\n",
       "      <td>0.073827</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.539200</td>\n",
       "      <td>0.859760</td>\n",
       "      <td>0.719522</td>\n",
       "      <td>0.647666</td>\n",
       "      <td>2.265003e-01</td>\n",
       "      <td>0.598530</td>\n",
       "      <td>0.213176</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.926105</td>\n",
       "      <td>0.129568</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.350911</td>\n",
       "      <td>0.378595</td>\n",
       "      <td>0.396887</td>\n",
       "      <td>0.397010</td>\n",
       "      <td>4.164819e-01</td>\n",
       "      <td>0.387977</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.783896</td>\n",
       "      <td>0.255563</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.316784</td>\n",
       "      <td>0.269901</td>\n",
       "      <td>-0.007207</td>\n",
       "      <td>-0.111506</td>\n",
       "      <td>3.588291e-01</td>\n",
       "      <td>0.165360</td>\n",
       "      <td>0.188533</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.913386</td>\n",
       "      <td>0.184393</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.736853</td>\n",
       "      <td>0.857364</td>\n",
       "      <td>0.565901</td>\n",
       "      <td>0.571821</td>\n",
       "      <td>4.278798e-01</td>\n",
       "      <td>0.631964</td>\n",
       "      <td>0.149291</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.642660</td>\n",
       "      <td>0.301644</td>\n",
       "      <td>0.009454</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.599056</td>\n",
       "      <td>0.456264</td>\n",
       "      <td>0.512621</td>\n",
       "      <td>0.511898</td>\n",
       "      <td>5.533389e-01</td>\n",
       "      <td>0.526636</td>\n",
       "      <td>0.047589</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.485450</td>\n",
       "      <td>0.370282</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.316191</td>\n",
       "      <td>0.226142</td>\n",
       "      <td>0.421521</td>\n",
       "      <td>0.349432</td>\n",
       "      <td>3.498114e-01</td>\n",
       "      <td>0.332620</td>\n",
       "      <td>0.063386</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.325738      0.010685         0.009383        0.007661   \n",
       "1        0.960306      0.047907         0.004473        0.006156   \n",
       "2        0.527482      0.045188         0.003729        0.006065   \n",
       "3        0.417315      0.057224         0.006248        0.007652   \n",
       "4        1.058794      0.077090         0.001298        0.002595   \n",
       "5        0.589339      0.096416         0.005236        0.006618   \n",
       "6        0.621597      0.024535         0.003003        0.006007   \n",
       "7        1.171057      0.158624         0.003203        0.006406   \n",
       "8        0.580582      0.038565         0.000000        0.000000   \n",
       "9        0.799867      0.100239         0.008853        0.008123   \n",
       "10       1.373146      0.139187         0.003124        0.006248   \n",
       "11       0.718881      0.288386         0.004226        0.006083   \n",
       "12       1.506210      0.054632         0.006247        0.007651   \n",
       "13       1.957781      0.076002         0.006249        0.007653   \n",
       "14       0.886619      0.230618         0.000820        0.001640   \n",
       "15       0.289139      0.138763         0.009376        0.007655   \n",
       "16       0.975422      0.073470         0.009382        0.007661   \n",
       "17       0.564288      0.338190         0.001797        0.002544   \n",
       "18       0.493371      0.077664         0.003849        0.005382   \n",
       "19       1.119308      0.109350         0.006869        0.007252   \n",
       "20       0.532117      0.414853         0.003124        0.006249   \n",
       "21       0.647192      0.114749         0.004527        0.006177   \n",
       "22       1.160041      0.024592         0.006850        0.007244   \n",
       "23       1.094301      0.073625         0.003124        0.006249   \n",
       "24       0.948787      0.054547         0.009367        0.007648   \n",
       "25       1.443547      0.118655         0.009373        0.007653   \n",
       "26       1.408564      0.111364         0.006259        0.007665   \n",
       "27       1.418664      0.062044         0.004482        0.006790   \n",
       "28       2.060161      0.116246         0.004303        0.006067   \n",
       "29       1.781039      0.142020         0.003004        0.005758   \n",
       "30       0.290740      0.146961         0.010293        0.006702   \n",
       "31       1.111930      0.061836         0.005928        0.007279   \n",
       "32       0.180619      0.038680         0.007011        0.007168   \n",
       "33       0.316261      0.219681         0.003371        0.006742   \n",
       "34       1.210004      0.080554         0.006251        0.007655   \n",
       "35       0.398264      0.241954         0.010482        0.006546   \n",
       "36       0.546046      0.265944         0.010078        0.006885   \n",
       "37       1.321742      0.163197         0.007749        0.006987   \n",
       "38       0.613795      0.323635         0.006250        0.007655   \n",
       "39       1.044049      0.073827         0.003133        0.006266   \n",
       "40       1.926105      0.129568         0.003124        0.006249   \n",
       "41       0.783896      0.255563         0.006249        0.007653   \n",
       "42       1.913386      0.184393         0.007661        0.006995   \n",
       "43       2.642660      0.301644         0.009454        0.007721   \n",
       "44       1.485450      0.370282         0.006247        0.007652   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_solver  \\\n",
       "0              relu                    (10,)        lbfgs   \n",
       "1              relu                    (10,)         adam   \n",
       "2              relu                    (10,)          sgd   \n",
       "3              relu                    (20,)        lbfgs   \n",
       "4              relu                    (20,)         adam   \n",
       "5              relu                    (20,)          sgd   \n",
       "6              relu                    (30,)        lbfgs   \n",
       "7              relu                    (30,)         adam   \n",
       "8              relu                    (30,)          sgd   \n",
       "9              relu                    (50,)        lbfgs   \n",
       "10             relu                    (50,)         adam   \n",
       "11             relu                    (50,)          sgd   \n",
       "12             relu                   (100,)        lbfgs   \n",
       "13             relu                   (100,)         adam   \n",
       "14             relu                   (100,)          sgd   \n",
       "15         logistic                    (10,)        lbfgs   \n",
       "16         logistic                    (10,)         adam   \n",
       "17         logistic                    (10,)          sgd   \n",
       "18         logistic                    (20,)        lbfgs   \n",
       "19         logistic                    (20,)         adam   \n",
       "20         logistic                    (20,)          sgd   \n",
       "21         logistic                    (30,)        lbfgs   \n",
       "22         logistic                    (30,)         adam   \n",
       "23         logistic                    (30,)          sgd   \n",
       "24         logistic                    (50,)        lbfgs   \n",
       "25         logistic                    (50,)         adam   \n",
       "26         logistic                    (50,)          sgd   \n",
       "27         logistic                   (100,)        lbfgs   \n",
       "28         logistic                   (100,)         adam   \n",
       "29         logistic                   (100,)          sgd   \n",
       "30             tanh                    (10,)        lbfgs   \n",
       "31             tanh                    (10,)         adam   \n",
       "32             tanh                    (10,)          sgd   \n",
       "33             tanh                    (20,)        lbfgs   \n",
       "34             tanh                    (20,)         adam   \n",
       "35             tanh                    (20,)          sgd   \n",
       "36             tanh                    (30,)        lbfgs   \n",
       "37             tanh                    (30,)         adam   \n",
       "38             tanh                    (30,)          sgd   \n",
       "39             tanh                    (50,)        lbfgs   \n",
       "40             tanh                    (50,)         adam   \n",
       "41             tanh                    (50,)          sgd   \n",
       "42             tanh                   (100,)        lbfgs   \n",
       "43             tanh                   (100,)         adam   \n",
       "44             tanh                   (100,)          sgd   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'activation': 'relu', 'hidden_layer_sizes': (...           0.786233   \n",
       "1   {'activation': 'relu', 'hidden_layer_sizes': (...           0.719203   \n",
       "2   {'activation': 'relu', 'hidden_layer_sizes': (...          -0.000751   \n",
       "3   {'activation': 'relu', 'hidden_layer_sizes': (...           0.851892   \n",
       "4   {'activation': 'relu', 'hidden_layer_sizes': (...           0.565666   \n",
       "5   {'activation': 'relu', 'hidden_layer_sizes': (...          -0.000917   \n",
       "6   {'activation': 'relu', 'hidden_layer_sizes': (...           0.789059   \n",
       "7   {'activation': 'relu', 'hidden_layer_sizes': (...           0.802977   \n",
       "8   {'activation': 'relu', 'hidden_layer_sizes': (...          -0.000748   \n",
       "9   {'activation': 'relu', 'hidden_layer_sizes': (...           0.789201   \n",
       "10  {'activation': 'relu', 'hidden_layer_sizes': (...           0.857722   \n",
       "11  {'activation': 'relu', 'hidden_layer_sizes': (...          -0.000782   \n",
       "12  {'activation': 'relu', 'hidden_layer_sizes': (...           0.788628   \n",
       "13  {'activation': 'relu', 'hidden_layer_sizes': (...           0.870120   \n",
       "14  {'activation': 'relu', 'hidden_layer_sizes': (...          -0.000688   \n",
       "15  {'activation': 'logistic', 'hidden_layer_sizes...           0.396646   \n",
       "16  {'activation': 'logistic', 'hidden_layer_sizes...          -9.198538   \n",
       "17  {'activation': 'logistic', 'hidden_layer_sizes...          -0.000315   \n",
       "18  {'activation': 'logistic', 'hidden_layer_sizes...           0.031333   \n",
       "19  {'activation': 'logistic', 'hidden_layer_sizes...          -1.898307   \n",
       "20  {'activation': 'logistic', 'hidden_layer_sizes...          -0.000158   \n",
       "21  {'activation': 'logistic', 'hidden_layer_sizes...           0.750879   \n",
       "22  {'activation': 'logistic', 'hidden_layer_sizes...          -0.088577   \n",
       "23  {'activation': 'logistic', 'hidden_layer_sizes...           0.394927   \n",
       "24  {'activation': 'logistic', 'hidden_layer_sizes...           0.730800   \n",
       "25  {'activation': 'logistic', 'hidden_layer_sizes...          -0.000792   \n",
       "26  {'activation': 'logistic', 'hidden_layer_sizes...           0.441157   \n",
       "27  {'activation': 'logistic', 'hidden_layer_sizes...           0.704556   \n",
       "28  {'activation': 'logistic', 'hidden_layer_sizes...           0.540784   \n",
       "29  {'activation': 'logistic', 'hidden_layer_sizes...           0.498697   \n",
       "30  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.612643   \n",
       "31  {'activation': 'tanh', 'hidden_layer_sizes': (...          -2.453220   \n",
       "32  {'activation': 'tanh', 'hidden_layer_sizes': (...          -0.000117   \n",
       "33  {'activation': 'tanh', 'hidden_layer_sizes': (...          -0.000316   \n",
       "34  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.149762   \n",
       "35  {'activation': 'tanh', 'hidden_layer_sizes': (...          -0.000181   \n",
       "36  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.337320   \n",
       "37  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.380642   \n",
       "38  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.000079   \n",
       "39  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.539200   \n",
       "40  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.350911   \n",
       "41  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.316784   \n",
       "42  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.736853   \n",
       "43  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.599056   \n",
       "44  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.316191   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.722939           0.778956           0.848990   \n",
       "1            0.683744           0.742275           0.756102   \n",
       "2           -0.005921          -0.002025          -0.031815   \n",
       "3            0.737156           0.765081           0.766760   \n",
       "4            0.658956           0.734243           0.794446   \n",
       "5           -0.006062          -0.001800           0.731900   \n",
       "6            0.746986           0.797666           0.843849   \n",
       "7            0.837741           0.727192           0.695855   \n",
       "8           -0.005617          -0.001392          -0.035879   \n",
       "9            0.809267           0.764364           0.808892   \n",
       "10           0.731883           0.743221           0.796063   \n",
       "11           0.176726           0.464039          -0.034535   \n",
       "12           0.821272           0.742396           0.799465   \n",
       "13           0.792679           0.922259           0.835851   \n",
       "14          -0.006017          -0.001908           0.358894   \n",
       "15           0.701952           0.602547          -0.028222   \n",
       "16          -7.434539         -13.361405         -42.428043   \n",
       "17           0.307528           0.317856           0.322802   \n",
       "18           0.487338           0.562070           0.598304   \n",
       "19          -1.779114          -6.564944          -1.472527   \n",
       "20           0.194639           0.378155          -0.029036   \n",
       "21           0.747475           0.524466           0.734274   \n",
       "22          -0.056146          -0.025725          -0.187055   \n",
       "23           0.197467           0.372426           0.435342   \n",
       "24           0.743898           0.692108           0.721862   \n",
       "25           0.296560           0.350907           0.317310   \n",
       "26           0.285477           0.448750           0.296605   \n",
       "27           0.846216           0.512350           0.643021   \n",
       "28           0.338361           0.504672           0.490029   \n",
       "29           0.398959           0.482212           0.598950   \n",
       "30           0.559711           0.591731           0.717279   \n",
       "31          -1.147129          -4.607638          -5.959582   \n",
       "32          -0.006458          -0.003496          -0.026421   \n",
       "33           0.734346           0.461947          -0.052885   \n",
       "34           0.117792           0.030243           0.057638   \n",
       "35          -0.005422           0.281795          -0.032626   \n",
       "36           0.809361           0.556568          -0.035723   \n",
       "37           0.221126           0.340893           0.279918   \n",
       "38           0.111568          -0.000788          -0.051903   \n",
       "39           0.859760           0.719522           0.647666   \n",
       "40           0.378595           0.396887           0.397010   \n",
       "41           0.269901          -0.007207          -0.111506   \n",
       "42           0.857364           0.565901           0.571821   \n",
       "43           0.456264           0.512621           0.511898   \n",
       "44           0.226142           0.421521           0.349432   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0        7.145431e-01         0.770332        0.048729                3  \n",
       "1        5.690507e-01         0.694075        0.067141               10  \n",
       "2       -1.937841e-05        -0.008106        0.012028               40  \n",
       "3        6.361040e-01         0.751398        0.069308                7  \n",
       "4        6.614271e-01         0.682948        0.077275               12  \n",
       "5       -7.924098e-07         0.144624        0.293645               32  \n",
       "6        6.065841e-01         0.756829        0.081178                5  \n",
       "7        6.825114e-01         0.749255        0.060842                8  \n",
       "8       -7.414334e-06        -0.008729        0.013714               41  \n",
       "9        7.414004e-01         0.782625        0.026366                2  \n",
       "10       6.405538e-01         0.753888        0.072115                6  \n",
       "11      -1.245547e-05         0.121087        0.186787               33  \n",
       "12       6.372844e-01         0.757809        0.065538                4  \n",
       "13       7.907002e-01         0.842322        0.049666                1  \n",
       "14       5.077138e-05         0.070066        0.144429               36  \n",
       "15       1.270293e-01         0.359990        0.276440               25  \n",
       "16      -2.635523e+01       -19.755552       13.128143               45  \n",
       "17      -3.694988e-04         0.189500        0.155084               30  \n",
       "18       6.574054e-01         0.467290        0.224834               20  \n",
       "19      -2.592225e+00        -2.861423        1.887673               43  \n",
       "20      -6.606572e-04         0.108588        0.156699               34  \n",
       "21       6.633056e-01         0.684080        0.085917               11  \n",
       "22      -5.617319e-01        -0.183847        0.196567               42  \n",
       "23       4.375413e-01         0.367541        0.088539               24  \n",
       "24       6.870200e-01         0.715138        0.022085                9  \n",
       "25       2.810783e-01         0.249013        0.127074               29  \n",
       "26       3.910616e-01         0.372610        0.069578               22  \n",
       "27       4.705706e-01         0.635343        0.135347               13  \n",
       "28       4.997339e-01         0.474716        0.070307               19  \n",
       "29       5.560815e-01         0.506980        0.068147               17  \n",
       "30      -1.739638e-04         0.496238        0.253764               18  \n",
       "31      -7.613615e+00        -4.356237        2.330849               44  \n",
       "32      -2.665425e-04        -0.007352        0.009817               39  \n",
       "33       3.876769e-01         0.306154        0.295668               28  \n",
       "34       3.796972e-02         0.078681        0.046965               35  \n",
       "35      -1.070821e-03         0.048499        0.117254               37  \n",
       "36       1.939488e-01         0.372295        0.291373               23  \n",
       "37       4.522351e-01         0.334963        0.079829               26  \n",
       "38       1.820914e-01         0.048209        0.085649               38  \n",
       "39       2.265003e-01         0.598530        0.213176               15  \n",
       "40       4.164819e-01         0.387977        0.022070               21  \n",
       "41       3.588291e-01         0.165360        0.188533               31  \n",
       "42       4.278798e-01         0.631964        0.149291               14  \n",
       "43       5.533389e-01         0.526636        0.047589               16  \n",
       "44       3.498114e-01         0.332620        0.063386               27  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# résultats de la validation croisée\n",
    "res = mlp.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2297c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'activation': 'relu', 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(mlp.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf597809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8423216935001617\n"
     ]
    }
   ],
   "source": [
    "mlp_r2 = mlp.best_score_\n",
    "print(\"Best score: \", mlp.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a6de7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score du training set :  0.9501799859785902\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = mlp.predict(X_train)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "print(\"Score du training set : \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e2f45",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ee33ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5952a",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20c42aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4e598",
   "metadata": {},
   "source": [
    "#### Les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbaeb800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.329699</td>\n",
       "      <td>0.087225</td>\n",
       "      <td>0.912775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mse       rse        R²\n",
       "MLP  0.329699  0.087225  0.912775"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'mse':mse,\n",
    "    'rse' :rse,\n",
    "    'R²' : r2\n",
    "}\n",
    "df_mlp  = pd.DataFrame(scores, index = ['MLP'])\n",
    "df_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6899ded",
   "metadata": {},
   "source": [
    "### c.) Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f540eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire le meilleur estimator de GridSearchCV object\n",
    "best_mlp = mlp.best_estimator_\n",
    "\n",
    "# Calculate feature importances\n",
    "coefs = np.abs(best_mlp.coefs_[0])\n",
    "feature_importances = np.sum(coefs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "020f8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les importances de caractéristiques\n",
    "feat_imp = feature_importances\n",
    "\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance':feat_imp\n",
    "})\n",
    "# Trier la dataframe obtenué\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08b40951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BuildingType_4</td>\n",
       "      <td>14.929261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PrimaryPropertyType_3</td>\n",
       "      <td>13.731531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Neighborhood_7</td>\n",
       "      <td>12.972097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Attribute  Importance\n",
       "17         BuildingType_4   14.929261\n",
       "21  PrimaryPropertyType_3   13.731531\n",
       "47         Neighborhood_7   12.972097"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = importances.iloc[:3]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "679ec825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='red')\n",
    "plt.title('Feature importances ', size=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83401c3",
   "metadata": {},
   "source": [
    "## <a name=\"C35\"> 3.5) XGBoost </a>\n",
    "#### Installation de XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f03a3050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ebe65",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle\n",
    "#### modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a95d99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e75e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du modèle\n",
    "rp = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [1,2,3,4,5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf3fbddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec recherche d'hyperparamètre par validation croisée\n",
    "gb = GridSearchCV(estimator=rp, param_grid = param_grid, cv=5, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00a862d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=42, ...),\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.2],\n",
       "                         'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [100, 150, 200, 250, 300]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiser sur le jeu d'entraînement\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73a5667f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.195925</td>\n",
       "      <td>0.017543</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.851122</td>\n",
       "      <td>0.913402</td>\n",
       "      <td>0.909631</td>\n",
       "      <td>0.890400</td>\n",
       "      <td>0.680382</td>\n",
       "      <td>0.848987</td>\n",
       "      <td>0.087149</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.315552</td>\n",
       "      <td>0.018087</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.867228</td>\n",
       "      <td>0.950604</td>\n",
       "      <td>0.950211</td>\n",
       "      <td>0.942894</td>\n",
       "      <td>0.682023</td>\n",
       "      <td>0.878592</td>\n",
       "      <td>0.103168</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.431506</td>\n",
       "      <td>0.017306</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.868872</td>\n",
       "      <td>0.967311</td>\n",
       "      <td>0.963631</td>\n",
       "      <td>0.960808</td>\n",
       "      <td>0.676918</td>\n",
       "      <td>0.887508</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.529332</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.013851</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.867207</td>\n",
       "      <td>0.974646</td>\n",
       "      <td>0.969912</td>\n",
       "      <td>0.966753</td>\n",
       "      <td>0.671245</td>\n",
       "      <td>0.889953</td>\n",
       "      <td>0.116460</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.633455</td>\n",
       "      <td>0.016094</td>\n",
       "      <td>0.016906</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'n_est...</td>\n",
       "      <td>0.864680</td>\n",
       "      <td>0.978496</td>\n",
       "      <td>0.973332</td>\n",
       "      <td>0.970252</td>\n",
       "      <td>0.665259</td>\n",
       "      <td>0.890404</td>\n",
       "      <td>0.120304</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.370124</td>\n",
       "      <td>0.007878</td>\n",
       "      <td>0.028280</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.891584</td>\n",
       "      <td>0.994634</td>\n",
       "      <td>0.994302</td>\n",
       "      <td>0.990928</td>\n",
       "      <td>0.719168</td>\n",
       "      <td>0.918123</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.538772</td>\n",
       "      <td>0.025213</td>\n",
       "      <td>0.025177</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.891886</td>\n",
       "      <td>0.994779</td>\n",
       "      <td>0.994469</td>\n",
       "      <td>0.991085</td>\n",
       "      <td>0.718939</td>\n",
       "      <td>0.918232</td>\n",
       "      <td>0.107136</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.687539</td>\n",
       "      <td>0.026493</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.892039</td>\n",
       "      <td>0.994773</td>\n",
       "      <td>0.994496</td>\n",
       "      <td>0.991121</td>\n",
       "      <td>0.719060</td>\n",
       "      <td>0.918298</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.898691</td>\n",
       "      <td>0.048541</td>\n",
       "      <td>0.021913</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.891993</td>\n",
       "      <td>0.994786</td>\n",
       "      <td>0.994504</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.719175</td>\n",
       "      <td>0.918321</td>\n",
       "      <td>0.107058</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.069814</td>\n",
       "      <td>0.051609</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.892011</td>\n",
       "      <td>0.994788</td>\n",
       "      <td>0.994518</td>\n",
       "      <td>0.991174</td>\n",
       "      <td>0.719144</td>\n",
       "      <td>0.918327</td>\n",
       "      <td>0.107074</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.195925      0.017543         0.014618        0.002670   \n",
       "1        0.315552      0.018087         0.025559        0.005535   \n",
       "2        0.431506      0.017306         0.018027        0.003089   \n",
       "3        0.529332      0.016969         0.013851        0.003544   \n",
       "4        0.633455      0.016094         0.016906        0.002371   \n",
       "..            ...           ...              ...             ...   \n",
       "70       0.370124      0.007878         0.028280        0.006331   \n",
       "71       0.538772      0.025213         0.025177        0.005854   \n",
       "72       0.687539      0.026493         0.014962        0.001733   \n",
       "73       0.898691      0.048541         0.021913        0.007549   \n",
       "74       1.069814      0.051609         0.015782        0.000197   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                 0.05               1                100   \n",
       "1                 0.05               1                150   \n",
       "2                 0.05               1                200   \n",
       "3                 0.05               1                250   \n",
       "4                 0.05               1                300   \n",
       "..                 ...             ...                ...   \n",
       "70                 0.2               5                100   \n",
       "71                 0.2               5                150   \n",
       "72                 0.2               5                200   \n",
       "73                 0.2               5                250   \n",
       "74                 0.2               5                300   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.851122   \n",
       "1   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.867228   \n",
       "2   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.868872   \n",
       "3   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.867207   \n",
       "4   {'learning_rate': 0.05, 'max_depth': 1, 'n_est...           0.864680   \n",
       "..                                                ...                ...   \n",
       "70  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.891584   \n",
       "71  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.891886   \n",
       "72  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.892039   \n",
       "73  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.891993   \n",
       "74  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.892011   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.913402           0.909631           0.890400   \n",
       "1            0.950604           0.950211           0.942894   \n",
       "2            0.967311           0.963631           0.960808   \n",
       "3            0.974646           0.969912           0.966753   \n",
       "4            0.978496           0.973332           0.970252   \n",
       "..                ...                ...                ...   \n",
       "70           0.994634           0.994302           0.990928   \n",
       "71           0.994779           0.994469           0.991085   \n",
       "72           0.994773           0.994496           0.991121   \n",
       "73           0.994786           0.994504           0.991148   \n",
       "74           0.994788           0.994518           0.991174   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.680382         0.848987        0.087149               75  \n",
       "1            0.682023         0.878592        0.103168               74  \n",
       "2            0.676918         0.887508        0.111563               73  \n",
       "3            0.671245         0.889953        0.116460               72  \n",
       "4            0.665259         0.890404        0.120304               71  \n",
       "..                ...              ...             ...              ...  \n",
       "70           0.719168         0.918123        0.107000               45  \n",
       "71           0.718939         0.918232        0.107136               44  \n",
       "72           0.719060         0.918298        0.107092               43  \n",
       "73           0.719175         0.918321        0.107058               42  \n",
       "74           0.719144         0.918327        0.107074               41  \n",
       "\n",
       "[75 rows x 16 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# résultats de la validation croisée\n",
    "res = gb.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04f0c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(gb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "737d8f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.9368815931513573\n"
     ]
    }
   ],
   "source": [
    "gb_r2 = gb.best_score_\n",
    "print(\"Best score: \", gb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e130ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score du training set :  0.99980840204639\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = gb.predict(X_train)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "print(\"Score du training set : \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fa1fc",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78c89243",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b099f93",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d9959c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9db85c",
   "metadata": {},
   "source": [
    "### Les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0f858b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.050173</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.986726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mse       rse        R²\n",
       "XGBoost  0.050173  0.013274  0.986726"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'mse':mse,\n",
    "    'rse' :rse,\n",
    "    'R²' : r2\n",
    "}\n",
    "df_gb  = pd.DataFrame(scores, index = ['XGBoost'])\n",
    "df_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ed7d3",
   "metadata": {},
   "source": [
    "### c.) Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f9de4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les importances de caractéristiques\n",
    "feat_imp = gb.best_estimator_.feature_importances_\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance':feat_imp\n",
    "})\n",
    "# Trier la dataframe obtenué\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "76b2499c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SiteEUI(kBtu/sf)</td>\n",
       "      <td>0.653964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Electricity(kBtu)</td>\n",
       "      <td>0.171460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaturalGas(kBtu)</td>\n",
       "      <td>0.033160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Attribute  Importance\n",
       "8    SiteEUI(kBtu/sf)    0.653964\n",
       "11  Electricity(kBtu)    0.171460\n",
       "12   NaturalGas(kBtu)    0.033160"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = importances.iloc[:3]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee7030cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='red')\n",
    "plt.title('Feature importances ', size=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea273f0",
   "metadata": {},
   "source": [
    "# <a name=\"C4\"> CHOIX DU MODELE </a>\n",
    "## <a name=\"C41\"> 4.1) Tableau récapitulatif des scores du modèle </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebeb23a",
   "metadata": {},
   "source": [
    "#### best scores issus du GridSearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d40834af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear reg</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>grd boosting</th>\n",
       "      <th>mlp</th>\n",
       "      <th>XGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R²</th>\n",
       "      <td>0.654792</td>\n",
       "      <td>0.898771</td>\n",
       "      <td>0.94188</td>\n",
       "      <td>0.842322</td>\n",
       "      <td>0.936882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    linear reg  RandomForest  grd boosting       mlp       XGB\n",
       "R²    0.654792      0.898771       0.94188  0.842322  0.936882"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'linear reg':lr_r2,\n",
    "    'RandomForest':rfr_r2,\n",
    "    'grd boosting' : gbr_r2,\n",
    "    'mlp' : mlp_r2,\n",
    "    'XGB' :gb_r2\n",
    "}\n",
    "R2  = pd.DataFrame(scores, index = ['R²'])\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b23ea8",
   "metadata": {},
   "source": [
    "Comme, nous pouvons le constater dans le tableau le modèle présentant le meilleur score est celui de : **Gradiant Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe4187",
   "metadata": {},
   "source": [
    "#### Tableau compilatif des scores du testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ab8fc51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Régression Linéaire</th>\n",
       "      <td>0.821181</td>\n",
       "      <td>0.178403</td>\n",
       "      <td>0.821597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.077860</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.979401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forêt Aléatoire</th>\n",
       "      <td>0.171782</td>\n",
       "      <td>0.045447</td>\n",
       "      <td>0.954553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.329699</td>\n",
       "      <td>0.087225</td>\n",
       "      <td>0.912775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.050173</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.986726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mse       rse        R²\n",
       "Régression Linéaire  0.821181  0.178403  0.821597\n",
       "Gradient Boosting    0.077860  0.020599  0.979401\n",
       "Forêt Aléatoire      0.171782  0.045447  0.954553\n",
       "MLP                  0.329699  0.087225  0.912775\n",
       "XGBoost              0.050173  0.013274  0.986726"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF1 = pd.concat([df_lr,df_gr,df_rfr,df_mlp,df_gb])\n",
    "DF1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e993c221",
   "metadata": {},
   "source": [
    "## <a name=\"C42\"> 4.2) Modèle Gradiant Boosting avec la librairie LIME </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1675c25",
   "metadata": {},
   "source": [
    "#### Installation de la librairie LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8b5d5dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lime in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (0.2.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from lime) (1.0.2)\n",
      "Requirement already satisfied: scikit-image>=0.12 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from lime) (0.19.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from lime) (4.64.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from lime) (3.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from lime) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from lime) (1.7.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2021.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (21.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (9.0.1)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2.7.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from packaging>=20.0->scikit-image>=0.12->lime) (3.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->lime) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->lime) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from matplotlib->lime) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from matplotlib->lime) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from matplotlib->lime) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from matplotlib->lime) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dmedc\\anaconda3\\lib\\site-packages (from tqdm->lime) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877b689",
   "metadata": {},
   "source": [
    "#### Feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9c844f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f9ff38c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 0:\n",
      "True value: 14.154190890660312\n",
      "Predicted value: 14.23756749332124\n",
      "Explanation: \n",
      "[('SiteEUI(kBtu/sf) <= 3.48', -0.7611105194815003), ('13.43 < Electricity(kBtu) <= 14.27', -0.6384547284112523), ('SourceEUI(kBtu/sf) <= 4.31', 0.31276738082161826), ('SteamUse(kBtu) <= 0.00', -0.28887938611685576), ('0.00 < NaturalGas(kBtu) <= 13.11', -0.26380769412571203)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 1:\n",
      "True value: 19.495992961993323\n",
      "Predicted value: 19.52327601396316\n",
      "Explanation: \n",
      "[('Electricity(kBtu) > 15.29', 1.882900990921605), ('NaturalGas(kBtu) > 14.18', 0.7020600383343478), ('SiteEUI(kBtu/sf) > 4.39', 0.5091913301158588), ('SteamUse(kBtu) > 0.00', 0.3748958890312221), ('PropertyGFABuilding(s) > 11.41', 0.16207157245794387)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 2:\n",
      "True value: 17.538779458047447\n",
      "Predicted value: 17.506272452171572\n",
      "Explanation: \n",
      "[('Electricity(kBtu) > 15.29', 1.888209420926598), ('NaturalGas(kBtu) > 14.18', 0.684791333266834), ('SiteEUI(kBtu/sf) > 4.39', 0.47339006300144637), ('SteamUse(kBtu) <= 0.00', -0.3380970968011008), ('PropertyGFABuilding(s) > 11.41', 0.15035378610313244)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAEVCAYAAACSfo1yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArv0lEQVR4nO3de7ymc73/8dfbqSEyNEPOk+RYGloIqRHbdips2hQ5bDup/KTSWRm0a7fbbaJkyzHnlKQolBEVsTDGyDlsp8w4hibH9++P67vMNbd7rXWvNWtmrTXX+/l43I+57+/1PV3Xurk+1/f7va9LtomIiIhmWmi4OxARERHDJ4FAREREgyUQiIiIaLAEAhEREQ2WQCAiIqLBEghEREQ0WAKBiGgsSV+WdNJw9yNiOCUQiIhBkXSfpFmSnq29VhyCOrceqj72x/Y3bP/7/GqvL5ImSzpzuPtRJ+l1kk6WdL+kZyTdJGm74e5XDK0EAhExN95ve8na6+Hh7IykRYaz/cEawf1eBHgAeC+wNPBV4MeSJgxnp2JoJRCIiCElaelyFfmIpIckfV3SwmXbWyRdIelxSY9JOkvS2LLtDGBV4BdldOHzkiZJerCl/ldHDcpV9E8knSnpb8C+fbXfpq+vXoVLmiDJkvaT9ICkJyUdKGkjSdMkPSXpe7Wy+0r6g6TjJD0t6XZJW9W2ryjpIklPSLpb0kdb2q33+0Dgy8DuZd9vLvn2k3RbuRr/i6SP1eqYJOlBSZ+VNKPs73617YtL+k65mn9a0u8lLV62vUvSH8s+3SxpUrvjY/s525Nt32f7Fdu/BO4F3tnP1yBGkQQCETHUTgdeAtYANgC2AXqG3wV8E1gRWAdYBZgMYPsjwP8xe5ThvzpsbyfgJ8BY4Kx+2u/EJsBbgd2BY4CvAFsD6wH/Kum9LXn/AowDDgcukLRs2XYO8GDZ192Ab9QDhZZ+nwx8Aziv7Ps7Sp4ZwI7AG4D9gKMlbVir401UV+orAfsD35e0TNn231Qn7M2AZYHPA69IWgm4GPh6ST8U+Kmk8f0dGEnLA2sCt/aXN0aPBAIRMTcuLFeVT0m6sJwotgMOKVeTM4CjgT0AbN9t+3Lbz9ueCfwP1bDz3LjG9oW2X6E6YfbafoeOsv0P25cBzwHn2J5h+yHgaqrgoscM4BjbL9o+D7gD2EHSKsC7gS+UuqYCJwEfaddv27PadcT2xbbvceV3wGXAFrUsLwJHlvYvAZ4F1pK0EPBvwKdsP2T7Zdt/tP08sBdwie1LStuXA93A9n0dFEmLUgIt27f3fxhjtBip81IRMTrsbPs3PR8kbQwsCjwiqSd5Iap5ZiQtBxxLdTJbqmx7ci778EDt/Wp9td+hR2vvZ7X5vGTt80Oe88lt91ONAKwIPGH7mZZtXb30u62yMO9wqqvwhYAlgFtqWR63/VLt899L/8YBY4B72lS7GvBBSe+vpS0KTOmjHwsBZwAvAAf11+8YXRIIRMRQegB4HhjXcoLq8U3AwPq2H5e0M/C92vbWx6E+R3XyA6DM9bcOYdfL9Nf+UFtJkmrBwKrARcDDwLKSlqoFA6sCD9XKtu7rHJ8lvQ74KbA38HPbL0q6kGp6pT+PAf8A3gLc3LLtAeAM2x99Tak2VEVUJwPLA9vbfrGTcjF6ZGogIoaM7Ueohq+/I+kNkhYqCwR7hv+Xohq+fqrMVX+upYpHgdVrn+8ExkjaoQxNHwa8bi7aH2rLAQdLWlTSB6nWPVxi+wHgj8A3JY2RtD7VHP5ZfdT1KDChXH0DLEa1rzOBl8rowDaddKpMk5wC/E9ZtLiwpE1LcHEm8H5J/1zSx5SFhyv3Ut0Pyn69v7cpjBjdEghExFDbm+ok9meqYf+fACuUbUcAGwJPUy1Yu6Cl7DeBw8qag0NtPw18gmp+/SGqEYIH6Vtf7Q+1P1EtLHwM+A9gN9uPl20fAiZQjQ78DDi8zMf35vzy7+OSbiwjCQcDP6bajw9TjTZ06lCqaYTrgSeAbwELlSBlJ6pfKcykGiH4HG3OB5JWAz4GTAT+qtn3i9hzAP2IEU5zTm9FREQnJO0L/Lvtdw93XyLmRkYEIiIiGiyBQERERIMlEIiIRlCbuxTODdun9TctULtb4Xz/hZakPSVdNr/bjdEngUBEDBvN54cMLajaBRy2z7Ld0a8MotkSCERERDRYAoGIGHFUPf72GEkPl9cx5TfwPdt3kjRV0t8k3SNp25Le60N6OmhzbUmXq3pI0B2S/rWkv6WkbVg+r6jqgUmTyucrJX1T0nXl4T4/rz1voLWNXvun/h8itIOqxwD/TdVDkSbXqr6q/PtU+XnfpqoeivT7WvnNJF1f+ni9pM1q266UdJSqhyg9I+kySeM6PXYxuiUQiIiR6CvAu6h+v/4OYGOqmwn13Mb4R1S/fR8LvAe4r5Tr7yE9bUl6PXA5cDbVTYI+BBwvaT3b9wBfAM6StARwKnCa7StrVexNdW//FakeeHRsL03NzUOEnivtjAV2AD6u6s6MlGMAMLY8tOialv1bluq+DccCb6R6xsPFkt5Yy/bh0qflqO7DcGgv+xALmAQCETES7Un1MJ0Z5eFERzD7gT37A6eUhxe9Uh6qczt09JCe3uwI3Gf7VNsv2b6R6va+u5V6fwjcRXUDoRWoApW6M2xPt/0c8FWqpxS+5tHHg32IUCl7pe1byj5Po3q6Yad3TNwBuMv2GWX/zgFuB+rPGzjV9p3l7oE/pgrCogESCETESLQi1UN6evQ8zAeqRxe3e5gOkraTdG0Zyn+K6ol6nQxxrwZsotlPUnyKKhh5Uy3PD4G3AceVp/jV1R8gdD/VQ3xe024H/evtIUJI2kTSFEkzJT0NHNjhvsFrj2dPP1eqff5ru3ZjwZdAICJGooepTs49Vi1pUJ1039JaQLMf0vPfwPK2xwKX0NlDeh4Afmd7bO21pO2Pl7qXBI6hevjO5DZrAFZp6euLVLcdHqr+QTVtcRGwiu2lgRNqZfu7RWzr8ezp50Nt8kbDJBCIiOG2aHnwTc9rEaph78MkjS+L1r5G9bAcqE7G+0naStVDhVaStDZz8ZAe4JfAmpI+ouoBQotK2kjSOmX7d4EbbP871Vz7CS3l95K0bllDcCTwE9svt+SZm/5B9cCmJ2z/o6yT+HBt20zgFeZ8YFPdJWX/PixpEUm7A+uW/Y6GSyAQEcPtEmBW7TUZ+DrQDUyjenDOjSUN29dRFtpRPbzod8Bqc/OQnlJ2G2APqqvnv1I9pOd1knYCtqUaigf4DLCh5nzwzhnAaaXcmNKPdm3MzUOEPgEcKekZqsDox7W6/0710KM/lKmNd7W0/TjVOojPAo8Dnwd2tD3HqEU0Ux46FBExFyRdCZxp+6Th7kvEYGREICIiosESCERERDRYpgYiIiIaLCMCERERDTbfH40ZMbfGjRvnCRMmDHc3IiJGlRtuuOEx2+Nb0xMIxKgzYcIEuru7h7sbERGjiqTWu0sCmRqIiIhotAQCERERDZZAICIiosESCERERDRYAoGIiIgGSyAQERHRYAkEIiIiGiyBQERERIPlhkIRo4CO0HB3ISJGAB8+9M8HyohAREREgyUQiIiIaLAEAhEREQ2WQCAiIqLBEghEREQ0WAKBiIiIBksgEBER0WAJBCIiIhosgUBERESDJRCIiIhosAQCERERDZZAICIiosFGVSAg6WVJU2uvL5b0KyV1DaK+iZK272N7l6Rj+6njEkljy+sTHba7gaSTyvvJkg5tk+c0SfeW/bxd0uG1bYdIWqKDdg6StF8nfeqgrl9LekrSL/vo51RJE9uUnSjpGkm3SpomaffatvdJulHSdEmnS8qDsCIi5qNRFQgAs2xPrL3+cy7rmwi0DQQkLWK72/bBfVVge3vbTwFjgY4CAeDLwHEd5Puc7Ymln/tIenNJPwToNxAATgHa9l/SMh2Ur/s28JFetn2u9jeZ2mb734G9ba8HbAscUwKnhYDTgT1svw24H9hngP2KiIi5MNoCgX5J2qZcfd4o6XxJS5b0jST9UdLNkq6TtDRwJLB7uZLdvVydnyjpMuBHkib1XAFLWlLSqZJuKVe1u5b0+ySNA/4TeEup69uSzpC0U61fZ0n6gKSlgPVt39ym7x+V9CtJi7dsGlP+fU7SwcCKwBRJU0q5Z2t17CbpNADbfwfuk7Rxm0O1e7kKP1TS+P6Oq+3fAs/0l6+Xsnfavqu8fxiYAYwH3gg8b/vOkvVyYNfBtBEREYMz2gKBxVumBnavbywn5MOArW1vCHQDn5G0GHAe8Cnb7wC2Bp4DvgacV65kzyvVvBPYyfaHW9r+KvC07bfbXh+4omX7F4F7Sl2fA04C9iv9WhrYDLgE6AKmt+6YpIOA9wM7255Vkr8taSrwIHCu7Rm2jwUeBra0vWUHx6wb2KI10fYJwHbA4sBVkn4iadtylT5Q/1GCo6Mlva6vjCUoWQy4B3gMWLQ2rbMbsMog2o+IiEEabYFA69TAeS3b3wWsC/yhnED3AVYD1gIesX09gO2/2X6plzYuqp2I67YGvt/zwfaTfXXU9u+ANSQtB3wI+GlpcwVgZkv2j1CdlHe1/XwtvWdq4E3AVpI266vNXsygGkFo18cHbB9FdcxOLq8LB1j/l4C1gY2AZYEv9JZR0grAGcB+tl+xbWAP4GhJ11GNOLT9u0g6QFK3pO6ZM1sPX0REDNZoCwT6I+DyWqCwru39S7o7rOO5PurutI4eZwB7Uo0MnFrSZjF7qL/HdGACsHK7Smw/C1wJvLuXdur9aq17TGmzrXKFfjzVmoXzqU7sHbP9iCvPU+1ju2kIJL0BuBg4zPa1tfLX2N7C9sbAVcBdvbRzou0u213jx/c7kxERER1a0AKBa4HNJa0BIGkJSWsCtwMrStqopC9VVqc/AyzVYd2XAQf1fGiz2K5dXadRLezD9q0l7TZgjZZ8NwEfAy6S9Jqr99LXTaiG09u19aikdcqw/i4txdek/VTENpKmAV+nCjLWtX1IrZ8dKVf5SBKwcy9tLQb8DPiR7fNbti1X/n0d1WjCCQNpPyIi5s5oCwRa1wjM8asB2zOBfYFzyknuWmBt2y8AuwPHSbqZalHaGGAKsG679QZtfB1YpiywuxmYY37e9uNUUxLTJX27pD1KdeI/tZbvdmDpsmiwXv73wKHAxWWtA8xeIzANuAW4oKSfCPyqZ7Eg1fqEX1KtW3ikpd+bA79psz+PA++3vY3t88ox6pWkq6lGDLaS9KCkfy6bzpJ0S+nfuHKcen56eVLJ86/Ae4B99dqfGX5O0m1lH39hu3XtRUREzEOqpmljXlD1W/9bgA1tP11L/zTwjO2Tei08NO1vAHzGdm8/+xuVurq63N3dPdzdmK90hIa7CxExAvjwwZ+zJd1g+zX33BltIwKjhqStqaYkjqsHAcUPgOdfW2rIjaP6tUNERERbuYvbPGL7N8CqvWz7B9VCwnndh8vndRsRETG6ZUQgIiKiwRIIRERENFgCgYiIiAZLIBAREdFgCQQiIiIaLIFAREREgyUQiIiIaLAEAhEREQ2WQCAiIqLBcmfBiFFgbu4vHhHRl4wIRERENFgCgYiIiAZLIBAREdFgCQQiIiIaLIFAREREgyUQiIiIaLAEAhEREQ2W+whEjAI6QsPdhUbK/RuiCTIiEBER0WAJBCIiIhosgUBERESDJRCIiIhosAQCERERDZZAICIiosESCERERDRYAoGIiIgGSyAQERHRYAkEIiIiGiyBQERERIMlEIiIiGiwBAIRERENNiIDAUmW9J3a50MlTe6nzCRJmw1xP+6TNK68X17S2ZL+IukGSddI2mWQ9UrSFZLeIGmCpOlt8kyS9LSkqZKmSfqNpOVq2/rdV0njJf16MH1sU9dBku4uf5txbbZvJOllSbsNpLykpSX9QtLNkm6VtN9Q9DciIjozIgMB4HngX9qdcPowCRhQICBp4Q7zCbgQuMr26rbfCewBrDyQ9mq2B262/bd+8l1te6Lt9YHrgU+W9El0sK+2ZwKPSNq8dZukxSS9fgB9/gOwNXB/m7oWBr4FXDqI8p8E/mz7HVT79R1Jiw2gXxERMRdGaiDwEnAi8OnWDZLeL+lPkm4qV8nLS5oAHAh8ulxBbyHptPrVqaRny7+TJE2RdDZwS0m7sFzl3yrpgDb9eR/wgu0TehJs32/7uFJ+gqSrJd1YXpuV9BUkXVX6NF3SFqX4nsDP2+zb6mW/NmpJF7AU8ORA9rW4sLTXahngVkn/29peO7Zvsn1fL5v/H/BTYMYgyhtYquzjksATVH//iIiYD0ZqIADwfWBPSUu3pP8eeJftDYBzgc+XE8wJwNHlCvrqfureGPiK7XXL538rV/ldwMGS3tiSfz3gxj7qmwH8k+0Ngd2BY0v6h4FLbU8E3gFMLembAzfUK5C0FtXJdD/b15fkLSRNBf6P6mr6lEHsazewRWui7UeBtYApwH+UAORgScv2U98cJK0E7FL6NBjfA9YBHqYKzD5l+5U27RwgqVtS98yZMwfZVEREtBqxgUAZNv8RcHDLppWBSyXdAnyO6iQ9UNfZvrf2+WBJNwPXAqsAb+2rsKTvlzntnhP2osAPS5/OB3oCjOuB/cr6hrfbfqakL1t7DzCeaoRgL9tTa+k9UwOrAKcC/zXQHaUKUlZst8H287bPtb0NsBNVsPGwpLb5e3EM8AXbLw+ibwD/TBUgrQhMBL4n6Q1t+nqi7S7bXePHjx9kUxER0WrEBgLFMcD+QH0u+zjge7bfDnwMGNNL2Zco+1eGnevzzs/1vJE0ieoEuGmZp76pTZ23Ahv2fLD9SWArqhM4VFMYj1Jd9Xf1tGX7KuA9wEPAGZL27umbpPqxfxp4gGqkoDcXlboGuq9jgFm9VSppOUmfBX4BLEw1ivFoH/1o1QWcK+k+YDfgeEk7D6D8fsAFrtwN3AusPYDyERExF0Z0IGD7CeDHVMFAj6WpTqwA+9TSn6GaR+9xH/DO8n4nqqv2dpYGnrT9d0lrA+9qk+cKYIykj9fSlmip45EypP0RqhMqklYDZtj+IXAys4OJO4DVa+VfAHYG9pb04V76+W7gnvJ+IPu6JtDuVwlLS7oQuApYHNje9g62LxjI1b3tN9ueYHsC8BPgE7Yv7LQ81bTHVqVPy1NNV/xlAOUjImIujOhAoPgOUP/1wGTgfElXA4/V0n8B7NKzgA74IfBeSdcBm1AbBWjxa2ARSdOAo6imB+Zg21Qn6vdKurfUeTrwhZLleGAfSddSnXh72poETJV0E7Ar8N2SfnHZVm/jOWBHqkWAO5XkLcr+3EwVYHx2EPu6ZWmvnWOBdWx/3fZDveQBoKwfeJBqamaapJP6yl/KXNIzzdBH+aOAzcq0ym+pphkea19jREQMNVXnuJifJK0A/Mj2P82Htq4CdrL95Lxua37p6upyd3f3cHdjvtIRGu4uNJIPz/8fY8Eh6QbbXa3po2FEYIFj+xGqxYWvWRQ3lCSNB/5nQQoCIiJiaC0y3B1oKts/ng9tzKS6j0BERERbGRGIiIhosAQCERERDZZAICIiosESCERERDRYAoGIiIgGSyAQERHRYAkEIiIiGiyBQERERIPlhkIRo0BudRsR80pGBCIiIhosgUBERESDJRCIiIhosAQCERERDZZAICIiosESCERERDRYAoGIiIgGSyAQERHRYLmhUMQooCM03F0YdrmpUsS8kRGBiIiIBksgEBER0WAJBCIiIhosgUBERESDJRCIiIhosAQCERERDZZAICIiosESCERERDRYAoGIiIgGSyAQERHRYAkEIiIiGiyBQERERIMtcIGApK9IulXSNElTJW1S0k+StG55/+UO67pP0i2lnqmSji3pV0rqquWbIGl6eT9J0i9r23aW9LXy/jRJu7Vp50pJd5Q2bpN0QG1bR30teTeV9MM+th9c6j9L0o6Sjui07g7aXljSTfV9b9m+U+1v0i3p3bVtn5I0vfzdDhmqPkVERP8WqKcPStoU2BHY0PbzksYBiwHY/vda1i8D3+iw2i1tPzYX3fo88IEO8u1pu1vSssA9kk6z/QID6+u2wK/72P4JYDvb90oScJSkb9n+ez2TpKWBZ2y/0mG7AJ8CbgPe0Mv23wIX2bak9YEfA2tLehvwUWBj4AXg15Iutn3XANqOiIhBWtBGBFYAHrP9PIDtx2w/DLOv4iX9J7B4uTI9q2zbS9J1Je1/JS08FJ2RtCbwfLtAQtJRZYSg9W+wJPAc8HJrX+sjD6WOQyVNrpXdCviNpPVq+zNN0lslnQCsDlwk6dO2DVxJFTi1ejdwh6TJklbtYD9XBnYATuotj+1nS5sArwd63q8DXGv777ZfAn4H7NJfmxERMTQWtEDgMmAVSXdKOl7Se1sz2P4iMMv2RNt7SloH2B3Y3PZE4GVgz1qRKbWpgU8PsD+bAze2Jkr6L2A5YL/aVfdZkqYBdwBH2X65ta99NVRGP160/TRwIPDdsj9dwIO2DwQephrhOLoU6wa2aK3L9sXApsBTwM8lXSrpg5IW66X5Y6hGPvocQZC0i6TbgYuBfyvJ04H3SHqjpCWA7YFV2pQ9oEwpdM+cObOvZiIiYgAWqEDA9rPAO4EDgJnAeZL27afYVqXM9ZKmls+r17ZvWU7EE2snUPNa7dJWKP2o+yow1vbHalfIUE0NrA+sChwqabV++t1qG6pACOAa4MuSvgCsZntWL2VmACu221BGU46xvQEwGTiSKnCYg6QdgRm2b+ivg7Z/ZnttYGfgqJJ2G/At4HKqaY2bgZfalD3RdpftrvHjx/fXVEREdGiBCgQAypX0lbYPBw4Cdu2niIDTayf7tWxP7qfM48Aytc/LAu3WEcwCxrSkXQ+8s6wFaNf/mVSjCJu02fwSc/7N6nVvR1kfYPtsqnUJs4BLJb2vl/0YU/K0JWldSd8GzgD+SDWX32pz4AOS7gPOBd4n6cze6iz9uwp4SxnFwPbJtje0/R7gCSDrAyIi5pMFKhCQtJakt9aSJgL3t8n6oqRFy/vfArtJWq7UsWwHV+NXAnuVBXcA+wBT2uS7DVijJe3XwH8CF0taqs0+LAFsANzTpq+PAsuVYfTXUeb3Sz/WB6aWz6sDf7F9LHBR2dbOmlRD86192FDStVRz/rcDE23vb/tPrXltf8n2yrYnAHsAV9jeq02da/QcL0kbUi3ifLx87jn2qwL/ApzTS38jImKILVC/GqBaaHecpLFUV893U00TtDoRmCbpxrJO4DDgsrJw70Xgk8wOIKZIerm8n2Z771J+beBmSaYaMv9Sm3auAr4jSfVpANvnlyDgIknbl+SzJM0CXgecVhtqb+3rkcCfgHupTtJQTW3cVGtjd6pA5UXgr1TD+u1s2Uu/Z1GtX7itl3IdkXQggO0TqEZm9i59mgXsXuvvTyW9kXLsbT85N+1GRETnNOc0dQw1Sd8FfmH7N/OwjcOAu22fO4AyywNn295qXvVrXunq6nJ392uWKyzQdIT6z7SA8+H5f1XE3JB0g+2u1vQFbURgJPoG7ef7h4ztrw+i2KrAZ4e6LxERMbokEJjHbD9KNU8/oti+frj7EBERw2+BWiwYERERA5NAICIiosESCERERDRYAoGIiIgGSyAQERHRYAkEIiIiGiyBQERERIMlEIiIiGiwBAIRERENljsLRowCuc9+RMwrGRGIiIhosAQCERERDZZAICIiosESCERERDRYAoGIiIgGSyAQERHRYAkEIiIiGiz3EYhmkYa7B4Pj3EcgIuaNjAhEREQ0WAKBiIiIBksgEBER0WAJBCIiIhosgUBERESDJRCIiIhosAQCERERDZZAICIiosESCERERDRYAoGIiIgGSyAQERHRYAkEIiIiGmzEBwKSviLpVknTJE2VtElJP0TSEvO47QmSprekTZZ06CDr20DSSX3VI+k0SfeWfb1d0uG1bR3ts6SDJO03mD4OlKQ3S/qTpLsknSdpsV7y7VPy3CVpn4GWj4iIeWNEBwKSNgV2BDa0vT6wNfBA2XwIME8DgXngy8BxHeT7nO2JwERgH0lvLumH0Nk+nwIcPJCOSVp2IPlrvgUcbfutwJPA/r3UfTiwCbAxcLikZTotHxER886IDgSAFYDHbD8PYPsx2w9LOhhYEZgiaQqApG0kXSPpRknnS1qypH9N0vWSpks6UaqeQyvpSklHS7pK0m2SNpJ0Qbky/XonnZN0sKQ/l9GKc0va6yWdUtq8SdJOJX0pYH3bN7ep56OSfiVp8ZZNY8q/z/Wyz8/W6thN0mnlOP0duE/Sxv30f4ykPUt9x3ayzy3lBbwP+ElJOh3YuU3WfwYut/2E7SeBy4FtB1A+IiLmkZEeCFwGrCLpTknHS3ovgO1jgYeBLW1vKWkccBiwte0NgW7gM6WO79neyPbbgMWpRhh6vGD7PcAJwM+BTwJvA/aV9MYO+vdFYIMyWnFgSfsKcIXtjYAtgW9Lej3QBUxvrUDSQcD7gZ1tzyrJ35Y0FXgQONf2jNZ97qBv3cAW7TZIeoek40p/NgUOtb1X2bZWmZZo9xrbUtUbgadsv1Q+Pwis1KbJlZg9klPP12l5JB0gqVtS98yZM/vZ9YiI6NSIDgRsPwu8EzgAmAmcJ2nfNlnfBawL/KGcQPcBVivbtixz0LdQXX2uVyt3Ufn3FuBW24+U0Ye/AKsA7q1r5d9pwFmS9gJ6TmbbAF8s/biS6qp+VarRjdYz2EeA7YBde0Y9ip6pgTcBW0narJd+9GUG1QjCHCR9BvgTcCewnu2DbN/w6o7Zd9ie2Mvrqdbq2rTb7pj1lq/T8tg+0XaX7a7x48e3yxIREYOwyHB3oD+2X6Y6oV5ZTub7AKe1ZBPV0POH5kiUxgDHA122H5A0mdnD7QA9J99Xau97Pi8CPA4sw5yWBe4t73cA3gN8APiqpPVKX3a1fUdLX9ZuaRuqK/KJwMq1Ouv7/qykK4F3A39s3c6cJ83WuscAs3itM4FFgY9RBUmnAr/quSqXtBZwXptyAJNagoHHgLGSFinlV6YatWj1IDCp9nllqr9pp+UjImIeGdEjAmWY+q21pInA/eX9M8BS5f21wOaS1ijllpC0JrNPjo+VNQO7DaT9MiLxiKStSr3LAtsCv5e0ELCK7SnA54GxwJLApcD/q61F2KBUdxuwRksTN1GdkC+S1O7qfRGqBXb3tNlngEclrVP6sktL8TVpMxVRphm+VaZKjqE6JneWkYIBjQjYNjCF2cd1H6opllaXAttIWqYsEtwGuHQA5SMiYh4Z0YEA1Yn19J4FeVTD/5PLthOBX0maYnsmsC9wTsl3LbB2OXH9kGro/0Lg+kH0YW/gsDLUfwVwhO17gIWBM8soxU1UK9+fAo6iuuKepuqnh0cB2L4dWLosGnyV7d8DhwIXl7UOMHuNwLTS9wta97l8/iLwy9KvR1r6vTnwm752zPZVtvehCrCmdXIw2vgC8BlJd1PN+Z8MIKlL5aeStp+gOg7Xl9eRJa3X8hERMX+ouiiL+UHSp4FnbJ80j9vZAPiM7Y/My3aGS1dXl7u7uwdXWO2WJYwC+e80IuaSpBtsd7Wmj/QRgQXND5hzLcK8Mg746nxoJyIiRrkRv1hwQWL7H8AZ86Gdy+d1GxERsWDIiEBERESDJRCIiIhosAQCERERDZZAICIiosESCERERDRYAoGIiIgGSyAQERHRYAkEIiIiGiyBQERERIPlzoLRLLlnf0TEHDIiEBER0WAJBCIiIhosgUBERESDJRCIiIhosAQCERERDZZAICIiosESCERERDRY7iMQMQroCA15nT4891SIiIwIRERENFoCgYiIiAZLIBAREdFgCQQiIiIaLIFAREREgyUQiIiIaLAEAhEREQ2WQCAiIqLBEghEREQ0WAKBiIiIBksgEBER0WAJBCIiIhqs30BA0suSpkqaLul8SUvMj47V2j+kkzYlLS/pbEl/kXSDpGsk7VK2TZL0dNmPqZJ+Uyv3c0nXtNQ1WdJDJe/tkn4gqc9jJalL0rHl/b6SvtdLvmfLvytK+kn/R6DPNg+RtHcf23eUdMTctFGr6xRJMyRNb0n/oKRbJb0iqaufOhaWdJOkXw6mfEREDL1ORgRm2Z5o+23AC8CB9Y2SFp4nPZtd9yFAn4GAJAEXAlfZXt32O4E9gJVr2a4u+zHR9tal3FhgQ2CspDe3VHu07YnAusDbgff21Qfb3bYP7nDXsP2w7d06zd9K0iLAvwFn95HtYuAD7QIpSUv3F9y0OA3Ytk36dOBfgKs6qONTwG1zUT4iIobYQKcGrgbWKFfYUySdDdwiaYykUyXdUq74toRXr4x/LunXku6QdHhPRZL2knRduer+356AQtKzko6U9CfgK8CKwJTS3v6Sjq7V8VFJ/wO8D3jB9gk922zfb/u4fvZnV+AXwLlUgUM7iwFjgCdLm1f2XLlKGifpvvJ+Uv1Kt9bHN5fRieslHVVLn9BzdV2O0wXlON0l6b9q+faXdGdp94e1kYb3ATfafqnkO1jSnyVNk3RuOQYGrgR2bLNf7wbuKKMfq/ZznLB9FfBEm/TbbN/RX3lJKwM7ACcNpnxERMwbHQcC5Qp0O+CWkrQx8BXb6wKfBLD9duBDwOmSxtTy7QlMBD5YhtDXAXYHNi9X3S+XPACvB6bb3sT2kcDDwJa2t6Q6YX9A0qIl737AqcB6wI397MIWtamBr5S0DwHnlNeHWvJ/WtJU4BHgTttT+6m/N98FfmB7I+CvfeSbSHVM3g7sLmkVSSsCXwXeBfwTsHYt/+bADbXPXwQ2sL0+c47adANbtDZm+2JgU+Ap4OeSLi3D9IsNbPc6dgzweeCVwRSWdICkbkndM2fOHNKORUQ0WSeBwOLlhNgN/B9wckm/zva95f27gTMAbN8O3A+sWbZdbvtx27OAC0rerYB3AteXurcCVi/5XwZ+2q4jtp8DrgB2lLQ2sKjtW1rzSfq+pJslXV9Lrk8N/Iek5YE1gN/bvhN4SdLbavl7pgaWA14vqbcRg/5sThVoQDlGvfit7adt/wP4M7AaVRD1O9tP2H4ROL+WfwWgfkacBpwlaS/gpVr6DKpRldew/ZjtY2xvAEwGjqT6Ow8pSTsCM2zf0G/mXtg+0XaX7a7x48cPYe8iIpptkQ7yzConxFdVU/I8V0/qo7zbfBZwuu0vtcn/D9sv91HfScCXgdupRgMAbqUa5q8asD8paRx9n9R2B5YB7i378waq6YHD5uis/aKkXwPvoRqReInZAdQYOtN6DNp5vvb+Zaq/TV/HdVZL+zuUPn4A+Kqk9cq0wZiSty1J61KNrOwC/A44sYO+DtTmVCM525f+vEHSmbb3mgdtRUTEAAzVzwevogztS1oTWBXomff9J0nLSloc2Bn4A/BbYDdJy5Uyy0parZe6nwGW6vlg+0/AKsCHmX2lfQUwRtLHa+X6+6XBh4BtbU+wPYFqhOI1V/1lIeJmwD0l6b6SF6CTxX5/qNW7Z18Z27gOeK+kZcrUzK61bbdRjWhQFv2tYnsK1fD7WGDJkm9NqgV5c5C0oaRrqQKr24GJtvcvx3dI2f6S7ZXLcd4DuCJBQETEyDBUgcDxwMKSbgHOA/a13XOF+3uqIfGpwE/L6vo/U115XyZpGnA51VB3OycCv5I0pZb2Y+APtp+EVxfF7Ux10rxX0nXA6cAX2lUoaQJVsHJtT1qZ5vibpE1KUs8agelUV+fHl/T/Bj4u6Y/AuH6OC1Qr5T9ZpimW7iD/q2w/BHwD+BPwG6opg6fL5l9RjQAALAycWY7/TVTTGk+VbVtS/Xqg1SxgP9ub2T7Z9rN99UXSOcA1wFqSHpS0f0nfRdKDVOsNLpZ0aUlfUdIl/e1jb+UjImL+UHUOnUeVS/sCXbYPGuJ6f0l1svvtUNY7Ekla0vazZUTgZ8Aptn9Wtv0M+Lztu3opuzxwtu2t5l+P572uri53dw/5UoYRTUf0NUs0OD583v23HxEjj6QbbL/mfi2j6s6CksZKupNq3cICHwQUk2sjE/dS3S+hxxfpfSQFqlGPz86znkVExKjXyWLBQbN9GtWNaIaqvqeY/WuERrB9aB/b7mD2Wox226/vbVtERASMshGBiIiIGFoJBCIiIhosgUBERESDJRCIiIhosAQCERERDZZAICIiosESCERERDRYAoGIiIgGSyAQERHRYPP0zoIRMTTyXICImFcyIhAREdFgCQQiIiIaLIFAREREgyUQiIiIaLAEAhEREQ2WQCAiIqLBEghEREQ0WAKBiIiIBksgEBER0WCyc8eyGF0kzQTuH+5+zGfjgMeGuxMjTI7JnHI85pTj8Vqr2R7fmphAIGIUkNRtu2u4+zGS5JjMKcdjTjkencvUQERERIMlEIiIiGiwBAIRo8OJw92BESjHZE45HnPK8ehQ1ghEREQ0WEYEIiIiGiyBQMQIImlbSXdIulvSF9tsl6Rjy/ZpkjYcjn7OLx0cj0mSnpY0tby+Nhz9nF8knSJphqTpvWxv1PcDOjomjfqODEYCgYgRQtLCwPeB7YB1gQ9JWrcl23bAW8vrAOAH87WT81GHxwPgatsTy+vI+drJ+e80YNs+tjfm+1FzGn0fE2jWd2TAEghEjBwbA3fb/ovtF4BzgZ1a8uwE/MiVa4GxklaY3x2dTzo5Ho1i+yrgiT6yNOn7AXR0TKIfCQQiRo6VgAdqnx8saQPNs6DodF83lXSzpF9JWm/+dG3EatL3YyDyHenDIsPdgYh4ldqktf6sp5M8C4pO9vVGqtumPitpe+BCqmHxpmrS96NT+Y70IyMCESPHg8Aqtc8rAw8PIs+Cot99tf0328+W95cAi0oaN/+6OOI06fvRkXxH+pdAIGLkuB54q6Q3S1oM2AO4qCXPRcDeZXX4u4CnbT8yvzs6n/R7PCS9SZLK+42p/p/2+Hzv6cjRpO9HR/Id6V+mBiJGCNsvSToIuBRYGDjF9q2SDizbTwAuAbYH7gb+Duw3XP2d1zo8HrsBH5f0EjAL2MML8F3SJJ0DTALGSXoQOBxYFJr3/ejRwTFp1HdkMHJnwYiIiAbL1EBERESDJRCIiIhosAQCERERDZZAICIiosESCERERDRYAoGIiIgGSyAQERHRYAkEIiIiGuz/A46Qe+F6/mOWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 3:\n",
      "True value: 14.889071669765524\n",
      "Predicted value: 14.751056921750434\n",
      "Explanation: \n",
      "[('PrimaryPropertyType_19 <= 0.00', -0.2875932912793371), ('Neighborhood_2 <= 0.00', -0.23190921697050218), ('SteamUse(kBtu) <= 0.00', -0.21663057024612986), ('PrimaryPropertyType_10 > 0.00', 0.10589272945359023), ('14.27 < Electricity(kBtu) <= 15.29', 0.08369937846577301)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 4:\n",
      "True value: 16.76860230947871\n",
      "Predicted value: 16.828830532404446\n",
      "Explanation: \n",
      "[('Electricity(kBtu) > 15.29', 1.8994962796998522), ('NaturalGas(kBtu) > 14.18', 0.7079220458499831), ('SiteEUI(kBtu/sf) > 4.39', 0.4868721597385047), ('SteamUse(kBtu) <= 0.00', -0.3051505920794239), ('PropertyGFABuilding(s) > 11.41', 0.16705934801465594)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Création d'un explainer LIME\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X.columns.values, discretize_continuous=True, mode='regression')\n",
    "\n",
    "# Calcul de l'importance des fonctionnalités pour les instances de test\n",
    "for i in range(5):\n",
    "    exp = explainer.explain_instance(X_test.values[i], gbr.predict, num_features=5)\n",
    "    print('Instance {}:'.format(i))\n",
    "    print('True value: {}'.format(y_test.values[i]))\n",
    "    print('Predicted value: {}'.format(gbr.predict(X_test.values[i].reshape(1, -1))[0]))\n",
    "    print('Explanation: \\n{}'.format(exp.as_list()))\n",
    "# Visualisation de l'importance des fonctionnalités\n",
    "    fig = exp.as_pyplot_figure()\n",
    "    fig.suptitle('Feature importance {}'.format(i))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0c3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e21775dd",
   "metadata": {},
   "source": [
    "# <a name=\"C5\"> MODELISATION SANS \"ENERGYSTARScore\"</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e13bd0",
   "metadata": {},
   "source": [
    "#### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ed926c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns= [\"Target_Energies\",\"Target_GES\",\"ENERGYSTARScore\",\"GHGEmissionsIntensity\"])\n",
    "y = data['Target_Energies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "781bc4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CouncilDistrictCode</th>\n",
       "      <th>AgeBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>SteamUse(kBtu)</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighborhood_9</th>\n",
       "      <th>Neighborhood_10</th>\n",
       "      <th>Neighborhood_11</th>\n",
       "      <th>Neighborhood_12</th>\n",
       "      <th>Neighborhood_13</th>\n",
       "      <th>Neighborhood_14</th>\n",
       "      <th>Neighborhood_15</th>\n",
       "      <th>Neighborhood_16</th>\n",
       "      <th>Neighborhood_17</th>\n",
       "      <th>Neighborhood_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.492968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.492968</td>\n",
       "      <td>3.015535</td>\n",
       "      <td>3.927896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.090340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.090340</td>\n",
       "      <td>5.282696</td>\n",
       "      <td>6.426974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.101395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.101395</td>\n",
       "      <td>6.001662</td>\n",
       "      <td>6.816517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.800922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.800922</td>\n",
       "      <td>4.360548</td>\n",
       "      <td>4.654912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.202261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.202261</td>\n",
       "      <td>3.411148</td>\n",
       "      <td>4.123903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CouncilDistrictCode  AgeBuilt  NumberofBuildings  NumberofFloors  \\\n",
       "405                     1        27                1.0               2   \n",
       "1144                    2        56                1.0               1   \n",
       "1225                    4        43                1.0               1   \n",
       "1105                    1        99                1.0               1   \n",
       "573                     2        56                1.0               1   \n",
       "\n",
       "      PropertyGFATotal  PropertyGFAParking  PropertyGFABuilding(s)  \\\n",
       "405          11.492968                 0.0               11.492968   \n",
       "1144         10.090340                 0.0               10.090340   \n",
       "1225         10.101395                 0.0               10.101395   \n",
       "1105         10.800922                 0.0               10.800922   \n",
       "573          11.202261                 0.0               11.202261   \n",
       "\n",
       "      SiteEUI(kBtu/sf)  SourceEUI(kBtu/sf)  SteamUse(kBtu)  ...  \\\n",
       "405           3.015535            3.927896             0.0  ...   \n",
       "1144          5.282696            6.426974             0.0  ...   \n",
       "1225          6.001662            6.816517             0.0  ...   \n",
       "1105          4.360548            4.654912             0.0  ...   \n",
       "573           3.411148            4.123903             0.0  ...   \n",
       "\n",
       "      Neighborhood_9  Neighborhood_10  Neighborhood_11  Neighborhood_12  \\\n",
       "405              1.0              0.0              0.0              0.0   \n",
       "1144             1.0              0.0              0.0              0.0   \n",
       "1225             0.0              0.0              0.0              0.0   \n",
       "1105             0.0              0.0              0.0              0.0   \n",
       "573              1.0              0.0              0.0              0.0   \n",
       "\n",
       "      Neighborhood_13  Neighborhood_14  Neighborhood_15  Neighborhood_16  \\\n",
       "405               0.0              0.0              0.0              0.0   \n",
       "1144              0.0              0.0              0.0              0.0   \n",
       "1225              1.0              0.0              0.0              0.0   \n",
       "1105              0.0              0.0              0.0              0.0   \n",
       "573               0.0              0.0              0.0              0.0   \n",
       "\n",
       "      Neighborhood_17  Neighborhood_18  \n",
       "405               0.0              0.0  \n",
       "1144              0.0              0.0  \n",
       "1225              0.0              0.0  \n",
       "1105              0.0              1.0  \n",
       "573               0.0              0.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=5, shuffle=True)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "45218388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258     15.293267\n",
       "626     14.477483\n",
       "1545    13.093904\n",
       "1146    13.546447\n",
       "722     13.442477\n",
       "Name: Target_Energies, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac2c2d",
   "metadata": {},
   "source": [
    "## <a name=\"C51\"> 5.1) Regression linéaire </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb14cef",
   "metadata": {},
   "source": [
    "\n",
    "###  a.) Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe2026b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'normalize': False}\n",
    "# initialisation du modèle\n",
    "lr = LinearRegression()\n",
    "# Adapter les données (entraînement du modèle)\n",
    "lr.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9189e",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b62ec90",
   "metadata": {},
   "source": [
    "####  Evaluation du training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dc579db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse = mean_squared_error(y_train, y_train_pred)\n",
    "mse = (np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_lr_train  = pd.DataFrame(scores, index = ['Training set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990129d",
   "metadata": {},
   "source": [
    "####  Evaluation du testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30aa7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'erreur quadratique moyenne\n",
    "mse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "# Le score R²\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "# l'erreur carré relative\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_lr  = pd.DataFrame(scores, index = ['Régression Linéaire'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15dab2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION LINEAIRE :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training set</th>\n",
       "      <td>0.808755</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.823312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Régression Linéaire</th>\n",
       "      <td>0.923167</td>\n",
       "      <td>0.226547</td>\n",
       "      <td>0.773453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mse       rse        R²\n",
       "Training set         0.808755  0.013274  0.823312\n",
       "Régression Linéaire  0.923167  0.226547  0.773453"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_lr_train,df_lr])\n",
    "print(\"REGRESSION LINEAIRE :\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72691ad8",
   "metadata": {},
   "source": [
    "## <a name=\"C52\"> 5.2) Forêt Aléatoire </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6491fd1",
   "metadata": {},
   "source": [
    "###  a.) Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aef5703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du modèle\n",
    "rfr = model_class(random_state=42, max_depth= 5, n_estimators= 100)\n",
    "# Adapter les données (entraînement du modèle)\n",
    "rfr.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "y_train_pred = rfr.predict(X_train)\n",
    "y_test_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95212c14",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle\n",
    "####  Evaluation du training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43bc2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train,y_train_pred )\n",
    "mse = mean_squared_error(y_train, y_train_pred )\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_rfr_train  = pd.DataFrame(scores, index = ['Training set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535a1f1",
   "metadata": {},
   "source": [
    "####  Evaluation du testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c2230085",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_rfr = pd.DataFrame(scores, index = ['Forêt Aléatoire'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83711ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORÊT ALEATOIRE :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training set</th>\n",
       "      <td>0.067119</td>\n",
       "      <td>0.018131</td>\n",
       "      <td>0.981869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forêt Aléatoire</th>\n",
       "      <td>0.091941</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>0.975560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mse       rse        R²\n",
       "Training set     0.067119  0.018131  0.981869\n",
       "Forêt Aléatoire  0.091941  0.024440  0.975560"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_rfr_train,df_rfr])\n",
    "print(\"FORÊT ALEATOIRE :\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11676a6f",
   "metadata": {},
   "source": [
    "## <a name=\"C53\"> 5.3) Gradient Boosting  </a>\n",
    "###  a.) Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a22ea656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Hyperparameters for GradientBoostingRegressor\n",
    "gbr_params = {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 300}\n",
    "\n",
    "gbr = GradientBoostingRegressor(**gbr_params,random_state=0)\n",
    "gbr.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "y_train_pred = gbr.predict(X_train)\n",
    "y_test_pred = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ee1ec",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle\n",
    "####  Evaluation du training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cb42e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train,y_train_pred )\n",
    "mse = mean_squared_error(y_train, y_train_pred )\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_grb_train  = pd.DataFrame(scores, index = ['Training set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c50b9e",
   "metadata": {},
   "source": [
    "####  Evaluation du testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5a1637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_grb = pd.DataFrame(scores, index = ['Gradient Boosting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b776d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOSTING  :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training set</th>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.999175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.076920</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.979553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mse       rse        R²\n",
       "Training set       0.003053  0.000825  0.999175\n",
       "Gradient Boosting  0.076920  0.020447  0.979553"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_grb_train,df_grb])\n",
    "print(\"GRADIENT BOOSTING  :\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae287ee",
   "metadata": {},
   "source": [
    "## <a name=\"C54\"> 5.4) MLP </a>\n",
    "###  a.) Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "14be2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmedc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(activation = 'relu', hidden_layer_sizes= (30,), solver ='lbfgs')\n",
    "mlp.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "y_test_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd14632",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle\n",
    "####  Evaluation du training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cad4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train,y_train_pred )\n",
    "mse = mean_squared_error(y_train, y_train_pred )\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_mlp_train  = pd.DataFrame(scores, index = ['Training set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f3c38",
   "metadata": {},
   "source": [
    "####  Evaluation du testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d98619c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_mlp = pd.DataFrame(scores, index = ['MLP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b8721d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training set</th>\n",
       "      <td>0.60889</td>\n",
       "      <td>0.164480</td>\n",
       "      <td>0.835520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.94424</td>\n",
       "      <td>0.251003</td>\n",
       "      <td>0.748997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mse       rse        R²\n",
       "Training set  0.60889  0.164480  0.835520\n",
       "MLP           0.94424  0.251003  0.748997"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_mlp_train, df_mlp])\n",
    "print(\"MLP :\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1994d",
   "metadata": {},
   "source": [
    "## <a name=\"C55\"> 5.5) XGBoost </a>\n",
    "###  a.) Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a973c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = xgb.XGBRegressor(learning_rate= 0.2, max_depth=3, n_estimators= 300) \n",
    "gb.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "y_train_pred = gb.predict(X_train)\n",
    "y_test_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff1d7c",
   "metadata": {},
   "source": [
    "### b.) Evaluation du modèle\n",
    "####  Evaluation du training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5e5bc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train,y_train_pred )\n",
    "mse = mean_squared_error(y_train, y_train_pred )\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_gb_train  = pd.DataFrame(scores, index = ['Training set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb42b1af",
   "metadata": {},
   "source": [
    "####  Evaluation du testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d655497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rse = 1-r2\n",
    "\n",
    "scores = {'mse':mse,'rse' :rse,'R²' : r2}\n",
    "df_gb = pd.DataFrame(scores, index = ['XGBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "be6ec350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training set</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.999785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.022047</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.994139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mse       rse        R²\n",
       "Training set  0.000797  0.000215  0.999785\n",
       "XGBoost       0.022047  0.005861  0.994139"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_gb_train, df_gb])\n",
    "print(\"XGBOOST :\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69112246",
   "metadata": {},
   "source": [
    "## Tableau récapitulatif des scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8e752d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rse</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Régression Linéaire</th>\n",
       "      <td>0.923167</td>\n",
       "      <td>0.226547</td>\n",
       "      <td>0.773453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.076920</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.979553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forêt Aléatoire</th>\n",
       "      <td>0.091941</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>0.975560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.944240</td>\n",
       "      <td>0.251003</td>\n",
       "      <td>0.748997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.022047</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.994139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mse       rse        R²\n",
       "Régression Linéaire  0.923167  0.226547  0.773453\n",
       "Gradient Boosting    0.076920  0.020447  0.979553\n",
       "Forêt Aléatoire      0.091941  0.024440  0.975560\n",
       "MLP                  0.944240  0.251003  0.748997\n",
       "XGBoost              0.022047  0.005861  0.994139"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF2 = pd.concat([df_lr,df_grb,df_rfr,df_mlp,df_gb])\n",
    "DF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "703640ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Régression Linéaire</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>Forêt Aléatoire</th>\n",
       "      <th>MLP</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R²(avec ENERGYSTARScore)</th>\n",
       "      <td>0.821597</td>\n",
       "      <td>0.979401</td>\n",
       "      <td>0.954553</td>\n",
       "      <td>0.912775</td>\n",
       "      <td>0.986726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R²(Sans ENERGYSTARScore)</th>\n",
       "      <td>0.773453</td>\n",
       "      <td>0.979553</td>\n",
       "      <td>0.975560</td>\n",
       "      <td>0.748997</td>\n",
       "      <td>0.994139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Régression Linéaire  Gradient Boosting  \\\n",
       "R²(avec ENERGYSTARScore)             0.821597           0.979401   \n",
       "R²(Sans ENERGYSTARScore)             0.773453           0.979553   \n",
       "\n",
       "                          Forêt Aléatoire       MLP   XGBoost  \n",
       "R²(avec ENERGYSTARScore)         0.954553  0.912775  0.986726  \n",
       "R²(Sans ENERGYSTARScore)         0.975560  0.748997  0.994139  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF2 = DF2.drop(columns=[\"mse\",\"rse\"])\n",
    "DF2 = DF2.transpose()\n",
    "\n",
    "DF1 = DF1.drop(columns=[\"mse\",\"rse\"])\n",
    "DF1 = DF1.transpose()\n",
    "\n",
    "DF = pd.concat([DF1,DF2])\n",
    "DF.index = [\"R²(avec ENERGYSTARScore)\",\"R²(Sans ENERGYSTARScore)\"]\n",
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c59342",
   "metadata": {},
   "source": [
    "Nous ne constatons pas de changement notable du R²."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f5497",
   "metadata": {},
   "source": [
    "# <a name=\"C6\"> CONCLUSION </a>\n",
    "\n",
    "Le meilleur modèle pour la prédiction de la consommation de l'énergie est l'algorithme Gradiant Boosting.\n",
    "\n",
    "La suppression de la variable \"ENERGYSTARScore\" n'a pas d'impact majeur sur notre modèle.\n",
    "\n",
    "Les variables ayant le plus d'importance dans la prédiction de lénergie sont : \n",
    "\n",
    "   - **SiteEUI(kBtu/sf) (54%)**\n",
    " \n",
    "   - **Electricity(kBtu) (36%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26d102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
